<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>The Expectation Functional of Simple Random Variables - hqin</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="hqin"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="hqin"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="DefinitionsExpectation of Simple Random Variables:  Let $(X,\Sigma, \mathbf{p})$ be a probability space.   The set of all simple random variables on $(X,\Sigma, \mathbf{p})$ is a linear space relative"><meta property="og:type" content="blog"><meta property="og:title" content="The Expectation Functional of Simple Random Variables"><meta property="og:url" content="https://hqin-2020.github.io/2020/12/15/Mathematics/Analysis/10%20Expectation%20via%20the%20Lebesgue%20Integral/The-Expectation-Functional-of-Simple-Random-Variables/"><meta property="og:site_name" content="hqin"><meta property="og:description" content="DefinitionsExpectation of Simple Random Variables:  Let $(X,\Sigma, \mathbf{p})$ be a probability space.   The set of all simple random variables on $(X,\Sigma, \mathbf{p})$ is a linear space relative"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://hqin-2020.github.io/img/og_image.png"><meta property="article:published_time" content="2020-12-15T13:52:59.000Z"><meta property="article:modified_time" content="2021-01-02T05:47:12.809Z"><meta property="article:author" content="hqin"><meta property="article:tag" content="Measure Theoretic Probability"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hqin-2020.github.io/2020/12/15/Mathematics/Analysis/10%20Expectation%20via%20the%20Lebesgue%20Integral/The-Expectation-Functional-of-Simple-Random-Variables/"},"headline":"hqin","image":["https://hqin-2020.github.io/img/og_image.png"],"datePublished":"2020-12-15T13:52:59.000Z","dateModified":"2021-01-02T05:47:12.809Z","author":{"@type":"Person","name":"hqin"},"description":"DefinitionsExpectation of Simple Random Variables:  Let $(X,\\Sigma, \\mathbf{p})$ be a probability space.   The set of all simple random variables on $(X,\\Sigma, \\mathbf{p})$ is a linear space relative"}</script><link rel="canonical" href="https://hqin-2020.github.io/2020/12/15/Mathematics/Analysis/10%20Expectation%20via%20the%20Lebesgue%20Integral/The-Expectation-Functional-of-Simple-Random-Variables/"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="hqin" type="application/atom+xml">
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">hqin</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T13:52:59.000Z" title="12/15/2020, 9:52:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span> / </span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span> / </span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-F-Expectation-Lebesgue-Integral-and-Stieltjes-Integral/">1.1.F Expectation, Lebesgue Integral, and Stieltjes Integral</a></span></div></div><h1 class="title is-3 is-size-4-mobile">The Expectation Functional of Simple Random Variables</h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Expectation of Simple Random Variables</strong>:</p>
<ul>
<li><p>Let $(X,\Sigma, \mathbf{p})$ be a probability space. </p>
</li>
<li><p>The set of all simple random variables on $(X,\Sigma, \mathbf{p})$ is a linear space relative to the pointwise defined addition and scalar multiplication operations.</p>
</li>
<li><p>By definition, for any simple random variable $x$ on $(X,\Sigma, \mathbf{p})$, we have $|x(X)| &lt; \infty$ and<br>$$<br>x=\sum_{a\in x(X)}a\mathbf{1}_{x=a}<br>$$</p>
</li>
<li><p>where $\mathbf{1}_{ {x=a} }$ stands for the indicator function of the event ${x = a}\in\Sigma$ on $X$.</p>
</li>
<li><p>We define the <strong>expectation</strong> of any such $x$ as the real number<br>$$<br>\mathbb{E}(x):=\sum_{a\in  x(X)}a\mathbf{p}{x=a}<br>$$</p>
</li>
<li><p>Thus, the expected value of $x$ is the weighted average of its values, where the weight of $a$ is $\mathbf{p}<em>x{a}$ for each $a\in x(X)$. That is, $\mathbf{E}(x) =\sum</em>{a\in x(X)}\mathbf{p}_x{a}$.</p>
</li>
</ul>
<blockquote>
<p>Linearity of $\mathbb{E}$:<br>$$<br>\mathbb{E}(x+y)=\mathbb{E}(x)+\mathbb{E}(y)<br>$$<br>Monotonicity of $\mathbb{E}$:<br>$$<br>\mathbb{E}(x) \geq \mathbb{E}(y)\mbox{ whenever }x\geq_{a.s.}y<br>$$</p>
<p>$$<br>\mathbb{E}(x)= \mathbb{E}(y)\mbox{ whenever }x=_{a.s.}y<br>$$</p>
</blockquote>
<p><strong>Variance of Simple Random Variables</strong>:</p>
<ul>
<li><p>The <strong>variance</strong> of a simple random variable $x$ on $(X,\Sigma,\mathbf{p})$ is the number<br>$$<br>\mathbb{V}(x) := \mathbb{E}((x - \mathbb{E}(x))^2)<br>$$</p>
</li>
<li><p>where $(x-\mathbb{E}(x))^2$ is the simple random variable $\omega\mapsto (x(\omega) -\mathbb{E}(x))^2$ on $(X,\Sigma, \mathbf{p})$.</p>
</li>
</ul>
<blockquote>
<p>However, it is often more convenient to use the alternate formula<br>$$<br>\mathbb{V}(x) := \mathbb{E}(x^2) - \mathbb{E}(x)^2<br>$$</p>
</blockquote>
<p><strong>Expectation of Nonnegative Random Variables</strong></p>
<ul>
<li><p>Let $x$ be a $[0, \infty]$-valued random variable on a probability space $(X,\Sigma,\mathbf{p})$. </p>
</li>
<li><p>We define the <strong>expectation</strong> of $x$ as the (extended real) number<br>$$<br>\mathbb{E}(x) := \sup{\mathbb{E}(z) : z \in \mathfrak{L}(x)}<br>$$</p>
</li>
<li><p>where $\mathfrak{L}(x)$ stands for the set of all simple random variables $z$ such that $z\leq x$.</p>
</li>
<li><p>In turn, the <strong>variance</strong> of $x$ is defined as the (extended real) number<br>$$<br>\mathbb{V}(x) := \mathbb{E}((x - \mathbb{E}(x))^2),<br>$$</p>
</li>
<li><p>provided that $\mathbb{E}(x) &lt; \infty$. </p>
</li>
<li><p>where $(x-\mathbb{E}(x))^2$ is the simple random variable $\omega\mapsto (x(\omega) -\mathbb{E}(x))^2$ on $(X,\Sigma, \mathbf{p})$.</p>
</li>
</ul>
<blockquote>
<p>These definitions agree with those in the case of simple random variables on $(X,\Sigma, \mathbf{p})$. Moreover, they extend those definitions to the case of $[0,\infty]$-valued simple random variables.</p>
</blockquote>
<blockquote>
<p>In words, the (extended real) number $\mathbb{E}(x)$ is defined as the supremum of the weighted averages of all those simple random variables that are “smaller than” $x$ everywhere. </p>
<p>So, in this sense, the idea behind the definition of $\mathbb{E}(x)$ is reminiscent of that of the computation of the area under a given curve in $\mathbb{R}\times \mathbb{R}_+$ by approximating this area with the sum of the areas of the rectangles that lie under the curve and above the horizontal axis.</p>
<p>Put this way, you should see that $\mathbb{E}(x)$ can be thought of as some sort of an integral of $x$ – it is called the <strong>Lebesgue integral</strong> of $x$ with respect to $\mathbf{p}$ –where the sets in the domain of $x$ (analogous to the bases of the rectangles under the curve) are “measured” according to the underlying probability measure.</p>
</blockquote>
<blockquote>
<p>The commonly used notation for the Lebesgue integral of $x$ on $X$ with respect to $\mathbf{p}$ is $\int_Xxdp$, that is<br>$$<br>\int_X xd\mathbf{p}\ \mbox{ and }\ \mathbb{E}(x)<br>$$<br>denote the same (extended real) number. </p>
</blockquote>
<blockquote>
<p>Adopting the widely used conventions of integration theory, we also set<br>$$<br>\int_Sxd\mathbf{p}:=\mathbb{E}(x\mathbf{1}_S)\mbox{ for any } S\in \Sigma,<br>$$<br>where $\mathbf{1}_S$ is the indicator function of $S$ on $X$. Therefore, recalling the definition of the expectation of a simple random variable, we see that $\int_S d\mathbf{p}$, that is, the Lebesgue integral of the constant function $1$ with respect to $\mathbf{p}$ on $S$, and $\mathbb{E}(\mathbf{1}_S )$ denote the same number, namely, $\mathbf{p}(S)$, for any $S\in\Sigma$.</p>
</blockquote>
<blockquote>
<p>Many authors write<br>$$<br>\int_X x(\omega)\mathbf{p}(dw)<br>$$<br>instead of $\int_Xxd\mathbf{p}$. The Lebesgue integral of the map $\omega\mapsto\omega^2$ on the probability space $([0,1],\mathcal{B}[0,1],\ell)$ is, for instance, written as $\int_{[0,1]}\omega^2\ell(d\omega)$. </p>
</blockquote>
<p><strong>Lebesgue Integration of Simple Maps</strong>:</p>
<ul>
<li><p>Let $(X,\Sigma,\mu )$ be a measure space. </p>
</li>
<li><p>By <strong>a nonnegative simple $\Sigma$-measurable map</strong> on $X$, we mean a real function $f\in \mathcal{L}^0(X,\Sigma)$ such that $f\geq0$ and $f(X)$ is finite. </p>
</li>
<li><p>The <strong>Lebesgue integral</strong> of any such map with respect to $\mu$ is defined as the number<br>$$<br>\int_Xfd\mu:=\sum_{a\in f(X)}a\mu{f=a},<br>$$</p>
</li>
<li><p>where we adopt the convention that $0\cdot\infty$ equals $0$.</p>
</li>
</ul>
<p><strong>Lebesgue Integration of Nonnegative Maps</strong>:</p>
<ul>
<li><p>Let $(X,\Sigma,\mu)$ be a measure space. </p>
</li>
<li><p>The <strong>Lebesgue integral of any $\Sigma$-measurable</strong> $f : X \to [0, \infty]$ with respect to $\mu$ is defined as the (extended) real number<br>$$<br>\int_X fd\mu:=\sup{\int_Xhd\mu:h\in\mathfrak{M}(f)}<br>$$</p>
</li>
<li><p>where $\mathfrak{M}(f)$ stands for the set of all nonnegative simple $\Sigma$-measurable maps $h$ on $X$ with $h\leq f$. </p>
</li>
<li><p>In turn, we define<br>$$<br>\int_S fd\mu:=\int_X f\mathbf{1}_S d\mu\ \ \ \ \mbox{ for any }S\in\Sigma<br>$$</p>
</li>
<li><p>where $\mathbf{1}_S$ is the indicator function of $S$ on $X$.</p>
</li>
</ul>
<p><strong>$\sigma$-finite Measure</strong>:</p>
<ul>
<li>Let $(X,\Sigma,\mu)$ be a measure space. </li>
<li>We say that this space (or $\mu$ itself) is <strong>$\sigma$-finite</strong> if there is a countable partition $\mathcal{S}$ of $X$ such that $\mathcal{S}\subseteq \Sigma$ and $\mu(S) &lt; \infty$ for each $S \in\mathcal{S}$</li>
</ul>
<p><strong>Absolutely Continuous, Density Function, Density</strong>:</p>
<ul>
<li><p>Let $F$ be a distribution function. </p>
</li>
<li><p>We say that $F$ is <strong>absolutely continuous</strong> (with respect to the Lebesgue measure) if there is a Borel measurable map $f : \mathbb{R} \to \mathbb{R}<em>+$ such that<br>$$<br>F(t)=\int</em>{(-\infty,t]}fd\ell<br>$$</p>
</li>
<li><p>for every real number $t$.</p>
</li>
<li><p>When this is the case, we say that $F$ is induced by the <strong>density function</strong> $f$, and refer to $f$ as a <strong>density</strong> for $F$.</p>
</li>
</ul>
<blockquote>
<p>When $f$ is a density for $F$, $F(t)-F(s)=\int_{(s,t]}fd\ell$ for any real numbers $s$ and $t$ with $t &gt; s$.</p>
</blockquote>
<blockquote>
<p>Some distribution functions do not have closed form decriptions, but they are rather defined through integrating a density function.</p>
<p>The most important example of such a function is the so-called <strong>normal distribution</strong> function (with parameters $\mu $ and $\sigma$). For any given real numbers $\mu$ and $\sigma&gt;0$, this function $F$ is defined by<br>$$<br>f(t)=\frac{1}{\sqrt{2\pi}}e^{\frac{(t-\mu)^2}{2\sigma^2}}<br>$$<br>for any real number $t$, it is thus trivially absolutely continuous.</p>
<p>If  $\mu= 0$ and $\mu = 1$ here, this function is called the <strong>standard normal distribution</strong> <strong>function</strong>.</p>
</blockquote>
<blockquote>
<p>Not all distribution function arises from a density funtion.</p>
</blockquote>
<p><strong>Absolutely Continuous Measures</strong>:</p>
<ul>
<li>Let $(X,\Sigma)$ be a measurable space, and $\mu$ and $\nu$  two measures on $\Sigma$. </li>
<li>We say that $\mu$ is <strong>absolutely continuous with respect to $\nu$</strong>, this is denoted by writing    $\mu\ll\nu$ </li>
<li>if $\mu(S) = 0$ for every $S\in\Sigma$  with $\nu(S) = 0$.</li>
</ul>
<blockquote>
<p>The zero measure on $\Sigma$ is absolutely continuous with respect to any measure on $\Sigma$</p>
<p>While the counting measure on $\Sigma$ is not absolutely continuous with respect to any measure $\nu$ on $\Sigma$  such that $\nu(S) = 0$ for some nonempty $S\in\Sigma$ .</p>
</blockquote>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Proposition 1.1</strong>: </p>
<ul>
<li><p>For any $[0,\infty]$-valued random variables $x$ and $y$ (on a given probability space),<br>$$<br>x\geq_{a.s.}y\ \ \ \ \mbox{ implies }\ \ \ \ \mathbb{E}(x) \geq \mathbb{E}(y)<br>$$</p>
<p>$$<br>x=_{a.s.}y\ \ \ \ \mbox{ implies }\ \ \ \ \mathbb{E}(x) = \mathbb{E}(y)<br>$$</p>
</li>
</ul>
<p><strong>The Monotone Convergence Theorem 1</strong>:</p>
<ul>
<li>Let $x, x_1,x_2,\dots$ be $[0,\infty]$-valued random variables on a probability space $(X,\Sigma, \mathbf{p})$. Then,<br>$$<br>x_m \uparrow_{a.s.} x\ \ \ \ \ \mbox{ implies }\ \ \ \ \ \ \mathbb{E}(x_m)\uparrow \mathbb{E}(x)<br>$$</li>
</ul>
<p><strong>Proposition 1.2</strong>: </p>
<ul>
<li>Let $x$ and $y$ be two $[0,\infty]$-valued random variables on a probability space $(X,\Sigma, \mathbf{p})$. Then, for any $a\geq 0$,<br>$$<br>\mathbb{E}(ax+y)=a\mathbb{E}(x)+\mathbb{E}(y)<br>$$</li>
</ul>
<p><strong>Proposition 1.3</strong>: </p>
<ul>
<li><p>Let $(X,\Sigma,\mu )$ be a finite measure space. Then, there is a real number  $\lambda\geq 0$ and a probability measure $\mathbf{p}$ on $\Sigma$ such that<br>$$<br>\int_Xfd\mu=\lambda\int_Xfd\mathbf{p}<br>$$</p>
</li>
<li><p>for every $\Sigma$-measurable $f : X \to [0,\infty]$.</p>
</li>
</ul>
<p><strong>Proposition 1.5</strong>:</p>
<ul>
<li><p>Given any measure space $(X,\Sigma,\mu )$,<br>$$<br>\int_x(af+g)d\mu=a\int_Xfd\mu+\int_Xgd\mu<br>$$</p>
</li>
<li><p>for every $a\geq0$ and $\Sigma$-measurable $f : X \to [0,\infty]$.</p>
</li>
</ul>
<p><strong>Proposition 1.6</strong>: </p>
<ul>
<li>Every absolutely continuous distribution function is uniformly continuous.</li>
</ul>
<blockquote>
<p>If a distribution function is not continuous even at a single point, then it cannot possibly possess a density.</p>
<p>The converse of Proposition 1.6 is false. Indeed, even a continuous distribution function need not possess a density.</p>
</blockquote>
<p><strong>Proposition 1.7</strong>:</p>
<ul>
<li><p>Let $(X,\Sigma,\nu )$ be a measure space and take any $f\in \mathcal{L}^0_+(X,\Sigma )$. </p>
</li>
<li><p>Then, the map $\mu:\Sigma \to\mathbb{R}$ defined by<br>$$<br>\mu(S):=\int_S fd\nu,<br>$$</p>
</li>
<li><p>is a measure on $\Sigma$ with  $\mu\ll\nu$ . </p>
</li>
<li><p>If $\nu$ is $\sigma$-finite, so is $\mu$.</p>
</li>
</ul>
<p><strong>The Radon-Nikodym Theorem</strong>:</p>
<ul>
<li>Let $(X,\Sigma)$ be a measurable space, and $\mu$ and $\nu$ two $\sigma$-finite measures on $\Sigma$ with $\mu\ll\nu$. Then, there is an $f\in \mathcal{L}^0_+ ( X ,\Sigma)$ such that<br>$$<br>\mu(S)=\int_Sfd\nu\mbox{ for every }S\in\Sigma<br>$$</li>
</ul>
<blockquote>
<p>Any map $f\in\mathcal{L}^0_+(X,\Sigma)$ such that above equation holds is commonly referred to as either the <strong>density of $\mu$ with respect to $\nu$</strong> or as the <strong>Radon-Nikodym derivative of $\mu$ with respect to $\nu$</strong>. </p>
<p>It is quite standard to denote any such map as $\frac{d\mu}{d\nu}$.</p>
</blockquote>
<p><strong>Proposition 1.8</strong>:</p>
<ul>
<li>Let $F$ be a distribution function and $\mathbf{p}_F$ the Lebesgue-Stieltjes probability measure on $\mathbb{R}$ induced by $F$. </li>
<li>Then, $F$ is absolutely continuous iff, $\mathbf{p}_F$ is absolutely continuous with respect to $\ell$.</li>
</ul>
<h2 id="Examples-and-Exercises"><a href="#Examples-and-Exercises" class="headerlink" title="Examples and Exercises"></a>Examples and Exercises</h2><p><strong>Example 1.1, Binomial Distribution</strong>: </p>
<ul>
<li><p>Let $n$ be a positive integer and $p$ a number in $[0, 1]$.</p>
</li>
<li><p>A ${0,\dots, n}$-valued random variable $x$ on a probability space $(X,\Sigma,\mathbf{p})$ such that<br>$$<br>\mathbf{p}{x=i}=\left(\begin{matrix}n\ i\end{matrix}\right)p^i(1-p)^{n-i},\ \ \ \ i=0,\dots,n<br>$$</p>
</li>
<li><p>is said to have a binomial distribution with parameters $n$ and $p$</p>
</li>
<li><p>If $n = 1$ here, we say that $x$ has a Bernoulli distribution with parameter $p$</p>
</li>
<li><p>When $n = 1$, we have $\mathbb{E}(x) = p(1) + (1-p)(0) = p$, that is, the expected value of any random variable that has a Bernoulli distribution with parameter $p$ is $p$.</p>
</li>
<li><p>In this case, we also find that $\mathbb{E}(x^2) = p$, so $\mathbb{V}(x) = p -p^2$</p>
</li>
<li><p>More generally, for any random variable that has a binomial distribution with parameters $n$ and $p$, we have<br>$$<br>\mathbb{E}(x)=\sum^n_{i=0}\left(\begin{matrix}n\ i \end{matrix}\right)p^i(1-p)^{n-i}i=np\sum^{n-1}_{i=0}\left(\begin{matrix}n-1\ i \end{matrix}\right)p^i(1-p)^{(n-1)-i}<br>$$</p>
</li>
<li><p>so, by the Binomial Theorem, $\mathbb{E}(x) = np(p + (1 -p))^{n-1} = np$. By using a similar</p>
<p>method, we can also show that $\mathbb{E}(x^2) = n^2 p^2 -np^2 + np$, so $\mathbb{V}(x) = np(1-p)$.</p>
</li>
</ul>
<p><strong>Example 1.3</strong>:</p>
<ul>
<li><p>Let $(X,2^X,\mathbf{p})$ be a probability space with $X$ being a countable set. </p>
</li>
<li><p>We wish to find an expression for the expectation of an arbitrary nonnegative random variable $x$ on $(X,2^X,\mathbf{p})$.</p>
</li>
<li><p>Assume that $X$ is countably infinite, and enumerate it as $X := {\omega_1,\omega_2,\dots}$. </p>
</li>
<li><p>For every positive integer $m$, let us define the simple random variable<br>$$<br>x_m(\omega)=\left{\begin{matrix}x(\omega),&amp;\mbox{ if }\omega\in{\omega_1,\dots,\omega_m}\0,&amp;\mbox{otherwise}\end{matrix}\right.<br>$$</p>
</li>
<li><p>By definition of $\mathbb{E}$ for simple random variables, we have $\mathbb{E}(x_m) =\sum_{i\in[m]} x(\omega_i)\mathbf{p}{\omega_i}$ for each $m$.</p>
</li>
<li><p>But, $x_m \uparrow x$, so we have $\mathbb{E}(x_m)\uparrow \mathbb{E}(x)$ by the Monotone Convergence Theorem 1. Consequently,<br>$$<br>\mathbb{E}(x)=\lim\mathbb{E}(x_m)=\lim\sum_{i\in[m]}x(\omega_i)\mathbf{p}{\omega_i}=\sum^\infty_{i=1}x(\omega_i)\mathbf{p}{\omega_i}=\sum_{x\in X}x(\omega)\mathbf{p}{\omega}<br>$$</p>
</li>
<li><p>for any nonnegative random variable $x$ on $(X,2^X,\mathbf{p})$.</p>
</li>
</ul>
<p><strong>Example 1.5</strong>: </p>
<ul>
<li><p>For any real numbers $a$ and $b$ with $a &lt; b$, the uniform distribution $F$ on $[a,b]$ is absolutely continuous.</p>
</li>
<li><p>The map $f:\mathbb{R}\to\mathbb{R}+$ where<br>$$<br>f(t)=\left{\begin{matrix}\frac{1}{a-b},&amp;0\leq t\leq b\0,&amp;\mbox{otherwise}\end{matrix}\right.<br>$$</p>
</li>
<li><p>is a density for that distribution function. </p>
</li>
<li><p>Similarly, for any $\lambda &gt; 0$, the exponential distribution with parameter $\lambda$ ,is absolutely continuous.</p>
</li>
<li><p>The map $f:\mathbb{R}\to\mathbb{R}+$ where<br>$$<br>f(t)=\left{\begin{matrix}\lambda e^{-\lambda t},&amp; t\geq 0\0,&amp;\mbox{otherwise}\end{matrix}\right.<br>$$</p>
</li>
<li><p>is a density for that distribution function. </p>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, “Measure and Probability Theory with Economic Applications”;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, “Real and Complex Analysis”; </li>
<li>Walter Rudin, 1976, “Principle of Mathematical Analysis”; </li>
</ol>
</div><div class="article-licensing box"><div class="licensing-title"><p>The Expectation Functional of Simple Random Variables</p><p><a href="https://hqin-2020.github.io/2020/12/15/Mathematics/Analysis/10 Expectation via the Lebesgue Integral/The-Expectation-Functional-of-Simple-Random-Variables/">https://hqin-2020.github.io/2020/12/15/Mathematics/Analysis/10 Expectation via the Lebesgue Integral/The-Expectation-Functional-of-Simple-Random-Variables/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>hqin</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2020-12-15</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2021-01-02</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Measure-Theoretic-Probability/">Measure Theoretic Probability</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/12/15/Mathematics/Analysis/10%20Expectation%20via%20the%20Lebesgue%20Integral/The-Expectation-Functional-of-Arbitrary-Random-Variables/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">The Expectation Functional of Arbitrary Random Variables</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/12/15/Mathematics/Analysis/9%20Random%20Variables/The-Distribution-of-a-Random-Variable/"><span class="level-item">The Distribution of a Random Variable</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="hqin"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">hqin</p><p class="is-size-6 is-block">A Student in Economics</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Zhengzhou, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">46</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">13</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">4</p></a></div></div></nav></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-24T14:52:59.000Z">2020-12-24</time></p><p class="title"><a href="/2020/12/24/Mathematics/Algebra/2%20Linear%20Algebra/Geometric-Linear-Algebra/">Geometric Linear Algebra</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-2-Algebra/">1.2 Algebra</a> / <a href="/categories/1-Mathematics/1-2-Algebra/1-2-B-Linear-Algebra/">1.2.B Linear Algebra</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-24T14:52:00.000Z">2020-12-24</time></p><p class="title"><a href="/2020/12/24/Mathematics/Algebra/1%20Abstract%20Algebra/Elements-of-Abstract-Algebra/">Elements of Abstract Algebra</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-2-Algebra/">1.2 Algebra</a> / <a href="/categories/1-Mathematics/1-2-Algebra/1-2-A-Abstract-Algebra/">1.2.A Abstract Algebra</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-15T14:50:59.000Z">2020-12-15</time></p><p class="title"><a href="/2020/12/15/Mathematics/Analysis/15%20Stochastic%20Dependence/Propertities-of-Conditional-Expectation/">Propertities of Conditional Expectation</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a> / <a href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/">1.1.H Stochastic Independence and Dependence</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-15T14:49:59.000Z">2020-12-15</time></p><p class="title"><a href="/2020/12/15/Mathematics/Analysis/15%20Stochastic%20Dependence/Conditional-Expectation/">Conditional Expectation</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a> / <a href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/">1.1.H Stochastic Independence and Dependence</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-15T14:48:59.000Z">2020-12-15</time></p><p class="title"><a href="/2020/12/15/Mathematics/Analysis/14%20A%20Primer%20on%20Probability%20Limit%20Theorems/Law-of-Large-Numbers/">Law of Large Numbers</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a> / <a href="/categories/1-Mathematics/1-1-Analysis/1-1-G-Weak-Convergence-and-Probability-Limit/">1.1.G Weak Convergence and Probability Limit</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2020/12/"><span class="level-start"><span class="level-item">December 2020</span></span><span class="level-end"><span class="level-item tag">24</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/11/"><span class="level-start"><span class="level-item">November 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/10/"><span class="level-start"><span class="level-item">October 2020</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/09/"><span class="level-start"><span class="level-item">September 2020</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li></ul></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://ygnmax.github.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Guangnan Yang</span></span><span class="level-right"><span class="level-item tag">ygnmax.github.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Abstract-Algebra/"><span class="tag">Abstract Algebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Algebra/"><span class="tag">Linear Algebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Measure-Theoretic-Probability/"><span class="tag">Measure Theoretic Probability</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Real-Analysis/"><span class="tag">Real Analysis</span><span class="tag">24</span></a></div></div></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/1-Mathematics/"><span class="level-start"><span class="level-item">1 Mathematics</span></span><span class="level-end"><span class="level-item tag">46</span></span></a><ul><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/"><span class="level-start"><span class="level-item">1.1 Analysis</span></span><span class="level-end"><span class="level-item tag">44</span></span></a><ul><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-A-Preliminaries-of-Real-Analysis/"><span class="level-start"><span class="level-item">1.1.A Preliminaries of Real Analysis</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-B-Metric-Spaces-and-Continuity/"><span class="level-start"><span class="level-item">1.1.B Metric Spaces and Continuity</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-C-Linear-Spaces-and-Convexity/"><span class="level-start"><span class="level-item">1.1.C Linear Spaces and Convexity</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-D-Metric-Linear-Spaces-and-Normed-Linear-Spaces/"><span class="level-start"><span class="level-item">1.1.D Metric Linear Spaces and Normed Linear Spaces</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-E-Probability-via-Measure-Theory/"><span class="level-start"><span class="level-item">1.1.E Probability via Measure Theory</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-F-Expectation-Lebesgue-Integral-and-Stieltjes-Integral/"><span class="level-start"><span class="level-item">1.1.F Expectation, Lebesgue Integral, and Stieltjes Integral</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-G-Weak-Convergence-and-Probability-Limit/"><span class="level-start"><span class="level-item">1.1.G Weak Convergence and Probability Limit</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/"><span class="level-start"><span class="level-item">1.1.H Stochastic Independence and Dependence</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-2-Algebra/"><span class="level-start"><span class="level-item">1.2 Algebra</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/1-Mathematics/1-2-Algebra/1-2-A-Abstract-Algebra/"><span class="level-start"><span class="level-item">1.2.A Abstract Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-2-Algebra/1-2-B-Linear-Algebra/"><span class="level-start"><span class="level-item">1.2.B Linear Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">hqin</a><p class="is-size-7"><span>&copy; 2020 - 2021 hqin</span>  </p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'folded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>