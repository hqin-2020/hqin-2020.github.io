<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Category: 1.1.H Stochastic Independence and Dependence - hqin</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="hqin"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="hqin"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="hqin"><meta property="og:url" content="https://hqin-2020.github.io/"><meta property="og:site_name" content="hqin"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://hqin-2020.github.io/img/og_image.png"><meta property="article:author" content="hqin"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hqin-2020.github.io"},"headline":"hqin","image":["https://hqin-2020.github.io/img/og_image.png"],"author":{"@type":"Person","name":"hqin"},"description":""}</script><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="hqin" type="application/atom+xml">
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">hqin</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li><a href="/categories/1-Mathematics/">1 Mathematics</a></li><li><a href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a></li><li class="is-active"><a href="#" aria-current="page">1.1.H Stochastic Independence and Dependence</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:50:59.000Z" title="12/15/2020, 10:50:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/">1.1.H Stochastic Independence and Dependence</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/15%20Stochastic%20Dependence/Propertities-of-Conditional-Expectation/">Propertities of Conditional Expectation</a></h1><div class="content"><h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Proposition 2.1</strong>: </p>
<ul>
<li><p>Let $x$ and $y$ be integrable random variables on a probability space $(X,\Sigma, \mathbf{p})$ and $\Sigma_0$ a sub-$\sigma$-algebra of $\Sigma$. Then, for every real number $\alpha$<br>$$<br>\mathbb{E}(\alpha x|\Sigma_0)=<em>{a.s.}\alpha\mathbb{E}(x|\Sigma_0)<br>$$<br>and<br>$$<br>\mathbb{E}(x+y|\Sigma_0)=</em>{a.s.}\mathbb{E}(x|\Sigma_0)+\mathbb{E}(y|\Sigma_0)<br>$$</p>
</li>
<li><p>Moreover,<br>$$<br>x=_{a.s.}y\mbox{ implies }\mathbb{E}(x|\Sigma_0)+\mathbb{E}(y|\Sigma_0)<br>$$</p>
</li>
</ul>
<p><strong>Proposition 2.2</strong>: </p>
<ul>
<li>Let $x$ and $y$ be integrable random variables on a probability space $(X,\Sigma, \mathbf{p})$ and $\Sigma_0$ a sub-$\sigma$-algebra of $\Sigma$. Then,<br>$$<br>\mathbb{E}(\mathbb{E}(x|\Sigma_0))=\mathbb{E}(x)<br>$$<br>And if $\Sigma_1$ is another sub-$\sigma$-algebra of $\Sigma$, then<br>$$<br>\Sigma_0\subseteq \Sigma_1\mbox{ implies }\mathbb{E}(\mathbb{E}(x|\Sigma_1)|\Sigma_0)=\mathbb{E}(x|\Sigma_0)<br>$$</li>
</ul>
<p><strong>Proposition 2.4</strong>:</p>
<ul>
<li><p>Let $x$ and $y$ be integrable random variables on a probability space $(X,\Sigma, \mathbf{p})$ and $\Sigma_0$ a sub-$\sigma$-algebra of $\Sigma$.</p>
</li>
<li><p>If $y\in\mathcal{L}^0(X,\Sigma_0)$ and $\mathbb{E}(|xy|)&lt;\infty$,then<br>$$<br>\mathbb{E}(xy|\Sigma_0)=_{a.s.}y\mathbb{E}(x|\Sigma_0)<br>$$</p>
</li>
</ul>
<p><strong>The Conditional Monotone Convergence Theorem</strong>: </p>
<ul>
<li><p>Let $x, x_1,x_2,\dots$ be nonnegative integrable random variables on a probability space $(X,\Sigma, \mathbf{p})$ such that $x_m\nearrow_{a.s.} x$</p>
</li>
<li><p>If $\Sigma_0$ is a sub-$\sigma$-algebra of $\Sigma$, then<br>$$<br>\mathbb{E}(x_m|\Sigma_0)\nearrow_{a.s.}\mathbb{E}(x|\Sigma_0)<br>$$</p>
</li>
</ul>
<p><strong>The Conditional Dominated Convergence Theorem</strong>: </p>
<ul>
<li><p>Let $x, y,x_1,x_2,\dots$ be nonnegative integrable random variables on a probability space $(X,\Sigma, \mathbf{p})$ such that $x_m\leq_{a.s.} x$ for each $m$</p>
</li>
<li><p>If $\Sigma_0$ is a sub-$\sigma$-algebra of $\Sigma$, then<br>$$<br>\mathbb{E}(x_m|\Sigma_0)\to_{a.s.}\mathbb{E}(x|\Sigma_0)<br>$$</p>
</li>
</ul>
<p><strong>The Conditional Jensen‚Äôs Inequality</strong>:</p>
<ul>
<li>Let $x$ be an integrable random variable on a probability space $(X,\Sigma, \mathbf{p})$, and $\Sigma_0$ a sub-$\sigma$-algebra of $\Sigma$. If $\varphi$ is a concave self-map on $\mathbb{R}$ such that $\mathbb{E}(|\varphi\circ x|) &lt;\infty$, then<br>$$<br>\varphi(\mathbb{E}(x|\Sigma_0))\geq_{a.s.}\mathbb{E}(\varphi\circ x|\Sigma_0)<br>$$</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:49:59.000Z" title="12/15/2020, 10:49:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/">1.1.H Stochastic Independence and Dependence</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/15%20Stochastic%20Dependence/Conditional-Expectation/">Conditional Expectation</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Conditional Expectation on a Known Event</strong>:</p>
<ul>
<li><p>Let $x$ be an integrable random variable on a probability space $(X,\Sigma,\mathbf{p})$ </p>
</li>
<li><p>That is, $x\in\mathcal{L}^0(X,\Sigma$) and $\mathbb{E}(|x|) &lt; \infty$, or put differently, $x\in\mathcal{L}^1(X,\Sigma,\mathbf{p})$</p>
</li>
<li><p>For any event $C\in\Sigma$ with $\mathbf{p}(C) &gt; 0$, the <strong>conditional expectation</strong> <strong>of $x$ given</strong> $C$ is defined as<br>$$<br>\mathbb{E}(x|C):=\frac{1}{\mathbf{p}(C)}\int_Cxd\mathbf{p}<br>$$</p>
</li>
</ul>
<blockquote>
<p>When it is known that the event $C$ has occurred, one is less uncertain about the outcome of the underlying experiment. </p>
<p>The relevant probability space in this case can be thought of as $(C,\Sigma\cap C,\mathbf{q})$, where $\Sigma\cap C := {A\cap C:A\in\Sigma}$ and<br>$$<br>\mathbf{q}:=\frac{1}{\mathbf{p}(C)}\mathbf{p}|_{\Sigma\cap C}<br>$$<br>Consequently, we compute the conditional expectation of $x$ given $C$ simply as the expectation of $x|_C$ on this space.</p>
</blockquote>
<p><strong>Conditional Probability on a Known Event</strong>:</p>
<ul>
<li>The <strong>conditional probability</strong> of an event $A\in\Sigma$ given $C$ is $\mathbf{p}(A|C) := \frac{\mathbf{p}(A \cap C)}{\mathbf{p}(C)}$</li>
</ul>
<blockquote>
<p>Just as the probability of an event is the expectation of the indicator function of that event, the conditional probability of an event is the conditional expectation of the indicator function of that event:<br>$$<br>\mathbb{p}(A|C)=\frac{\mathbb{p}(A\cap C)}{\mathbf{p}(C)}\mathbb{E}(\mathbf{1}_A|C)<br>$$<br>Note that these notions apply only when we know that an event has already occurred.</p>
</blockquote>
<p><strong>Countable (finite) $\Sigma$-decomposition</strong>:</p>
<ul>
<li>By a <strong>countable (finite) $\Sigma$-decomposition</strong> of $X$ we mean a countable (finite) partition $\mathcal{C}$ of $X$ such that $\mathcal{C}\subseteq \Sigma$ and $\mathbf{p}(C) &gt; 0$ for all $C\in\mathcal{C}$.</li>
</ul>
<p><strong>Conditional Expectation on a Countable Decomposition</strong>:</p>
<ul>
<li><p>We define the <strong>conditional expectation of $x$ given $\mathcal{C}$</strong> as the <u>discrete random variable</u> $\mathbb{E}(x|{\mathcal{C}}) : X \to \mathbb{R}$ with<br>$$<br>\mathbb{E}(x|\mathcal{C})(\omega):=\mathbb{E}(x|C_\omega)<br>$$<br>or<br>$$<br>\int_{C_\omega}\mathbb{E}(x|\mathcal{C})d\mathbf{p}=\int_{C_\omega}xd\mathbf{p}\mbox{ for every }\omega\in X<br>$$</p>
</li>
<li><p>where $C_\omega$ is the member of $\mathcal{C}$ that contains the outcome $\omega$.</p>
</li>
<li><p>More compactly, we may write<br>$$<br>\mathbb{E}(x|\mathcal{C}):=\sum_{C\in\mathcal{C}}\mathbb{E}(x|C)\mathbf{1}_C<br>$$</p>
</li>
</ul>
<blockquote>
<p>Given that we will observe which member of $\mathcal{C}$ has occurred once the experiment is performed, we then calculate the conditional expectation.</p>
<p>A gambler, for instance, would like to have a strategy which is contingent on what will happen through the sequence of games she will repeatedly participate in.</p>
</blockquote>
<p><strong>Conditional Probability on a Countable Decomposition</strong>:</p>
<ul>
<li><p>The <strong>conditional probability of an event $A$ in $\Sigma$ given $\mathcal{C}$</strong> is similarly defined as the <u>discrete random variable</u> $\mathbf{p}(A|\mathcal{C}) : X\to\mathbb{R}$ with<br>$$<br>\mathbf{p}(A|\mathcal{C}) (\omega):=\frac{\mathbf{p}(A\cap C_\omega)}{\mathbf{p}(C_\omega)}<br>$$</p>
</li>
<li><p>Or equivalently,<br>$$<br>\mathbf{p}(A|\mathcal{C}):=\sum_{C\in\mathcal{C}}\mathbf{p}(A\cap C)\mathbf{1}_C<br>$$</p>
</li>
</ul>
<blockquote>
<p>Of course, we have $\mathbf{p}(A|\mathcal{C})=\mathbb{E}(\mathbf{1}_A|\mathcal{C})$</p>
</blockquote>
<p><strong>Sub-$\sigma$-algebra</strong>:</p>
<ul>
<li>Let $(X,\Sigma,\mathbf{p})$ be a probability space. By a <strong>sub-$\sigma$-algebra</strong> of $\Sigma$, we mean a subset of $\Sigma$ which is itself a $\sigma$-algebra.</li>
</ul>
<p><strong>Conditional Expectation on an Arbitrary $\sigma$-algebra, Conditional Probability on an Arbitrary $\sigma$-algebra</strong>:</p>
<ul>
<li><p>For any sub-$\sigma$-algebra $\Sigma_0$ of $\Sigma$, and any $x\in\mathcal{L}^1(X,\Sigma,\mathbf{p})$, the <strong>conditional expectation of $x$ given $\Sigma_0$</strong> is defined as <u>an extended real function</u> $\mathbb{E}(x|\Sigma_0)$ on $X$ which satisfies<br>$$<br>\mathbb{E}(x | \Sigma_0)\mbox{ is }\Sigma_0\mbox{-measurable}<br>$$</p>
</li>
<li><p>and<br>$$<br>\int_B\mathbb{E}(x|\Sigma_0)d\mathbf{p}=\int_Bxd\mathbf{p}\mbox{ for every }B\in\Sigma_0<br>$$</p>
</li>
<li><p>For any $y \in \mathcal{L}^0(X,\Sigma)$ we define the <strong>conditional expectation of $x$ given $y$,</strong> denoted $\mathbb{E}(x| y)$ as $\mathbb{E}(x | y) := \mathbb{E}(x |\sigma (y))$ </p>
</li>
<li><p>For any $A\in\Sigma$, we define <strong>the conditional probability of $A$ given $\Sigma_0$</strong>, denoted $\mathbf{p}(A|\Sigma_0)$ as <u>an extended real function</u> on $X$ that equals $\mathbb{E}(\mathbf{1}_A| \Sigma_0)$ or equivalently, that satisfies<br>$$<br>\mathbf{p}(x | \Sigma_0)\mbox{ is }\Sigma_0\mbox{-measurable}<br>$$</p>
</li>
<li><p>and<br>$$<br>\int_B\mathbf{p}(x|\Sigma_0)d\mathbf{p}=\mathbf{p}(A\cap B)\mbox{ for every }B\in\Sigma_0<br>$$</p>
</li>
</ul>
<p><strong>Conditional Density</strong>:</p>
<ul>
<li><p>Let $x$ and $y$ be two integrable random variables on a probability space $(X,\Sigma,\mathbf{p})$ and let $f$ be a joint density for $x$ and $y$ </p>
</li>
<li><p>The <strong>conditional density of $x$ given $y$</strong> is defined as<br>$$<br>f_{x|y}(s,t):=\left{\begin{matrix}\frac{f(s,t)}{f_y(t)}&amp;\mbox{if }f_y(t)&gt;0\0&amp;\mbox{otherwise}\end{matrix}\right.<br>$$</p>
</li>
<li><p>where $f_y$ is the marginal density of $y$.</p>
</li>
</ul>
<blockquote>
<p>We can show that<br>$$<br>\mathbb{E}(x|y)=<em>{a.s.}\int^\infty</em>{-\infty}sf_{x|y}(s,y(\cdot))ds<br>$$</p>
</blockquote>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Therorem 1.1</strong>:</p>
<ul>
<li>If $x$ is an integrable random variable on the probability space $(X,\Sigma,\mathbf{p})$, and $\Sigma_0$ is a sub-$\sigma$-algebra of $\Sigma$, then $\mathbb{E}(x|\Sigma_0)$ exists.</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:46:59.000Z" title="12/15/2020, 10:46:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/">1.1.H Stochastic Independence and Dependence</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/13%20Stochastic%20Independence/Independence-of-Random-Variables/">Independence of Random Variables</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Independence of Random Variables</strong>:</p>
<ul>
<li><p>For any positive integer $i$, let $Y_i$ be a metric space and $x_i$ a $Y_i$-valued random variable on a probability space $(X,\Sigma,\mathbf{p})$. </p>
</li>
<li><p>For any $m &gt; 1$, we say that $x_1,\dots,x_m$ are (stochastically) <strong>independent</strong> when $(x_1),\dots,(x_m)$ are independent, that is,<br>$$<br>\mathbf{p}\left(\bigcap_{i\in[m]}{x_i\in A_i}\right)=\prod_{i\in[m]}\mathbf{p}{x_i\in A_i}\mbox{ for every }A_i\in\mathcal{B}(Y_i),\ i=1,\dots,m<br>$$</p>
</li>
<li><p>and we denote this situation by writting $\coprod [x_1,\dots,x_m]$ </p>
</li>
<li><p>If $\coprod [x,x]$ for any $Y$-valued random variable $x$ on $(x,\Sigma,\mathbf{p})$, we say that $x$ is <strong>independent of itself</strong>.</p>
</li>
<li><p>More generally, if $\coprod [\sigma(x_1),\sigma(x_2),\dots]$ we say that $x_1,x_2,\dots$ are <strong>independent</strong> or $(x_m)$ is a <strong>sequence of independent of random variables</strong>, and write $\coprod [x_1,x_2,\dots]$ </p>
</li>
</ul>
<p><strong>Uncorrelated</strong>:</p>
<ul>
<li>Let $x$ and $y$ be two integrable random variables on a probability space $(X,\Sigma,\mathbf{p})$.</li>
<li>Clearly, $xy$ is also a random variable on $(X,\Sigma,\mathbf{p})$</li>
<li>We say that $x$ and $y$ are <strong>uncorrelated</strong> if $\mathbb{E}(xy) = \mathbb{E}(x)\mathbb{E}(y)$.</li>
</ul>
<p><strong>Independently and Identically Distributed Random Variables</strong>:</p>
<ul>
<li>Let $Y$ be a metric space, and $(x_m)$ a sequence of $Y$-valued random variables on a probability space $(X,\Sigma,\mathbf{p})$. </li>
<li>For any $m &gt; 1$, we say that $x_1,\dots, x_m$ are <strong>independently and identically distributed</strong>, or simply <strong>i.i.d.</strong>, if $\coprod [x_1,\dots,x_m]$ and $\mathbf{p}_{x_i} = \mathbf{p}_{x_j}$ for every $i,j\in[m]$.</li>
<li>More generally, we say that $x_1,x_2,\dots$ are <strong>i.i.d</strong>. (or that $(x_m)$ is a <strong>sequence of i.i.d. random variables</strong> when $\coprod [x_1,\dots,x_m]$ and $\mathbf{p}_{x_i} = \mathbf{p}_{x_j}$ for every postive integers $i$ and $j$.</li>
</ul>
<blockquote>
<p>If $Y=\mathbb{R}$, then $\mathbf{p}_{x_i} = \mathbf{p}_{x_j}$ implies they have the same distribution and distribution functions. </p>
<p>Take the normal distribution as an example, the $\mu$ and $\sigma$ should be the same for all i.i.d. random variables.</p>
</blockquote>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Proposition 2.1</strong>: </p>
<ul>
<li>Let $m$ be a positive integer, and $x_1,\dots,x_m$ integrable random variables on a probability space $(X,\Sigma,\mathbf{p})$. Then,<br>$$<br>\coprod [x_1,\dots,x_m]\mbox{ implies }\mathbb{E}\left(\prod_{i\in[m]}x_i\right)=\prod_{i\in[m]}\mathbb{E}(x_i)<br>$$</li>
</ul>
<blockquote>
<p>The expectation of the product of a finite number of independent random variables (each with finite expectation) equals the product of the expectations of these random variables. </p>
<p>In particular, any two independent random variables are uncorrelated.</p>
</blockquote>
<p><strong>Proposition 2.2</strong>: </p>
<ul>
<li>Let $m$ be a positive integer, and $x_1,\dots,x_m$ random variables on a probability space $(X,\Sigma, \mathbf{p})$. Then, $\coprod [x_1,\dots,x_m]$ iff<br>$$<br>F_{x_1,\dots,x_m}(a_1,\dots,a_m)=\prod_{i\in[m]}F_{x_i}(a_i)\mbox{ for every }(a_1,\dots,a_m)\in\mathbb{R}^m.<br>$$</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:45:59.000Z" title="12/15/2020, 10:45:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/">1.1.H Stochastic Independence and Dependence</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/13%20Stochastic%20Independence/Independence-of-Collection-of-Events/">Independence of Collection of Events</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Independence of Events</strong>:</p>
<ul>
<li><p>Let $(X,\Sigma,\mathbf{p})$ be a probability space. </p>
</li>
<li><p>The events $A,B\in\Sigma$ are said to be <strong>(stochastically) independent</strong> if $\mathbf{p}(A \cap B) = \mathbf{p}(A)\mathbf{p}(B)$.</p>
</li>
<li><p>If $A = B$ here, we say that $A$ is independent of itself.</p>
</li>
<li><p>In turn, a nonempty collection $\mathcal{A}\subseteq \Sigma$ is called <strong>independent</strong> ‚Äì we denote this by writing $\coprod \mathcal{A}$ ‚Äì if<br>$$<br>\mathbf{p}(\bigcap \mathcal{S})=\prod_{A\in\mathcal{S}}\mathbf{p}(A)<br>$$</p>
</li>
<li><p>for every nonempty finite subset $\mathcal{S}$ of $\mathcal{A}$.</p>
</li>
</ul>
<p><strong>Independence of Finitely Many Familites of Events</strong>:</p>
<ul>
<li><p>Let $(X,\Sigma,\mathbf{p})$ be a probability space and $m$ an integrer with $m&gt;1$. </p>
</li>
<li><p>The nonempty collection $\mathcal{A}_1,\cdots,\mathcal{A}_m\subseteq \Sigma$ are said to be <strong>(stochastically) independent</strong> ‚Äì we denote this by writing $\coprod [\mathcal{A}_1,\dots,\mathcal{A}_m]$ ‚Äì if<br>$$<br>\coprod {A_1,\dots,A_m}\mbox{ for every }(A_1,\dotsm,A_m)\in\mathcal{A}_1\times\cdots\times\mathcal{A}_m<br>$$</p>
</li>
</ul>
<blockquote>
<p>The definition of independence of events is a special case of that of independence of collections of events.</p>
</blockquote>
<p><strong>Independence of Infinitely Many Familites of Events</strong>:</p>
<ul>
<li>Let $(X,\Sigma,\mathbf{p})$ be a probability space, $I$ any (index) set with $|I|&gt;1$, and $\mathcal{A}_i$ a nonempty subset of $\Sigma$ for each $i\in I$. </li>
<li>We say that $\mathcal{A}_i$s are <strong>independent</strong> ‚Äì we denote this by writing $\coprod [\mathcal{A}<em>i, i\in I]$ ‚Äì if  $\coprod [\mathcal{A}</em>{i_1},\dots,\mathcal{A}_{i_m}]$ for every integrer with $m&gt;1$ and every distinct $i_1,\dots,i_m\in I$.</li>
<li>If $I=\mathbb{N}$ here, we write $\coprod[\mathcal{A}_1,\mathcal{A}_2,\dots]$ to denote $\coprod[\mathcal{A}_i:i\in I]$.</li>
</ul>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Proposition 1.1</strong>: </p>
<ul>
<li><p>Let $(X,\Sigma,\mathbf{p})$ be a probabilty space, and $m$ an integer with $m &gt; 1$.</p>
</li>
<li><p>If $\mathcal{A}<em>i\subseteq\Sigma$ contains $X$ for each $i\in[m]$, then $\coprod [\mathcal{A}_1,\dots,\mathcal{A}_m]$ iff<br>$$<br>\mathbf{p}\left(\bigcap</em>{i\in[m]}A_i\right)=\prod_{i\in[m]}\mathbf{p}(A_i)\mbox{ for every }(A_1,\dotsm,A_m)\in\mathcal{A}_1\times\cdots\times\mathcal{A}_m<br>$$</p>
</li>
</ul>
<p><strong>Proposition 1.2</strong>: </p>
<ul>
<li><p>Let $(X,\Sigma,\mathbf{p})$ be a probabilty space, and $m$ an integer with $m &gt; 1$.</p>
</li>
<li><p>If $\mathcal{A}_i\subseteq\Sigma$ contains $X$, and is closed under taking finite intersections, for each $i\in[m]$, then<br>$$<br>\coprod [\mathcal{A}_1,\dots,\mathcal{A}_m]\mbox{ implies }\coprod [\sigma(\mathcal{A}_1),\dots,\sigma(\mathcal{A}_m)]<br>$$</p>
</li>
</ul>
<p><strong>Proposition 1.3</strong>: </p>
<ul>
<li><p>Let $(X,\Sigma,\mathbf{p})$ be a probabilty space, $I$ any (index) set with $|I|&gt;1$, and $\mathcal{A}_i$ a nonempty subset of $\Sigma$ for each $i\in I$. </p>
</li>
<li><p>If $\mathcal{A}_i\subseteq\Sigma$ contains $X$, and is closed under taking finite intersections, for each $i\in[m]$, then<br>$$<br>\coprod[\mathcal{A}_i:i\in I]\mbox{ implies }\coprod[\sigma(\mathcal{A}_i):i\in I]<br>$$</p>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="hqin"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">hqin</p><p class="is-size-6 is-block">A Student in Economics</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Zhengzhou, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">50</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">16</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">5</p></a></div></div></nav></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-01-03T14:17:22.000Z">2021-01-03</time></p><p class="title"><a href="/2021/01/03/Mathematics/Dynamic%20Optimization/2%20The%20Calculus%20of%20Variations/Transversality-Conditions-for-Variable-Endpoint-Problems/">Transversality Conditions for Variable-Endpoint Problems</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-4-Dynamic-Optimization/">1.4 Dynamic Optimization</a> / <a href="/categories/1-Mathematics/1-4-Dynamic-Optimization/1-4-B-The-Calculus-of-Variations/">1.4.B The Calculus of Variations</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-01-03T14:17:22.000Z">2021-01-03</time></p><p class="title"><a href="/2021/01/03/Mathematics/Dynamic%20Optimization/2%20The%20Calculus%20of%20Variations/Second-Order-Conditions/">Second-Order Conditions</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-4-Dynamic-Optimization/">1.4 Dynamic Optimization</a> / <a href="/categories/1-Mathematics/1-4-Dynamic-Optimization/1-4-B-The-Calculus-of-Variations/">1.4.B The Calculus of Variations</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-01-03T14:17:21.000Z">2021-01-03</time></p><p class="title"><a href="/2021/01/03/Mathematics/Dynamic%20Optimization/2%20The%20Calculus%20of%20Variations/The-Fundamental-Problem-of-the-Calculus-of-Variations/">The Fundamental Problem of the Calculus of Variations</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-4-Dynamic-Optimization/">1.4 Dynamic Optimization</a> / <a href="/categories/1-Mathematics/1-4-Dynamic-Optimization/1-4-B-The-Calculus-of-Variations/">1.4.B The Calculus of Variations</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-01-02T14:17:12.000Z">2021-01-02</time></p><p class="title"><a href="/2021/01/02/Mathematics/Dynamic%20Optimization/1%20Preliminaries%20of%20Dynamic%20Optimization/The-Nature-of-Dynamic-Optimization/">The Nature of Dynamic Optimization</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-4-Dynamic-Optimization/">1.4 Dynamic Optimization</a> / <a href="/categories/1-Mathematics/1-4-Dynamic-Optimization/1-4-A-Preliminaries-of-Dynamic-Optimization/">1.4.A Preliminaries of Dynamic Optimization</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-24T14:52:59.000Z">2020-12-24</time></p><p class="title"><a href="/2020/12/24/Mathematics/Algebra/2%20Linear%20Algebra/Geometric-Linear-Algebra/">Geometric Linear Algebra</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-2-Algebra/">1.2 Algebra</a> / <a href="/categories/1-Mathematics/1-2-Algebra/1-2-B-Linear-Algebra/">1.2.B Linear Algebra</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">January 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/12/"><span class="level-start"><span class="level-item">December 2020</span></span><span class="level-end"><span class="level-item tag">24</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/11/"><span class="level-start"><span class="level-item">November 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/10/"><span class="level-start"><span class="level-item">October 2020</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/09/"><span class="level-start"><span class="level-item">September 2020</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li></ul></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://ygnmax.github.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Guangnan Yang</span></span><span class="level-right"><span class="level-item tag">ygnmax.github.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Abstract-Algebra/"><span class="tag">Abstract Algebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Control-Theory/"><span class="tag">Control Theory</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Algebra/"><span class="tag">Linear Algebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Measure-Theoretic-Probability/"><span class="tag">Measure Theoretic Probability</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Real-Analysis/"><span class="tag">Real Analysis</span><span class="tag">24</span></a></div></div></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/1-Mathematics/"><span class="level-start"><span class="level-item">1 Mathematics</span></span><span class="level-end"><span class="level-item tag">50</span></span></a><ul><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/"><span class="level-start"><span class="level-item">1.1 Analysis</span></span><span class="level-end"><span class="level-item tag">44</span></span></a><ul><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-A-Preliminaries-of-Real-Analysis/"><span class="level-start"><span class="level-item">1.1.A Preliminaries of Real Analysis</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-B-Metric-Spaces-and-Continuity/"><span class="level-start"><span class="level-item">1.1.B Metric Spaces and Continuity</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-C-Linear-Spaces-and-Convexity/"><span class="level-start"><span class="level-item">1.1.C Linear Spaces and Convexity</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-D-Metric-Linear-Spaces-and-Normed-Linear-Spaces/"><span class="level-start"><span class="level-item">1.1.D Metric Linear Spaces and Normed Linear Spaces</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-E-Probability-via-Measure-Theory/"><span class="level-start"><span class="level-item">1.1.E Probability via Measure Theory</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-F-Expectation-Lebesgue-Integral-and-Stieltjes-Integral/"><span class="level-start"><span class="level-item">1.1.F Expectation, Lebesgue Integral, and Stieltjes Integral</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-G-Weak-Convergence-and-Probability-Limit/"><span class="level-start"><span class="level-item">1.1.G Weak Convergence and Probability Limit</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/"><span class="level-start"><span class="level-item">1.1.H Stochastic Independence and Dependence</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-2-Algebra/"><span class="level-start"><span class="level-item">1.2 Algebra</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/1-Mathematics/1-2-Algebra/1-2-A-Abstract-Algebra/"><span class="level-start"><span class="level-item">1.2.A Abstract Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-2-Algebra/1-2-B-Linear-Algebra/"><span class="level-start"><span class="level-item">1.2.B Linear Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-4-Dynamic-Optimization/"><span class="level-start"><span class="level-item">1.4 Dynamic Optimization</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/1-Mathematics/1-4-Dynamic-Optimization/1-4-A-Preliminaries-of-Dynamic-Optimization/"><span class="level-start"><span class="level-item">1.4.A Preliminaries of Dynamic Optimization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-4-Dynamic-Optimization/1-4-B-The-Calculus-of-Variations/"><span class="level-start"><span class="level-item">1.4.B The Calculus of Variations</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">hqin</a><p class="is-size-7"><span>&copy; 2020 - 2021 hqin</span>¬†¬†</p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'folded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">√ó</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>