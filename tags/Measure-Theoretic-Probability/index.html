<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tag: Measure Theoretic Probability - hqin</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="hqin"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="hqin"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="hqin"><meta property="og:url" content="https://hqin-2020.github.io/"><meta property="og:site_name" content="hqin"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://hqin-2020.github.io/img/og_image.png"><meta property="article:author" content="hqin"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hqin-2020.github.io"},"headline":"hqin","image":["https://hqin-2020.github.io/img/og_image.png"],"author":{"@type":"Person","name":"hqin"},"description":""}</script><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="hqin" type="application/atom+xml">
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">hqin</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">Measure Theoretic Probability</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:50:59.000Z" title="12/15/2020, 10:50:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/">1.1.H Stochastic Independence and Dependence</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/15%20Stochastic%20Dependence/Propertities-of-Conditional-Expectation/">Propertities of Conditional Expectation</a></h1><div class="content"><h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Proposition 2.1</strong>: </p>
<ul>
<li><p>Let $x$ and $y$ be integrable random variables on a probability space $(X,\Sigma, \mathbf{p})$ and $\Sigma_0$ a sub-$\sigma$-algebra of $\Sigma$. Then, for every real number $\alpha$<br>$$<br>\mathbb{E}(\alpha x|\Sigma_0)=<em>{a.s.}\alpha\mathbb{E}(x|\Sigma_0)<br>$$<br>and<br>$$<br>\mathbb{E}(x+y|\Sigma_0)=</em>{a.s.}\mathbb{E}(x|\Sigma_0)+\mathbb{E}(y|\Sigma_0)<br>$$</p>
</li>
<li><p>Moreover,<br>$$<br>x=_{a.s.}y\mbox{ implies }\mathbb{E}(x|\Sigma_0)+\mathbb{E}(y|\Sigma_0)<br>$$</p>
</li>
</ul>
<p><strong>Proposition 2.2</strong>: </p>
<ul>
<li>Let $x$ and $y$ be integrable random variables on a probability space $(X,\Sigma, \mathbf{p})$ and $\Sigma_0$ a sub-$\sigma$-algebra of $\Sigma$. Then,<br>$$<br>\mathbb{E}(\mathbb{E}(x|\Sigma_0))=\mathbb{E}(x)<br>$$<br>And if $\Sigma_1$ is another sub-$\sigma$-algebra of $\Sigma$, then<br>$$<br>\Sigma_0\subseteq \Sigma_1\mbox{ implies }\mathbb{E}(\mathbb{E}(x|\Sigma_1)|\Sigma_0)=\mathbb{E}(x|\Sigma_0)<br>$$</li>
</ul>
<p><strong>Proposition 2.4</strong>:</p>
<ul>
<li><p>Let $x$ and $y$ be integrable random variables on a probability space $(X,\Sigma, \mathbf{p})$ and $\Sigma_0$ a sub-$\sigma$-algebra of $\Sigma$.</p>
</li>
<li><p>If $y\in\mathcal{L}^0(X,\Sigma_0)$ and $\mathbb{E}(|xy|)&lt;\infty$,then<br>$$<br>\mathbb{E}(xy|\Sigma_0)=_{a.s.}y\mathbb{E}(x|\Sigma_0)<br>$$</p>
</li>
</ul>
<p><strong>The Conditional Monotone Convergence Theorem</strong>: </p>
<ul>
<li><p>Let $x, x_1,x_2,\dots$ be nonnegative integrable random variables on a probability space $(X,\Sigma, \mathbf{p})$ such that $x_m\nearrow_{a.s.} x$</p>
</li>
<li><p>If $\Sigma_0$ is a sub-$\sigma$-algebra of $\Sigma$, then<br>$$<br>\mathbb{E}(x_m|\Sigma_0)\nearrow_{a.s.}\mathbb{E}(x|\Sigma_0)<br>$$</p>
</li>
</ul>
<p><strong>The Conditional Dominated Convergence Theorem</strong>: </p>
<ul>
<li><p>Let $x, y,x_1,x_2,\dots$ be nonnegative integrable random variables on a probability space $(X,\Sigma, \mathbf{p})$ such that $x_m\leq_{a.s.} x$ for each $m$</p>
</li>
<li><p>If $\Sigma_0$ is a sub-$\sigma$-algebra of $\Sigma$, then<br>$$<br>\mathbb{E}(x_m|\Sigma_0)\to_{a.s.}\mathbb{E}(x|\Sigma_0)<br>$$</p>
</li>
</ul>
<p><strong>The Conditional Jensen‚Äôs Inequality</strong>:</p>
<ul>
<li>Let $x$ be an integrable random variable on a probability space $(X,\Sigma, \mathbf{p})$, and $\Sigma_0$ a sub-$\sigma$-algebra of $\Sigma$. If $\varphi$ is a concave self-map on $\mathbb{R}$ such that $\mathbb{E}(|\varphi\circ x|) &lt;\infty$, then<br>$$<br>\varphi(\mathbb{E}(x|\Sigma_0))\geq_{a.s.}\mathbb{E}(\varphi\circ x|\Sigma_0)<br>$$</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:49:59.000Z" title="12/15/2020, 10:49:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/">1.1.H Stochastic Independence and Dependence</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/15%20Stochastic%20Dependence/Conditional-Expectation/">Conditional Expectation</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Conditional Expectation on a Known Event</strong>:</p>
<ul>
<li><p>Let $x$ be an integrable random variable on a probability space $(X,\Sigma,\mathbf{p})$ </p>
</li>
<li><p>That is, $x\in\mathcal{L}^0(X,\Sigma$) and $\mathbb{E}(|x|) &lt; \infty$, or put differently, $x\in\mathcal{L}^1(X,\Sigma,\mathbf{p})$</p>
</li>
<li><p>For any event $C\in\Sigma$ with $\mathbf{p}(C) &gt; 0$, the <strong>conditional expectation</strong> <strong>of $x$ given</strong> $C$ is defined as<br>$$<br>\mathbb{E}(x|C):=\frac{1}{\mathbf{p}(C)}\int_Cxd\mathbf{p}<br>$$</p>
</li>
</ul>
<blockquote>
<p>When it is known that the event $C$ has occurred, one is less uncertain about the outcome of the underlying experiment. </p>
<p>The relevant probability space in this case can be thought of as $(C,\Sigma\cap C,\mathbf{q})$, where $\Sigma\cap C := {A\cap C:A\in\Sigma}$ and<br>$$<br>\mathbf{q}:=\frac{1}{\mathbf{p}(C)}\mathbf{p}|_{\Sigma\cap C}<br>$$<br>Consequently, we compute the conditional expectation of $x$ given $C$ simply as the expectation of $x|_C$ on this space.</p>
</blockquote>
<p><strong>Conditional Probability on a Known Event</strong>:</p>
<ul>
<li>The <strong>conditional probability</strong> of an event $A\in\Sigma$ given $C$ is $\mathbf{p}(A|C) := \frac{\mathbf{p}(A \cap C)}{\mathbf{p}(C)}$</li>
</ul>
<blockquote>
<p>Just as the probability of an event is the expectation of the indicator function of that event, the conditional probability of an event is the conditional expectation of the indicator function of that event:<br>$$<br>\mathbb{p}(A|C)=\frac{\mathbb{p}(A\cap C)}{\mathbf{p}(C)}\mathbb{E}(\mathbf{1}_A|C)<br>$$<br>Note that these notions apply only when we know that an event has already occurred.</p>
</blockquote>
<p><strong>Countable (finite) $\Sigma$-decomposition</strong>:</p>
<ul>
<li>By a <strong>countable (finite) $\Sigma$-decomposition</strong> of $X$ we mean a countable (finite) partition $\mathcal{C}$ of $X$ such that $\mathcal{C}\subseteq \Sigma$ and $\mathbf{p}(C) &gt; 0$ for all $C\in\mathcal{C}$.</li>
</ul>
<p><strong>Conditional Expectation on a Countable Decomposition</strong>:</p>
<ul>
<li><p>We define the <strong>conditional expectation of $x$ given $\mathcal{C}$</strong> as the <u>discrete random variable</u> $\mathbb{E}(x|{\mathcal{C}}) : X \to \mathbb{R}$ with<br>$$<br>\mathbb{E}(x|\mathcal{C})(\omega):=\mathbb{E}(x|C_\omega)<br>$$<br>or<br>$$<br>\int_{C_\omega}\mathbb{E}(x|\mathcal{C})d\mathbf{p}=\int_{C_\omega}xd\mathbf{p}\mbox{ for every }\omega\in X<br>$$</p>
</li>
<li><p>where $C_\omega$ is the member of $\mathcal{C}$ that contains the outcome $\omega$.</p>
</li>
<li><p>More compactly, we may write<br>$$<br>\mathbb{E}(x|\mathcal{C}):=\sum_{C\in\mathcal{C}}\mathbb{E}(x|C)\mathbf{1}_C<br>$$</p>
</li>
</ul>
<blockquote>
<p>Given that we will observe which member of $\mathcal{C}$ has occurred once the experiment is performed, we then calculate the conditional expectation.</p>
<p>A gambler, for instance, would like to have a strategy which is contingent on what will happen through the sequence of games she will repeatedly participate in.</p>
</blockquote>
<p><strong>Conditional Probability on a Countable Decomposition</strong>:</p>
<ul>
<li><p>The <strong>conditional probability of an event $A$ in $\Sigma$ given $\mathcal{C}$</strong> is similarly defined as the <u>discrete random variable</u> $\mathbf{p}(A|\mathcal{C}) : X\to\mathbb{R}$ with<br>$$<br>\mathbf{p}(A|\mathcal{C}) (\omega):=\frac{\mathbf{p}(A\cap C_\omega)}{\mathbf{p}(C_\omega)}<br>$$</p>
</li>
<li><p>Or equivalently,<br>$$<br>\mathbf{p}(A|\mathcal{C}):=\sum_{C\in\mathcal{C}}\mathbf{p}(A\cap C)\mathbf{1}_C<br>$$</p>
</li>
</ul>
<blockquote>
<p>Of course, we have $\mathbf{p}(A|\mathcal{C})=\mathbb{E}(\mathbf{1}_A|\mathcal{C})$</p>
</blockquote>
<p><strong>Sub-$\sigma$-algebra</strong>:</p>
<ul>
<li>Let $(X,\Sigma,\mathbf{p})$ be a probability space. By a <strong>sub-$\sigma$-algebra</strong> of $\Sigma$, we mean a subset of $\Sigma$ which is itself a $\sigma$-algebra.</li>
</ul>
<p><strong>Conditional Expectation on an Arbitrary $\sigma$-algebra, Conditional Probability on an Arbitrary $\sigma$-algebra</strong>:</p>
<ul>
<li><p>For any sub-$\sigma$-algebra $\Sigma_0$ of $\Sigma$, and any $x\in\mathcal{L}^1(X,\Sigma,\mathbf{p})$, the <strong>conditional expectation of $x$ given $\Sigma_0$</strong> is defined as <u>an extended real function</u> $\mathbb{E}(x|\Sigma_0)$ on $X$ which satisfies<br>$$<br>\mathbb{E}(x | \Sigma_0)\mbox{ is }\Sigma_0\mbox{-measurable}<br>$$</p>
</li>
<li><p>and<br>$$<br>\int_B\mathbb{E}(x|\Sigma_0)d\mathbf{p}=\int_Bxd\mathbf{p}\mbox{ for every }B\in\Sigma_0<br>$$</p>
</li>
<li><p>For any $y \in \mathcal{L}^0(X,\Sigma)$ we define the <strong>conditional expectation of $x$ given $y$,</strong> denoted $\mathbb{E}(x| y)$ as $\mathbb{E}(x | y) := \mathbb{E}(x |\sigma (y))$ </p>
</li>
<li><p>For any $A\in\Sigma$, we define <strong>the conditional probability of $A$ given $\Sigma_0$</strong>, denoted $\mathbf{p}(A|\Sigma_0)$ as <u>an extended real function</u> on $X$ that equals $\mathbb{E}(\mathbf{1}_A| \Sigma_0)$ or equivalently, that satisfies<br>$$<br>\mathbf{p}(x | \Sigma_0)\mbox{ is }\Sigma_0\mbox{-measurable}<br>$$</p>
</li>
<li><p>and<br>$$<br>\int_B\mathbf{p}(x|\Sigma_0)d\mathbf{p}=\mathbf{p}(A\cap B)\mbox{ for every }B\in\Sigma_0<br>$$</p>
</li>
</ul>
<p><strong>Conditional Density</strong>:</p>
<ul>
<li><p>Let $x$ and $y$ be two integrable random variables on a probability space $(X,\Sigma,\mathbf{p})$ and let $f$ be a joint density for $x$ and $y$ </p>
</li>
<li><p>The <strong>conditional density of $x$ given $y$</strong> is defined as<br>$$<br>f_{x|y}(s,t):=\left{\begin{matrix}\frac{f(s,t)}{f_y(t)}&amp;\mbox{if }f_y(t)&gt;0\0&amp;\mbox{otherwise}\end{matrix}\right.<br>$$</p>
</li>
<li><p>where $f_y$ is the marginal density of $y$.</p>
</li>
</ul>
<blockquote>
<p>We can show that<br>$$<br>\mathbb{E}(x|y)=<em>{a.s.}\int^\infty</em>{-\infty}sf_{x|y}(s,y(\cdot))ds<br>$$</p>
</blockquote>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Therorem 1.1</strong>:</p>
<ul>
<li>If $x$ is an integrable random variable on the probability space $(X,\Sigma,\mathbf{p})$, and $\Sigma_0$ is a sub-$\sigma$-algebra of $\Sigma$, then $\mathbb{E}(x|\Sigma_0)$ exists.</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:48:59.000Z" title="12/15/2020, 10:48:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-G-Weak-Convergence-and-Probability-Limit/">1.1.G Weak Convergence and Probability Limit</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/14%20A%20Primer%20on%20Probability%20Limit%20Theorems/Law-of-Large-Numbers/">Law of Large Numbers</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Random Sample, Statistic</strong>:</p>
<ul>
<li>Let $x$ be a random variable on a probability space $(X,\Sigma,\mathbf{p})$. </li>
<li>A <strong>random sample</strong> for $x$ is a finite collection $x_1,\dots,x_m$ of i.i.d. random variables on $(X,\Sigma,\mathbf{p})$ such that $x_1 =_{a.s.} x$. </li>
<li>A (real-valued) <strong>statistic</strong> based on such a random sample is a <u>random variable</u> of the form $\varphi(x_1,\dots, x_m)$, where $\varphi$ is <u>a Borel measurable real function</u> on $\mathbb{R}\cup \mathbb{R}^2\cdots $ </li>
<li>Notice that $\varphi$ can accomodate any random sample regardless of its size.</li>
</ul>
<p><strong>Unbiased estimator</strong>:</p>
<ul>
<li><p>The statistics based on a random sample are used to derive inferences about the characteristics of the random variable of interest. We would then surely wish them to satisfy certain properties. </p>
</li>
<li><p>For instance, a desirable property in this regard is that of unbiasedness: We say that a statistic $\varphi(x_1,\dots,x_m)$ based on the random sample $x_1,\dots, x_m$ is an <strong>unbiased estimator</strong> of $x$ if<br>$$<br>\mathbb{E}(\varphi(x_1,\dots,x_m))=\theta_x<br>$$</p>
</li>
<li><p>where $\theta_x$ is a characteristic of $x$, such as its mean or another moment. </p>
</li>
</ul>
<blockquote>
<p>The property of unbiasedness is well-defined for any random sample, regardless of its size. As such, it is said to be a small-sample property. </p>
</blockquote>
<p><strong>Consistent estimator, Strongly consistent esitimator</strong>:</p>
<ul>
<li>We say that a statistic $\varphi(x_1,\dots,x_m)$ based on the random sample $x_1,\dots, x_m$ is a <strong>consistent estimator</strong> of a characteristic $\theta_x$ of $x$ if<br>$$<br>\mathbf{p}\mbox{-}\lim\varphi(x_1,\dots,x_m)=\theta_x<br>$$<br>And that it is a <strong>strongly consistent estimator</strong> of $\theta_x$ if<br>$$<br>\mathbf{p}{\varphi(x_1,\dots,x_m)\to\theta_x}=1<br>$$</li>
</ul>
<blockquote>
<p>A large-sample property of a statistic would instead be based on the limiting properties of this statistic as the sample size gets large. </p>
<p>Of particular interest in this regard are the properties of consistency.</p>
</blockquote>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>The Weak Law of Large Numbers</strong>: (Chebyshev) </p>
<ul>
<li>Let $(x_m)$ be a sequence of independent random variables on a probability space $(X,\Sigma, \mathbf{p})$ with $\mathbb{E}(x_1) = \mathbb{E}(x_2) = \cdots\in \mathbb{R}$ and $\sup \mathbb{V}(x_m) &lt; \infty$. Then,<br>$$<br>\mathbb{E}\left(\left|\frac{1}{m}\sum_{i\in[m]}x_i-\mathbb{E}(x_1)\right|\right)\to 0\mbox{ and }\frac{1}{m}\sum_{i\in[m]}x_i\to\mathbb{E}(x_1)\mbox{ in probability}<br>$$</li>
</ul>
<p><strong>Corollary 2.1</strong>: </p>
<ul>
<li>Let $(x_m)$ be a sequence of i.i.d. random variables with finite expectation and variance. Then,<br>$$<br>\frac{1}{m}\sum_{i\in[m]}x_i\to\mathbb{E}(x_1)\mbox{ in probability}<br>$$</li>
</ul>
<p><strong>Khinchine‚Äôs Weak Law of Large Numbers</strong>:</p>
<ul>
<li>Let $(x_m)$ be a sequence of i.i.d. random variables with finite expectation. Then,</li>
</ul>
<p>$$<br>\frac{1}{m}\sum_{i\in[m]}x_i\to\mathbb{E}(x_1)\mbox{ in probability}<br>$$</p>
<p><strong>Markov‚Äôs Weak Law of Large Numbers</strong>: </p>
<ul>
<li><p>Let $(x_m)$ be a sequence of uncorrelated random variables on a probability space $(X,\Sigma,\mathbf{p})$ such that $\sup\mathbb{E}(x_m) &lt; 1$ and $\sup \mathbb{V}_(x_m) &lt; 1$.</p>
</li>
<li><p>Assume further that<br>$$<br>\lim\frac{1}{m}\sum_{i\in[m]}\mathbb{E}(x_i)\in\mathbb{R}\mbox{  and }\frac{1}{m^2}\sum_{i\in[m]}\mathbb{V}(x_i)\to0<br>$$</p>
</li>
<li><p>Then<br>$$<br>\frac{1}{m}\sum_{i\in[m]}x_i\to\lim\frac{1}{m}\sum_{i\in[m]}\mathbb{E}(x_i)\mbox{ in probability}<br>$$</p>
</li>
</ul>
<p><strong>The Strong Law of Large Numbers</strong>: (Kolmogorov) </p>
<ul>
<li>For any sequence $(x_m)$ of integrable i.i.d. random variables, we have<br>$$<br>\frac{1}{m}\sum_{i\in[m]}x_i\to_{a.s.}\mathbb{E}(x_1)<br>$$</li>
</ul>
<p><strong>Corollary 2.2</strong>: (Kolmogorov) </p>
<ul>
<li>For any sequence $(x_m)$ of integrable i.i.d. random variables such that $\mathbb{E}(x_1)\in{-\infty,\infty}$, we have<br>$$<br>\frac{1}{m}\sum_{i\in[m]}x_i\to_{a.s.}\mathbb{E}(x_1)<br>$$</li>
</ul>
<h2 id="Examples-and-Exercises"><a href="#Examples-and-Exercises" class="headerlink" title="Examples and Exercises"></a>Examples and Exercises</h2><p><strong>Sample Mean, Sample Variance</strong>:</p>
<ul>
<li><p>For a random sample with a finite collection $a_1,\dots,a_m$ of i.i.d. random variables on $(X,\Sigma,\mathbf{p})$ such that $a_1 =_{a.s.} a$. </p>
</li>
<li><p>If<br>$$<br>\varphi(a_1,\dots,a_m):=\frac{1}{m}\sum_{i\in[m]}a_i<br>$$<br>Then $\varphi(a_1,\dots,a_m)$ corresponds to the statistic of the sample mean</p>
</li>
<li><p>If<br>$$<br>\varphi(a_1,\dots,a_m):=\frac{1}{m}\sum_{i\in[m]}\left(a_i-\frac{1}{m}\sum_{i\in[m]}a_i\right)^2<br>$$<br>Then $\varphi(a_1,\dots,a_m)$ corresponds to the statistic of the sample variance.</p>
</li>
<li><p>Sample mean is an unbiased estimator of $\mathbb{E}(x)$, for any postive integer $m$.<br>$$<br>\mathbb{E}\left(\frac{1}{m}\sum_{i\in[m]}x_i\right)=\frac{1}{m}\sum_{i\in[m]}\mathbb<a href="x_i">E</a>=\mathbb{E}(x)<br>$$<br>as $\mathbb{E}(x_i) = \mathbb{E}(x)$ for each $i$.</p>
</li>
<li><p>By contrast, the sample variance is not an unbiased estimator of $\mathbb{V}(x)$.</p>
</li>
</ul>
<p><strong>Example 2.2</strong>:</p>
<ul>
<li><p>The sample mean is a strongly consistent estimator of $\mathbb{E}(x)$ provided that $\mathbb{E}(x)$ is finite. This is the same thing as saying that<br>$$<br>\frac{1}{m}\sum_{i\in[m]}x_i\to_{a.s.}\mathbb{E}(x)<br>$$</p>
</li>
<li><p>when $\mathbb{E}(x)$ is finite. </p>
</li>
</ul>
<p><strong>Example 2.3</strong>:</p>
<ul>
<li>The sample variance is a strongly consistent estimator of $\mathbb{V}(x)$ provided that both $\mathbb{E}(x)$ and $\mathbb{E}(x^2)$ are finite. This is the same thing as saying that<br>$$<br>\frac{1}{m}\sum_{i\in[m]}\left(x_i-\frac{1}{m}\sum_{i\in[m]}x_i\right)^2\to_{a.s.}\mathbb{V}(x)<br>$$</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:47:59.000Z" title="12/15/2020, 10:47:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-G-Weak-Convergence-and-Probability-Limit/">1.1.G Weak Convergence and Probability Limit</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/14%20A%20Primer%20on%20Probability%20Limit%20Theorems/Preliminaries-of-Probability-Limit-Theorems/">Preliminaries of Probability Limit Theorems</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Converge in Probability</strong>:</p>
<ul>
<li><p>Let $Y$ be a separable metric space, and $x,x_1,x_2,\dots$ be $Y$-valued random variables on a probability space $(X,\Sigma,\mathbf{p})$. </p>
</li>
<li><p>We say that $(x_m)$ <strong>converges to $x$ in probability</strong>, and write $x_m\to x$ in probability, or $\mathbf{p}$-$\lim x_m = x$ if<br>$$<br>\mathbf{p}{d_Y(x_m,x)&gt;\varepsilon}\to 0 \mbox{ for every }\varepsilon&gt;0<br>$$</p>
</li>
<li><p>That is, $x_m \to x$ in probability iff, for every positive real numbers $\varepsilon$ and $\delta$ there exists a positive integer $M$ such that<br>$$<br>\mathbf{p}{d_Y(x_m,x)&gt;\varepsilon}&lt;\delta \mbox{ for all }m&gt;M<br>$$</p>
</li>
</ul>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Proposition 1.1</strong>Ôºö</p>
<ul>
<li>Let $Y$ be a separable metric space, and $x,x_1,x_2,\dots$ be $Y$-valued random variables on a probability space $(X,\Sigma,\mathbf{p})$. </li>
<li>If $(x_m)$ converges to $x$ in probability, then $x_m\stackrel{D}\to x$.</li>
</ul>
<p><strong>Proposition 1.2</strong>: (Kolmogorov) </p>
<ul>
<li>Let $Y$ be a separable metric space, and $x,x_1,x_2,\dots$ be $Y$-valued random variables on a probability space $(X,\Sigma,\mathbf{p})$. </li>
<li>If $x_m\to_{a.s.}x$, then $(x_m)$ converges to $x$ in probability.</li>
</ul>
<blockquote>
<p>$$<br>\mbox{almost sure convergence}\Longrightarrow\mbox{convergence in probability}\Longrightarrow\mbox{convergence in distribution}<br>$$</p>
</blockquote>
<p><strong>Theorem 3.8</strong>:</p>
<ul>
<li>Let $Y$ be a separable metric space</li>
<li>For any given real number $p\geq1$, let $x, x_1,x_2,\dots$ be $Y$-valued random variables on $\mathcal{L}^p(X,\Sigma,\mathbf{p})$</li>
<li>If $(x_m)$ is $\mathcal{L}^p$-convergent, then $(x_m)$ <strong>converges to $x$ in probability</strong>.</li>
</ul>
<blockquote>
<p>$$<br>\mathcal{L}^p\mbox{-convergence}\Longrightarrow\mbox{convergence in probability}\Longrightarrow\mbox{convergence in distribution}<br>$$</p>
</blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:46:59.000Z" title="12/15/2020, 10:46:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/">1.1.H Stochastic Independence and Dependence</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/13%20Stochastic%20Independence/Independence-of-Random-Variables/">Independence of Random Variables</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Independence of Random Variables</strong>:</p>
<ul>
<li><p>For any positive integer $i$, let $Y_i$ be a metric space and $x_i$ a $Y_i$-valued random variable on a probability space $(X,\Sigma,\mathbf{p})$. </p>
</li>
<li><p>For any $m &gt; 1$, we say that $x_1,\dots,x_m$ are (stochastically) <strong>independent</strong> when $(x_1),\dots,(x_m)$ are independent, that is,<br>$$<br>\mathbf{p}\left(\bigcap_{i\in[m]}{x_i\in A_i}\right)=\prod_{i\in[m]}\mathbf{p}{x_i\in A_i}\mbox{ for every }A_i\in\mathcal{B}(Y_i),\ i=1,\dots,m<br>$$</p>
</li>
<li><p>and we denote this situation by writting $\coprod [x_1,\dots,x_m]$ </p>
</li>
<li><p>If $\coprod [x,x]$ for any $Y$-valued random variable $x$ on $(x,\Sigma,\mathbf{p})$, we say that $x$ is <strong>independent of itself</strong>.</p>
</li>
<li><p>More generally, if $\coprod [\sigma(x_1),\sigma(x_2),\dots]$ we say that $x_1,x_2,\dots$ are <strong>independent</strong> or $(x_m)$ is a <strong>sequence of independent of random variables</strong>, and write $\coprod [x_1,x_2,\dots]$ </p>
</li>
</ul>
<p><strong>Uncorrelated</strong>:</p>
<ul>
<li>Let $x$ and $y$ be two integrable random variables on a probability space $(X,\Sigma,\mathbf{p})$.</li>
<li>Clearly, $xy$ is also a random variable on $(X,\Sigma,\mathbf{p})$</li>
<li>We say that $x$ and $y$ are <strong>uncorrelated</strong> if $\mathbb{E}(xy) = \mathbb{E}(x)\mathbb{E}(y)$.</li>
</ul>
<p><strong>Independently and Identically Distributed Random Variables</strong>:</p>
<ul>
<li>Let $Y$ be a metric space, and $(x_m)$ a sequence of $Y$-valued random variables on a probability space $(X,\Sigma,\mathbf{p})$. </li>
<li>For any $m &gt; 1$, we say that $x_1,\dots, x_m$ are <strong>independently and identically distributed</strong>, or simply <strong>i.i.d.</strong>, if $\coprod [x_1,\dots,x_m]$ and $\mathbf{p}_{x_i} = \mathbf{p}_{x_j}$ for every $i,j\in[m]$.</li>
<li>More generally, we say that $x_1,x_2,\dots$ are <strong>i.i.d</strong>. (or that $(x_m)$ is a <strong>sequence of i.i.d. random variables</strong> when $\coprod [x_1,\dots,x_m]$ and $\mathbf{p}_{x_i} = \mathbf{p}_{x_j}$ for every postive integers $i$ and $j$.</li>
</ul>
<blockquote>
<p>If $Y=\mathbb{R}$, then $\mathbf{p}_{x_i} = \mathbf{p}_{x_j}$ implies they have the same distribution and distribution functions. </p>
<p>Take the normal distribution as an example, the $\mu$ and $\sigma$ should be the same for all i.i.d. random variables.</p>
</blockquote>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Proposition 2.1</strong>: </p>
<ul>
<li>Let $m$ be a positive integer, and $x_1,\dots,x_m$ integrable random variables on a probability space $(X,\Sigma,\mathbf{p})$. Then,<br>$$<br>\coprod [x_1,\dots,x_m]\mbox{ implies }\mathbb{E}\left(\prod_{i\in[m]}x_i\right)=\prod_{i\in[m]}\mathbb{E}(x_i)<br>$$</li>
</ul>
<blockquote>
<p>The expectation of the product of a finite number of independent random variables (each with finite expectation) equals the product of the expectations of these random variables. </p>
<p>In particular, any two independent random variables are uncorrelated.</p>
</blockquote>
<p><strong>Proposition 2.2</strong>: </p>
<ul>
<li>Let $m$ be a positive integer, and $x_1,\dots,x_m$ random variables on a probability space $(X,\Sigma, \mathbf{p})$. Then, $\coprod [x_1,\dots,x_m]$ iff<br>$$<br>F_{x_1,\dots,x_m}(a_1,\dots,a_m)=\prod_{i\in[m]}F_{x_i}(a_i)\mbox{ for every }(a_1,\dots,a_m)\in\mathbb{R}^m.<br>$$</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:45:59.000Z" title="12/15/2020, 10:45:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/">1.1.H Stochastic Independence and Dependence</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/13%20Stochastic%20Independence/Independence-of-Collection-of-Events/">Independence of Collection of Events</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Independence of Events</strong>:</p>
<ul>
<li><p>Let $(X,\Sigma,\mathbf{p})$ be a probability space. </p>
</li>
<li><p>The events $A,B\in\Sigma$ are said to be <strong>(stochastically) independent</strong> if $\mathbf{p}(A \cap B) = \mathbf{p}(A)\mathbf{p}(B)$.</p>
</li>
<li><p>If $A = B$ here, we say that $A$ is independent of itself.</p>
</li>
<li><p>In turn, a nonempty collection $\mathcal{A}\subseteq \Sigma$ is called <strong>independent</strong> ‚Äì we denote this by writing $\coprod \mathcal{A}$ ‚Äì if<br>$$<br>\mathbf{p}(\bigcap \mathcal{S})=\prod_{A\in\mathcal{S}}\mathbf{p}(A)<br>$$</p>
</li>
<li><p>for every nonempty finite subset $\mathcal{S}$ of $\mathcal{A}$.</p>
</li>
</ul>
<p><strong>Independence of Finitely Many Familites of Events</strong>:</p>
<ul>
<li><p>Let $(X,\Sigma,\mathbf{p})$ be a probability space and $m$ an integrer with $m&gt;1$. </p>
</li>
<li><p>The nonempty collection $\mathcal{A}_1,\cdots,\mathcal{A}_m\subseteq \Sigma$ are said to be <strong>(stochastically) independent</strong> ‚Äì we denote this by writing $\coprod [\mathcal{A}_1,\dots,\mathcal{A}_m]$ ‚Äì if<br>$$<br>\coprod {A_1,\dots,A_m}\mbox{ for every }(A_1,\dotsm,A_m)\in\mathcal{A}_1\times\cdots\times\mathcal{A}_m<br>$$</p>
</li>
</ul>
<blockquote>
<p>The definition of independence of events is a special case of that of independence of collections of events.</p>
</blockquote>
<p><strong>Independence of Infinitely Many Familites of Events</strong>:</p>
<ul>
<li>Let $(X,\Sigma,\mathbf{p})$ be a probability space, $I$ any (index) set with $|I|&gt;1$, and $\mathcal{A}_i$ a nonempty subset of $\Sigma$ for each $i\in I$. </li>
<li>We say that $\mathcal{A}_i$s are <strong>independent</strong> ‚Äì we denote this by writing $\coprod [\mathcal{A}<em>i, i\in I]$ ‚Äì if  $\coprod [\mathcal{A}</em>{i_1},\dots,\mathcal{A}_{i_m}]$ for every integrer with $m&gt;1$ and every distinct $i_1,\dots,i_m\in I$.</li>
<li>If $I=\mathbb{N}$ here, we write $\coprod[\mathcal{A}_1,\mathcal{A}_2,\dots]$ to denote $\coprod[\mathcal{A}_i:i\in I]$.</li>
</ul>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Proposition 1.1</strong>: </p>
<ul>
<li><p>Let $(X,\Sigma,\mathbf{p})$ be a probabilty space, and $m$ an integer with $m &gt; 1$.</p>
</li>
<li><p>If $\mathcal{A}<em>i\subseteq\Sigma$ contains $X$ for each $i\in[m]$, then $\coprod [\mathcal{A}_1,\dots,\mathcal{A}_m]$ iff<br>$$<br>\mathbf{p}\left(\bigcap</em>{i\in[m]}A_i\right)=\prod_{i\in[m]}\mathbf{p}(A_i)\mbox{ for every }(A_1,\dotsm,A_m)\in\mathcal{A}_1\times\cdots\times\mathcal{A}_m<br>$$</p>
</li>
</ul>
<p><strong>Proposition 1.2</strong>: </p>
<ul>
<li><p>Let $(X,\Sigma,\mathbf{p})$ be a probabilty space, and $m$ an integer with $m &gt; 1$.</p>
</li>
<li><p>If $\mathcal{A}_i\subseteq\Sigma$ contains $X$, and is closed under taking finite intersections, for each $i\in[m]$, then<br>$$<br>\coprod [\mathcal{A}_1,\dots,\mathcal{A}_m]\mbox{ implies }\coprod [\sigma(\mathcal{A}_1),\dots,\sigma(\mathcal{A}_m)]<br>$$</p>
</li>
</ul>
<p><strong>Proposition 1.3</strong>: </p>
<ul>
<li><p>Let $(X,\Sigma,\mathbf{p})$ be a probabilty space, $I$ any (index) set with $|I|&gt;1$, and $\mathcal{A}_i$ a nonempty subset of $\Sigma$ for each $i\in I$. </p>
</li>
<li><p>If $\mathcal{A}_i\subseteq\Sigma$ contains $X$, and is closed under taking finite intersections, for each $i\in[m]$, then<br>$$<br>\coprod[\mathcal{A}_i:i\in I]\mbox{ implies }\coprod[\sigma(\mathcal{A}_i):i\in I]<br>$$</p>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:44:59.000Z" title="12/15/2020, 10:44:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-G-Weak-Convergence-and-Probability-Limit/">1.1.G Weak Convergence and Probability Limit</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/12%20Weak%20Convergence/Convergence-of-Random-Variables/">Convergence of Random Variables</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Converge in distribution</strong>: </p>
<ul>
<li>Let $Y$ be a metric space. </li>
<li>For any sequence of $Y $-valued random variables $(x_m)$ and a $Y $-valued random variable $x$, we say that $x_m$ <strong>converges to $x$ in distribution</strong>, denoted $x_m\stackrel{D}\to x$, if $\mathbf{p}<em>{x_m}\stackrel{w}{\to} \mathbf{p}_x$, where $\mathbf{p}</em>{x_m}$ and $\mathbf{p}_x$ are the distributions of $x_m$ and $x$, respectively, $m = 1,2,\cdots$.</li>
</ul>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Proposition 2.1</strong>: </p>
<ul>
<li>Let $Y$ be a metric space. </li>
<li>For any $Y $-valued random variables $x, x_1, x_2,\cdots$, we have $x_m \stackrel{D}\to x$ iff,</li>
</ul>
<p>$$<br>\mathbb{E}(\varphi\circ x_m)\to \mathbb{E}(\phi\circ x)\ \mbox{ for every } \in\mathbf{CB}(Y).<br>$$</p>
<p><strong>Corollary 2.2</strong>: </p>
<ul>
<li>Let $Y$ be a metric space. </li>
<li>For any $Y $-valued random variables $x, x_1,x_2,\cdots$, we have $x_m \stackrel{D}\to x$ iff,</li>
</ul>
<p>$$<br>E(\phi\circ x_m) \to \mathbb{E}(\phi\circ x)<br>$$</p>
<ul>
<li>for every bounded and Lipschitz continuous real map $\phi$ on $Y$.</li>
</ul>
<p><strong>Proposition 2.3</strong>: </p>
<ul>
<li>Let $Y$ be a metric space, and let $x, x_1, x_2,\cdots$ be $Y $-valued random variables on a common probability space. Then</li>
</ul>
<p>$$<br>x_m\to_{a.s.} x\ \mbox{ implies } x_m \stackrel{D}{\to} x,<br>$$</p>
<ul>
<li>but not conversely.</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:44:39.000Z" title="12/15/2020, 10:44:39 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-G-Weak-Convergence-and-Probability-Limit/">1.1.G Weak Convergence and Probability Limit</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/12%20Weak%20Convergence/Weak-Convergence/">Weak Convergence</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Converge Weakly, Weak Limit</strong>:  </p>
<ul>
<li>Let $X$ be a metric space and $(\mathbf{p}_m)$ a sequence in $\Delta(X)$. </li>
<li>For any $\mathbf{p}\in \Delta(X)$, we say that  $(\mathbf{p}_m)$ <strong>converges weakly</strong> to $\mathbf{p}$, denoted $\mathbf{p}_m \stackrel{w}{\to} \mathbf{p}$, if</li>
</ul>
<p>$$<br>\int_X\varphi d\mathbf{p}_m\to\int_X\varphi d\mathbf{p}\ \ \mbox{ for every } \varphi\in\mathbf{CB}(X)<br>$$</p>
<ul>
<li><p>In this case $\mathbf{p}$ is said to be the <strong>weak limit</strong> of $(\mathbf{p}_m)$.</p>
</li>
<li><p>Put differently, we have<br>$$<br>\mathbf{p}<em>m \stackrel{w}{\to} \mathbf{p} \mbox{ iff }\mathbb{E}</em>{\mathbf{p}_m}(x)\to\mathbb{E}_\mathbf{p}(x)<br>$$</p>
</li>
<li><p>for every $x\in\mathcal{L}^0(X,\mathcal{B}(X))$.</p>
</li>
</ul>
<p><strong>Converge Weakly, Weak Limit</strong>:  </p>
<ul>
<li>The Lebesgue-Stieltjes measure induced by a distribution function $F$ is denoted by $\mathbf{p}_F$. And the class of all distribution functions is denoted by $\mathfrak{F}$.</li>
<li>For any distribution functions $F, F_1, F_2,\cdots$, if $F_m(t)\to F(t)$ holds for every $t$ at which $F$ is continuous, we say the sequence $(F_m)$ <strong>weakly converges</strong> to an $F\in\mathfrak{F}$.</li>
<li>$F$ is said to be the <strong>weak limit</strong> of $(F_m)$.</li>
<li>Naturally enough, we denote this situation by writing $F_m\stackrel{w}\to F$.</li>
</ul>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Proposition 1.1</strong>: </p>
<ul>
<li>Let $X$ be a metric space and ($\mathbf{p}_m$) a sequence in $\Delta(X)$. </li>
<li>If $\mathbf{p}_m \stackrel{w}{\to} \mathbf{p}$ and $\mathbf{p}_m\stackrel{w}{\to} \mathbf{q} $ for some $\mathbf{p},\mathbf{q}\in\Delta(X)$, then $\mathbf{p}=\mathbf{q}$.</li>
</ul>
<p><strong>Corollary 1.2</strong>: </p>
<ul>
<li>Given any metric space $X$ and $\mathbf{p}, \mathbf{q}\in \Delta(X)$, we have</li>
</ul>
<p>$$<br>\int_X\varphi d\mathbf{p}=\int_X\varphi d\mathbf{q}\ \mbox{ for all } \varphi\in\mathbf{CB}(X),\ \mbox{ iff } \mathbf{p}=\mathbf{q}<br>$$</p>
<blockquote>
<p>If two Borel probability measures are distinct, then the expectations of at least one continuous and bounded random variable with respect to these measures are not equal.</p>
</blockquote>
<p><strong>Proposition 1.7</strong>: </p>
<ul>
<li>For any distribution functions $F, F_1, F_2,\cdots$, we have $\mathbf{p}_{F_m}\stackrel{w}{\to} \mathbf{p}_F$ iff $F_m\stackrel{w}\to F$.</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:43:59.000Z" title="12/15/2020, 10:43:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-F-Expectation-Lebesgue-Integral-and-Stieltjes-Integral/">1.1.F Expectation, Lebesgue Integral, and Stieltjes Integral</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/11%20Expectation%20via%20the%20Stieltjes%20Integral/Integration-By-Parts/">Integration By Parts</a></h1><div class="content"><h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Integration by Parts Formula</strong>: (Stieltjes) </p>
<ul>
<li>Let $F$ and $\varphi$ be two increasing real functions on $[a,b]$. If $\varphi$ is $F$-integrable, then $F$ is $\varphi$-integrable, and</li>
</ul>
<p>$$<br>\int^b_a\varphi dF=\varphi(b)F(b)-\varphi(a)F(a)-\int^b_aFd\varphi<br>$$</p>
<p><strong>Proposition 3.1</strong>: </p>
<ul>
<li>Let $x$ be a nonnegative random variable on a probability space $(X,\Sigma, \mathbf{p})$. If $\varphi$ is an increasing and $F_x$-integrable self-map on $\mathbb{R} $, then</li>
</ul>
<p>$$<br>\mathbb{E}(\varphi\circ x)=\varphi(0)+\int^\infty_0(1-F_x)d\varphi<br>$$</p>
<ul>
<li>In particular,<br>$$<br>\mathbb{E}(x)=\int^\infty_0(1-F_x(t))dt<br>$$</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:42:59.000Z" title="12/15/2020, 10:42:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-F-Expectation-Lebesgue-Integral-and-Stieltjes-Integral/">1.1.F Expectation, Lebesgue Integral, and Stieltjes Integral</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/11%20Expectation%20via%20the%20Stieltjes%20Integral/Expectation-as-a-Stieltjes-Integral/">Expectation as a Stieltjes Integral</a></h1><div class="content"><h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Theorem 2.1</strong>: </p>
<ul>
<li>Let $x$ be a random variable and $\varphi$ an $F_x$-integrable self-map on $\mathbb{R} $. </li>
<li>If $\mathbb{E}(\varphi\circ x)$ exists, then</li>
</ul>
<p>$$<br>\mathbb{E}(\varphi\circ x)=\int_X(\varphi\circ x)d\mathbf{p}=\int_\mathbb{R}\varphi d\mathbf{p}<em>x=\int^\infty</em>{-\infty}\varphi dF_x<br>$$</p>
<p><strong>Corollary 2.2</strong>: </p>
<ul>
<li>Let $x$ be a nonnegative random variable and $\varphi$ an $F_x$-integrable self-map on $\mathbb{R} $. If $\mathbb{E}(\varphi\circ x)$ exists, then</li>
</ul>
<p>$$<br>\mathbb{\varphi\circ x}=\varphi(0)F_x(0)+\int^\infty_0\varphi dF_x<br>$$</p>
<p><strong>Corollary 2.3</strong>: </p>
<ul>
<li>Let $x$ be a random variable with a continuously differentiable distribution function $F_x$, and $f$ a density function for $F_x$. </li>
<li>Let $\varphi$ be an almost everywhere continuous and locally bounded self-map on $\mathbb{R} $. </li>
<li>If $\varphi$ is $F_x$-integrable and $\mathbb{E}(\varphi\circ x)$ exists, then</li>
</ul>
<p>$$<br>\mathbb{E}(\varphi\circ x)=\int^\infty_{-\infty}\varphi dF_x=\int^\infty_{-\infty}\varphi(t)f(t)dt<br>$$</p>
<ul>
<li><p>In particular, above equation holds for every continuous $\varphi : \mathbb{R}\to \mathbb{R}_+$. </p>
</li>
<li><p>Moreover, if $\mathbb{E}(x)$ exists,<br>$$<br>\mathbb{E}(x)=\int_Xxd\mathbf{p}=\int^\infty_{-\infty}tdF_x(t)=\int^\infty_{-\infty}tf(t)dt<br>$$</p>
</li>
</ul>
<p><strong>Proposition 2.4</strong>: </p>
<ul>
<li>Let $f : \mathbb{R}\to \mathbb{R}_+$ be a Borel measurable function. </li>
<li>If $f$ is Riemann integrable, then</li>
</ul>
<p>$$<br>\int_{\mathbb{R}}fd\ell=\int^\infty_{-\infty}f(t)dt<br>$$</p>
<ul>
<li>In particular, above equation holds when $f$ is bounded and continuous almost everywhere.</li>
</ul>
<p><strong>Corollary 2.5</strong>: </p>
<ul>
<li>Let $a$ and $b$ be real numbers with $a &lt; b$. </li>
<li>If $f : \mathbb{R}\to \mathbb{R}_+$ is Borel measurable and Riemann integrable (or bounded and continuous almost everywhere), then</li>
</ul>
<p>$$<br>\int_{[a,b]}fd\ell=\int^b_af(t)dt<br>$$</p>
<ul>
<li><p>Similarly, we have<br>$$<br>\int_{(-\infty,a]}fd\ell=\int^a_{-\infty}f(t)dt, \ \ \ and \ \ \ \int_{[b,\infty)}fd\ell=\int^\infty_bf(t)dt<br>$$</p>
</li>
<li><p>The Riemann and Lebesgue integrals of a Riemann integrable and nonnegative Borel measurable real function (defined on an interval) are equal.</p>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T14:41:59.000Z" title="12/15/2020, 10:41:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-F-Expectation-Lebesgue-Integral-and-Stieltjes-Integral/">1.1.F Expectation, Lebesgue Integral, and Stieltjes Integral</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/11%20Expectation%20via%20the%20Stieltjes%20Integral/The-Stieltjes-Integral/">The Stieltjes Integral</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Dissection, Subinterval, Division Point, Mesh</strong>: </p>
<ul>
<li><p>For two arbitrarily fixed real numbers $a$ and $b$ with $a &lt; b$, for any positive integer $m$ and real numbers $a_0,\cdots,a_m$ with $a=a_0 &lt;\cdots &lt;a_m =b$, we refer to the collection<br>$$<br>{[a_0,a_1], [a_1, a_2],\cdots,  [a_{m-1},a_m]}<br>$$</p>
</li>
<li><p>as a <strong>dissection</strong> of $[a,b]$, and denote it by either $\mathbf{a}$ or $[a_0,\cdots,a_m]$. </p>
</li>
<li><p>Any one of the intervals $[a_{i-1},a_i] $ is called a <strong>subinterval</strong> of $\mathbf{a}$, while any one of $a_i$s is called a <strong>division point</strong> of $\mathbf{a}$. </p>
</li>
<li><p>The maximum value of the lengths of its subintervals is called the <strong>mesh</strong> of $\mathbf{a}$-this value is denoted by $\mbox{mesh}(\mathbf{a})$.</p>
</li>
<li><p>The collection of all dissections of $[a, b]$ is denoted as $\mathcal{D}[a, b]$.</p>
</li>
</ul>
<p><strong>Finer than</strong>:</p>
<ul>
<li>For any dissections $\mathbf{a} = [a_0,\cdots,a_m]$ and $\mathbf{b} = [b_0,\cdots, b_k]$ of $[a, b]$, we write</li>
</ul>
<p>$$<br>\mathbf{a}\Cup\mathbf{b}<br>$$</p>
<ul>
<li>for the dissection $[c_0,\cdots, c_l]$ in $\mathcal{D}[a, b]$ where ${c_0,\cdots, c_l} = {a_0,\cdots, a_m}\cup{b_0,\cdots, b_k}$. </li>
<li>Moreover, we say that $\mathbf{b}$ is <strong>finer than</strong> $\mathbf{a}$ if ${a_0,\cdots, a_m} \subseteq {b_0,\cdots, b_k}$. </li>
<li>Evidently, $\mathbf{a}\Cup \mathbf{b} = \mathbf{b}$ iff $\mathbf{b}$ is finer than $\mathbf{a}$. </li>
<li>We also have $\mbox{mesh}(\mathbf{b})\leq \mbox{mesh}(\mathbf{a})$ if $\mathbf{b}$ is finer than $\mathbf{a}$, but not conversely.</li>
</ul>
<p><strong>Darboux Sum</strong>: </p>
<ul>
<li>Take any bounded real functions $\varphi$ and $F$ on $[a, b]$ with $F$ being increasing. </li>
<li>For any dissection $\mathbf{a} = [a_0,\cdots, a_m]$ of $[a, b]$, we define</li>
</ul>
<p>$$<br>\check{\varphi}<em>{\mathbf{a}}(i):=\sup{\varphi(t):a</em>{i-1}\leq t\leq a_i}<br>$$</p>
<ul>
<li><p>and<br>$$<br>\hat{\varphi}<em>{\mathbf{a}}(i):=\inf{\varphi(t):a</em>{i-1}\leq t\leq a_i}<br>$$</p>
</li>
<li><p>for each $i\in [m]$. (Since $\varphi$ is bounded, every one of these numbers is real.) </p>
</li>
<li><p>By a <strong>Darboux sum</strong> of $\varphi$ with respect to $F$ and $\mathbf{a}$, we mean a number like<br>$$<br>\sum_{i\in[m]}\alpha_i(F(a_i)-F(a_{i-1}))<br>$$</p>
</li>
<li><p>where $\hat{\varphi}_{\mathbf{a}} (i)\leq \alpha_i\leq \check{\varphi}_{\mathbf{a}}(i)$ for each $i$.</p>
</li>
<li><p>In particular, the <strong>$\mathbf{a}$-upper Darboux sum</strong> of $\varphi$ with respect to $F$ is defined as the number<br>$$<br>\mathbf{S}<em>{F,\mathbf{a}}(\varphi):=\sum</em>{i\in[m]}\check{\varphi}_{\mathbf{a}}(i)(F(a_i)-F(a_{i-1}))<br>$$</p>
</li>
<li><p>and the <strong>$\mathbf{a}$-lower Darboux sum</strong> of $\varphi$ with respect to $F$ is defined dually as<br>$$<br>\mathbf{s}<em>{F,\mathbf{a}}(\varphi):=\sum</em>{i\in[m]}\hat{\varphi}_{\mathbf{a}}(i)(F(a_i)-F(a_{i-1}))<br>$$</p>
</li>
<li><p>Clearly, $\mathbf{S}<em>{F,\mathbf{a}}(\varphi)$ decreases, and $\mathbf{s}</em>{F,\mathbf{a}}(\varphi)$ increases, as a becomes finer. </p>
</li>
<li><p>Evidently, we always have $\mathbf{S}<em>{F,\mathbf{a}}(\varphi)\geq\mathbf{s}</em>{F,\mathbf{a}}(\varphi) $. </p>
</li>
<li><p>Furthermore, and this is important, we have<br>$$<br>\inf{\mathbf{S}<em>{F,\mathbf{a}}(\varphi):\mathbf{a}\in\mathcal{D}[a,b]}\geq\sup{\mathbf{s}</em>{F,\mathbf{a}}(\varphi):\mathbf{a}\in\mathcal{D}[a,b]}<br>$$</p>
</li>
<li><p>The number on the left-hand side of this inequality is called the <strong>upper Stieltjes integral of $\varphi$ with respect to</strong> $F$, and is denoted by $\mathcal{S}_F (\varphi)$. </p>
</li>
<li><p>Similarly, the number on the right-hand side is called the <strong>lower Stieltjes integrals of $\varphi$ with respect to $F$</strong>, and is denoted by $\mathbf{s}_F (\varphi)$. </p>
</li>
<li><p>Thus, our inequality reads:<br>$$<br>\mathcal{S}_F (\varphi)\geq\mathbf{s}_F (\varphi)<br>$$</p>
</li>
</ul>
<p><strong>Stiltjes Integrals, Stieltjes Integrable, $F$-integrable</strong>: </p>
<ul>
<li>Let $\varphi,F\in \mathbf{B}[a, b]$ and assume that $F$ is increasing. </li>
<li>Suppose that there exists a real number $\theta $ such that, for any $\varepsilon &gt; 0$, there exists a dissection $\mathbf{a}$ of $[a, b]$ with</li>
</ul>
<p>$$<br>|\mathbf{S}<em>{F,\mathbf{a}}(\varphi)-\theta|&lt;\varepsilon\mbox{ and }|\mathbf{s}</em>{F,\mathbf{a}}(\varphi)-\theta|&lt; \varepsilon<br>$$</p>
<ul>
<li><p>Then this number $\theta$ is unique, and  it is denoted by<br>$$<br>\int^b_a\varphi dF\mbox{ or }\int^b_a\varphi(t)dF(t)<br>$$</p>
</li>
<li><p>When it exists, we refer to this number as the <strong>Stieltjes integral of $\varphi$ with respect to $F$,</strong> and in that case, we say that $\varphi$ is <strong>Stieltjes integrable with respect to $F$</strong>, or simply, <strong>$F$-integrable</strong>. </p>
</li>
<li><p>If , $\varphi$ is $F$-integrable, we also define<br>$$<br>\int^a_b\varphi dF=-\int^b_a\varphi dF<br>$$</p>
</li>
<li><p>Finally, where $a\leq c\leq  d\leq  b$, we say that $\varphi$ is $F$-integrable on $[c,d]$, if $\varphi|<em>{[c,d]}$ is $F|</em>{[c,d]}$-integrable.</p>
</li>
<li><p>$\varphi$ is $F$-integrable iff the upper and lower Stieltjes integrals of $\varphi$ with respect to $F$ are equal, that is,<br>$$<br>\inf{\mathbf{S}<em>{F,\mathbf{a}}(\varphi) :\mathbf{a}\in\mathcal{D}[a, b]} = \sup{\mathbf{s}</em>{F,\mathbf{a}}(\varphi) : \mathbf{a} \in \mathcal{D}[a, b]}<br>$$</p>
</li>
</ul>
<blockquote>
<p>The following statements are equivalent:</p>
<ul>
<li><p>$\varphi$ is $F$-integrable,</p>
</li>
<li><p>$\mathbf{S}_F(\varphi) = \mathbf{s}_F(\varphi)$,</p>
</li>
<li><p>For every $\varepsilon &gt; 0$, there is a dissection $\mathbf{a}\in \mathcal{D}[a, b]$ such that<br>$$<br>\mathbf{S}<em>{F,\mathbf{a}}(\varphi) -\mathbf{s}</em>{F,\mathbf{a}}(\varphi)&lt;\varepsilon<br>$$</p>
</li>
</ul>
</blockquote>
<p><strong>Riemman Integrable, Riemann Intergral</strong>: </p>
<ul>
<li>The Riemann integral is a special case of the Stieltjes integral. </li>
<li>Formally, we say that $\varphi\in \mathbb{R}^{[a,b]}$ is <strong>Riemann integrable</strong> if it is $\mbox{id}_{[a,b]}$-integrable, and for any such $\varphi$, we define the <strong>Riemann integral</strong> of $\varphi$, denoted by</li>
</ul>
<p>$$<br>\int^b_a\varphi(t)dt<br>$$</p>
<ul>
<li>as the Stieltjes integral of $\varphi$ with respect to the identity function on $[a, b]$.</li>
</ul>
<p><strong>Continuous almost everywhere</strong>: </p>
<ul>
<li>Let us agree to call a real map $\varphi$ on $[a,b]$ continuous almost everywhere on $[a, b]$ if</li>
</ul>
<p>$$<br>d(\varphi):={t\in[a,b]:\varphi\mbox{ is not continuous at }t}<br>$$</p>
<ul>
<li>is a ‚Äúsmall‚Äù set in the following sense: For every $\varepsilon &gt; 0$ there is an open subset $O$ of $[a,b]$ such that $ d(\varphi)\subseteq O$ and $\ell(O) &lt;\varepsilon$.</li>
</ul>
<blockquote>
<p>The totality of discontinuity points $\varphi$ fits within an open set of arbitrarily Lebesgue measure.</p>
</blockquote>
<p><strong>$F$-integrable, Improper Stieltjes Integral, Riemann Integrable</strong>: </p>
<ul>
<li><p>Let $\varphi$ and $F$ be any two self-maps on $\mathbb{R} $, and assume that $F$ is increasing. </p>
</li>
<li><p>Given any real numbers $a$ and $b$ with $a \leq b$, we say that $\varphi$ is <strong>$F$-integrable on $[a,b]$</strong>, if $\varphi$ is bounded on $[a,b]$ and $\int^b_a\varphi dF$ exists. (Note. If $\varphi$ is $F$-integrable on $[a,b]$, then $\int^b_a\varphi dF$ is a real number.) </p>
</li>
<li><p>In turn, we say that $\varphi$ is <strong>$F$-integrable on $[a,\infty)$</strong> if $\varphi$ is $F$-integrable on $[a,b]$ for each $b\geq a$, and $\lim_{b\to \infty}\int^b_a\varphi dF\in \overline{\mathbb{R} }$</p>
</li>
<li><p>In this case we define the <strong>(improper) Stieltjes integral</strong> of $\varphi$ with respect to $F$ on this unbounded interval as<br>$$<br>\int^\infty_a\varphi dF:=\lim_{c\to \infty}\int^c_a\varphi dF.<br>$$</p>
</li>
<li><p>The $F $-integrability of $\varphi$ on $(-\infty,a]$ and the extended real number $\int^a_{-\infty}\varphi dF$ is analogously defined. </p>
</li>
<li><p>Finally, we say that $\varphi$ is <strong>$F$-integrable</strong>, if there exists a real number a such that $\varphi$ is $F$-integrable on both $(-\infty,a]$ and $[a,\infty)$, and the expression $\int^a_\infty \varphi dF+\int^\infty_a\varphi dF$ is not of the indeterminate form $\infty-\infty$. </p>
</li>
<li><p>In this case, we define<br>$$<br>\int^\infty_{-\infty}\varphi dF:=\int^a_{-\infty}\varphi dF+\int^\infty_{a}\varphi dF,<br>$$</p>
</li>
<li><p>and note that this definition allows $\int^\infty_{-\infty}\varphi dF$ to equal $-\infty$ or $\infty$. </p>
</li>
<li><p>If $\varphi$ is $id_{\mathbb{R} }$-integrable, then we say that it is <strong>Riemann integrable</strong>.</p>
</li>
</ul>
<blockquote>
<p>The $F $-integrability of $\varphi$ implies that, on every compact interval, $\varphi$ is $F $-integrable. In particular, such a $\varphi$ is bounded on every compact interval. </p>
<p>A self-map on $\mathbb{R} $ with this property is said to be locally bounded.</p>
</blockquote>
<p><strong>Continous Almost Everywhere</strong>: </p>
<ul>
<li>The notion of almost everywhere continuity is extended to self-maps on $\mathbb{R} $ in the obvious way. </li>
<li>Put precisely, we say that $\varphi$ is <strong>continuous almost everywhere</strong> (or almost everywhere continuous) if, for every $\varepsilon &gt; 0$, there is an open subset $O$ of $\mathbb{R} $ such that $\ell(O) &lt; \varepsilon$ and every point of discontinuity of $\varphi$ is contained in $O$. </li>
</ul>
<blockquote>
<p>Obviously, if $\varphi$ is continuous almost everywhere, then it is continuous almost everywhere on any compact interval.</p>
</blockquote>
<p><strong>Density, Density Function</strong>: </p>
<ul>
<li>We say that a distribution function $F$ has <strong>density</strong>, if there exists an almost everywhere continuous map $f : \mathbb{R}\to \mathbb{R}_+$ such that $f$ is locally bounded and</li>
</ul>
<p>$$<br>F(s)=\int^s_{-\infty}f(t)dt<br>$$</p>
<ul>
<li>for every real number $s$. </li>
<li>In this case, we say that $f$ is a <strong>density function</strong> for $F$.</li>
</ul>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Lemma 1.1</strong>: </p>
<ul>
<li>Let $\varphi,\ F\in \mathbf{B}[a,b]$ be such that $F$ is increasing. If $\varphi$ is $F$-integrable, then,</li>
</ul>
<p>$$<br>\int^b_a\varphi dF=\int^c_a\varphi dF+\int^b_c\varphi dF,\ \ \ \  a\leq c\leq b<br>$$</p>
<ul>
<li>The same conclusion also holds if $\varphi$ is $F $-integrable on both $[a, c]$ and $[c, b]$.</li>
</ul>
<blockquote>
<p>The Stieltjes integral is additive with respect to the interval of integration. </p>
</blockquote>
<p><strong>Lemma 1.2</strong>: </p>
<ul>
<li>Assume $a &lt; b$, and take any $\varphi, F\in \mathbf{B}[a,b]$ with $F$ being increasing. </li>
<li>If $F$ is continuous and $\varphi$ is $F $-integrable. Then, </li>
</ul>
<p>$$<br>\int^{\frac{b-1}{m}}_a\varphi dF\to\int^b_a\varphi dF\ \ \ and\  \ \ \ \int^b_{\frac{a+1}{m}}\varphi dF\to\int^b_a\varphi dF<br>$$</p>
<blockquote>
<p>When the integrator is a continuous function, altering the value of an integrable function at a single point does not alter the value of its integral</p>
</blockquote>
<p><strong>Lemma 1.3</strong>: </p>
<ul>
<li>Let $\varphi,\ F\in \mathbf{B}[a, b]$ be such that $F$ is increasing and $\varphi$ is $F $-integrable. </li>
<li>If $\varphi\geq 0$ almost everywhere on $[a, b]$, then</li>
</ul>
<p>$$<br>\int^b_a\varphi dF\geq0<br>$$</p>
<p><strong>Corollary 1.4</strong>: </p>
<ul>
<li>Let $\varphi, F \in \mathbf{B}[a, b]$ be such that $F$ is increasing and $\varphi$ is $F $-integrable. If $\varphi$ vanishes almost everywhere on $[a,b]$, then</li>
</ul>
<p>$$<br>\int^b_a\varphi  dF=0<br>$$</p>
<p><strong>Lemma 1.5</strong>: </p>
<ul>
<li>Let $\varphi, F \in \mathbf{B}[a, b]$ be such that $F$ is increasing, and both $\varphi$ and $\phi$ are $F$-integrable. Then, for any real number $\alpha$, we have</li>
</ul>
<p>$$<br>\int^b_a(\alpha\varphi+\phi)dF=\alpha\int^b_a\varphi dF+\int^b_a\phi dF<br>$$</p>
<blockquote>
<p>The Stieltjes integral is linear with respect to its integrand. </p>
</blockquote>
<p><strong>Proposition 1.6</strong>: (Stieltjes) </p>
<ul>
<li>Take any $\varphi, F\in \mathbf{B}[a, b]$ with $F$ being increasing. </li>
<li>If $\varphi$ is continuous, then it is $F$-integrable.</li>
</ul>
<p><strong>Proposition 1.7</strong>: </p>
<ul>
<li>Let $\varphi, F \in \mathbf{B}[a, b]$ and assume that $F$ is increasing and Lipschitz continuous. </li>
<li>If $\varphi$ is continuous almost everywhere on $[a,b]$, then it is $F $-integrable.</li>
</ul>
<p><strong>The Lebesgue Criterion</strong>: </p>
<ul>
<li>If $\varphi \in \mathbf{B}[a,b]$ is continuous almost everywhere on $[a,b] $, then it is Riemann integrable.</li>
</ul>
<blockquote>
<p>Riemann integrability = Continuity almost everywhere.</p>
</blockquote>
<p><strong>Corollary 1.8</strong>: </p>
<ul>
<li>Let $\varphi\in \mathbf{B}[a, b]$ be continuous almost everywhere on $[a, b]$. If $\varphi$ vanishes almost everywhere on $[a, b]$, then</li>
</ul>
<p>$$<br>\int^b_a\varphi(t)dt=0<br>$$</p>
<p><strong>The Fundamental Theorem of Calculus 1</strong>: </p>
<ul>
<li>Let $f \in \mathbf{B}[a, b]$ be continuous almost everywhere and $F\in \mathbb{R}^{[a,b]}$ satisfy</li>
</ul>
<p>$$<br>F(s)=F(a)+\int^s_af(r)dr,\ \ \ \ a\leq s\leq b<br>$$</p>
<ul>
<li>Then, $F$ is Lipschitz continuous on $[a,b]$, and for every $s\in [a,b]$ at which $f$ is continuous, $F‚Äô(s)$ exists and equals $f(s)$.</li>
</ul>
<p><strong>The Fundamental Theorem of Calculus 2</strong>: </p>
<ul>
<li><p>Take any $F\in \mathbf{C}^1[a,b]$, and let $f \in \mathbf{B}[a,b]$ is a Riemann integrable function such that $F‚Äô = f$ almost everywhere on $[a, b]$. </p>
</li>
<li><p>Then we have<br>$$<br>F(s)=F(a)+\int^s_af(r)dr,\ \ \ \ a\leq s\leq b<br>$$</p>
</li>
</ul>
<blockquote>
<p>Roughly speaking, The Fundamental Theorem of Calculus says that we can think of dif ferentiation and Riemann integration as inverse operations.</p>
</blockquote>
<p><strong>Theorem 1.10</strong>: </p>
<ul>
<li>Let $\varphi\in \mathbf{B}[a, b]$ be continuous almost everywhere on $[a, b]$. </li>
<li>Then, for any increasing $F\in \mathbf{C}^1[a,b]$, we have</li>
</ul>
<p>$$<br>\int^b_a\varphi dF=\int^b_a\varphi(t)F‚Äô(t)dt<br>$$</p>
<p><strong>Corollary 1.11</strong>: </p>
<ul>
<li><p>Let $f,\varphi\in \mathbf{B}[a,b]$ be continuous almost everywhere on $[a,b]$ and assume $f \geq 0$. </p>
</li>
<li><p>Then, for any $F\in \mathbf{C}^1[a, b]$ such that<br>$$<br>F(s)=F(a)+\int^s_af(r)dr,\ \ \ \ a\leq s\leq b<br>$$</p>
</li>
<li><p>holds, we have</p>
</li>
</ul>
<p>$$<br>\int^b_a\varphi dF=\int^b_a\varphi(t)f(t)dt<br>$$</p>
<blockquote>
<p>Theorem 1.10 and Corollary 1.11 help to reduce a Stieltjes Integral to a Riemann Integral, gaining computational power.</p>
</blockquote>
<p><strong>Proposition 1.12</strong>: </p>
<ul>
<li>Let $\varphi$ and $F$ be two self-maps on $\mathbb{R} $, and assume that $F$ is increasing and continuously differentiable. </li>
<li>If $\varphi$ is nonnegative, locally bounded, and continuous almost everywhere, then it is $F $-integrable.</li>
</ul>
<p><strong>Theorem 1.13</strong>: </p>
<ul>
<li>Let $F\in \mathbf{C}^1(\mathbb{R} )$ be a distribution function, and $\varphi$ a locally bounded self-map on $\mathbb{R} $ that is continuous almost everywhere. </li>
<li>If $f$ is a density function for $F $, then</li>
</ul>
<p>$$<br>\int^\infty_{-\infty}\varphi dF=\int^\infty_{-\infty}\varphi(t)f(t)dt<br>$$</p>
<ul>
<li>in the sense that if one side exists so does the other.</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T13:55:59.000Z" title="12/15/2020, 9:55:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-F-Expectation-Lebesgue-Integral-and-Stieltjes-Integral/">1.1.F Expectation, Lebesgue Integral, and Stieltjes Integral</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/10%20Expectation%20via%20the%20Lebesgue%20Integral/Spaces-of-Integrable-Random-Variables/">Spaces of Integrable Random Variables</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>$p$-Integrable</strong></p>
<ul>
<li><p>Let $(X,\Sigma, \mathbf{p})$ be a measure space. </p>
</li>
<li><p>For any real number $p\geq 1$, we define $\mathcal{L}^p(X,\Sigma,\mu)$ as the set of all random variables $f$ on $(X,\Sigma,\mu)$ such that $|f|^p$ is integrable. </p>
</li>
<li><p>In other words,<br>$$<br>\mathcal{L}^p(X,\Sigma,\mu):=\left{f\in\mathcal{L}^0(X,\Sigma):\int_X|f|^pd\mu&lt;\infty\right}<br>$$</p>
</li>
<li><p>Any one member of $\mathcal{L}^p(X,\Sigma,\mu)$ is said to be $p$-<strong>integrable</strong>.</p>
</li>
</ul>
<blockquote>
<p>There is a natural way of making $\mathcal{L}^p(X,\Sigma,\mu)$ a seminormed linear space.</p>
<p>We define the real map $|\cdot|_p$ on $\mathcal{L}^p(X,\Sigma,\mu)$ by<br>$$<br>|f|_p:=\left(\int_X|f|^pd\mu\right)^\frac{1}{p}<br>$$<br>It is not a normed linear space proper, because $|\cdot|_p$ identifies any two random variables that are distinct from each other only on a negligible set with respect to $\mu$. </p>
<p>In other words, the map $(f, g) \mapsto |f- g|_p$ is a semimetric, but it is not a metric, for it fails to separate points in $\mathcal{L}^p(X,\Sigma,\mu)$. </p>
<p>The problem is that $|f|<em>p =0$ does not yield $f =\mathbf{0}$, it implies only that $f =</em>{a.s.} \mathbf{0}$.</p>
</blockquote>
<p><strong>$\mathcal{L}^p$-bounded</strong>:</p>
<ul>
<li>For any given real number $p\geq1$, we say that a set $\mathcal{X}$ of random variables on a given probability space is <strong>$\mathcal{L}^p$-bounded</strong> if either it is empty or<br>$$<br>\sup{\mathbb{E}(|x|^p):x\in\mathcal{X}}&lt;\infty<br>$$</li>
</ul>
<p><strong>$\mathcal{L}^p$-convergence</strong>:</p>
<ul>
<li><p>For any given real number $p\geq1$, let $x, x_1,x_2,\dots$ be random variables on $\mathcal{L}^p(X,\Sigma,\mu)$</p>
</li>
<li><p>We say that $x_m$ is <strong>$\mathcal{L}^p$-convergent</strong> if<br>$$<br>\lim_{m\to\infty}|x_m-x|<em>p=\lim</em>{m\to\infty}\left(\int_X|x_m-x|^pd\mu\right)^\frac{1}{p}=\lim_{m\to\infty}\mathbb{E}(|x_m-x|^p)=0<br>$$</p>
</li>
<li><p>$\mathcal{L}^1$-convergence is <strong>called convergence in the mean</strong>.</p>
</li>
</ul>
<blockquote>
<p>$\mathcal{L}^p$-convergence is a natural notion of convergence for sequences in this semimetric space.</p>
</blockquote>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Proposition 5.4</strong>: </p>
<ul>
<li>Let $X$ be a nonempty set of random variables on a probability space $(X,\Sigma,\mathbf{p})$. </li>
<li>If $X$ is uniformly integrable, then it is $\mathcal{L}^1$-bounded.</li>
</ul>
<p><strong>Proposition 5.5</strong>:</p>
<ul>
<li>Let $X$ be a set of random variables on a probability space $(X,\Sigma,\mathbf{p})$.  </li>
<li>If $X$ is $\mathcal{L}^p$-bounded for some $p &gt; 1$, then it is uniformly integrable.</li>
</ul>
<blockquote>
<p>$$<br>\mathcal{L}^p\mbox{-boundeness}\ \ (p&gt;1)\Longrightarrow\mbox{uniform integrability}\Longrightarrow\mathcal{L}^1\mbox{-boundeness}<br>$$</p>
</blockquote>
<p><strong>Proposition 5.6</strong>:</p>
<ul>
<li>Let $x, x_1,x_2,\dots$ be integrable random variables on a probability space $(X,\Sigma,\mathbf{p})$ such that $\mathbb{E}(|x_m -x|) \to 0$. </li>
<li>Then, $(x_m)$ is uniformly integrable.</li>
</ul>
<blockquote>
<p>$$<br>\mathcal{L}^1\mbox{-convergence}\Longrightarrow\mbox{uniform integrability}\Longrightarrow\mathcal{L}^1\mbox{-boundeness}<br>$$</p>
</blockquote>
<p><strong>Proposition 5.7</strong>: </p>
<ul>
<li>Let $(x_m)$ be a uniformly integrable sequence of random variables on a probability space $(X,\Sigma, \mathbf{p})$ such that $x_m\to_{a.s.} x$ for some $x \in \mathcal{L}^0(X,\Sigma)$</li>
<li>Then, $x$ is integrable and $\mathbb{E}(|x_m-x |) \to 0$.</li>
</ul>
<blockquote>
<p>Almost sure convergence does imply $\mathcal{L}^1$-convergence for uniformly integrable sequences.</p>
</blockquote>
<p><strong>Corollary 5.8</strong>: </p>
<ul>
<li>Let $x, x_1, x_2,\dots$ be integrable random variables on a probability space $(X,\Sigma,\mathbf{p})$ such that $x_m\to_{a.s.} x$. </li>
<li>Then, $\mathbb{E}(|x_m-x|) \to 0$ iff, $(x_m)$ is uniformly integrable.</li>
</ul>
<h2 id="Examples-and-Exercises"><a href="#Examples-and-Exercises" class="headerlink" title="Examples and Exercises"></a>Examples and Exercises</h2><p><strong>Example 5.1</strong>: </p>
<ul>
<li>Almost sure convergence does not imply $\mathcal{L}^1$-convergence. </li>
<li>Consider the sequence $(x_m)$ of random variables on the probability space  $([0,1],\mathcal{B}[0,1],\ell)$ where $x_m$ equals $m$ on $[0,\frac{1}{m}]$ and $0$ elsewhere on $[0,1]$. </li>
<li>Then, $x_m(\omega) \to0$ for each $\omega\in (0,1]$, and hence, $x_m \to_{a.s.} 0$. </li>
<li>But $|x_m|_1 = 1$ for each $m$.</li>
</ul>
<p><strong>Example 5.2</strong>: </p>
<ul>
<li>$\mathcal{L}^1$-convergence does not imply almost sure convergence. </li>
<li>Consider $(x_m) := (\mathbf{1}<em>{[0,1)},\mathbf{1}</em>{[0,\frac{1}{2})}, \mathbf{1}<em>{[\frac{1}{2},1)},\mathbf{1}</em>{[0,\frac{1}{3})}, \mathbf{1}<em>{[\frac{1}{3},\frac{2}{3})},\mathbf{1}</em>{[\frac{2}{3},1)},\dots),$ which is a sequence in $\mathcal{L}^1([0,1),\mathcal{B}[0,1),\ell)$. </li>
<li>Clearly, we have $\mathbb{E}(x_m)\to 0$, that is, $|x_m|_1\to 0$. </li>
<li>But $ (x_m(\omega))$ does not converge to a real number for any $\omega$ in $[0, 1)$.</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T13:54:59.000Z" title="12/15/2020, 9:54:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-F-Expectation-Lebesgue-Integral-and-Stieltjes-Integral/">1.1.F Expectation, Lebesgue Integral, and Stieltjes Integral</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/10%20Expectation%20via%20the%20Lebesgue%20Integral/Elementary-Probability-Inequalities/">Elementary Probability Inequalities</a></h1><div class="content"><h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Jensen‚Äôs Inequality</strong>:</p>
<ul>
<li><p>Let $x$ be an integrable random variable on a probability space $(X,\Sigma, \mathbf{p})$, $I$ an open interval that contains $x(X)$, and $\varphi : I \to \mathbb{R}$ a concave function. </p>
</li>
<li><p>Then, $\varphi \circ x \in \mathcal{L}^0(X ,\Sigma)$ and<br>$$<br>\mathbb{E}(\varphi\circ x) \leq \varphi(\mathbb{E}(x))<br>$$</p>
</li>
<li><p>If $\varphi$ is convex, then the inequality goes the other direction.</p>
</li>
</ul>
<blockquote>
<p>Under fairly general conditions, the expectation of a concave transformation of a random variable $x$ is always less than the same transformation of the expectation of $x$</p>
</blockquote>
<p><strong>Lemma 4.1</strong>:</p>
<ul>
<li><p>Let $Y$ be a metric space, and $x$ a $Y$-valued random variable on a probability space $(X,\Sigma, \mathbf{p})$. </p>
</li>
<li><p>Then, for any continuous $\varphi: Y \to \mathbb{R}_+$ and real number $\lambda &gt; 0$, we have<br>$$<br>\mathbf{p}{\varphi\circ x\geq \lambda}\leq\frac{1}{\lambda}\mathbb{E}(\varphi\circ x).<br>$$</p>
</li>
</ul>
<p><strong>Markov‚Äôs Inequality</strong>:</p>
<ul>
<li><p>Let $Y$ be a normed metric space, and $x$ a $Y$-valued random variable on a probability space $(X,\Sigma, \mathbf{p})$. </p>
</li>
<li><p>Then, for any real number $\lambda &gt; 0$, we have<br>$$<br>\mathbf{p}{| x|_Y\geq \lambda}\leq\frac{1}{\lambda}\mathbb{E}(| x|_Y).<br>$$</p>
</li>
<li><p>In particular, for any  random variable $x$ on $(x,\Sigma,\mathbf{p})$<br>$$<br>\mathbf{p}{| x|\geq \lambda}\leq\frac{1}{\lambda}\mathbb{E}(| x|).<br>$$</p>
</li>
</ul>
<p><strong>The Chebyshev-Bienaym√© Inequality</strong>:</p>
<ul>
<li>For any random variable $x$ defined on a probability space $(X,\Sigma,\mathbf{p})$, and any real number $\lambda&gt; 0$, we have<br>$$<br>\mathbf{p}{| x|\geq \lambda}\leq\frac{1}{\lambda^2}\mathbb{E}(x^2).<br>$$</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T13:53:59.000Z" title="12/15/2020, 9:53:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-F-Expectation-Lebesgue-Integral-and-Stieltjes-Integral/">1.1.F Expectation, Lebesgue Integral, and Stieltjes Integral</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/10%20Expectation%20via%20the%20Lebesgue%20Integral/The-Expectation-Functional-of-Arbitrary-Random-Variables/">The Expectation Functional of Arbitrary Random Variables</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Expectation of Arbitrary Random Variables</strong>:</p>
<ul>
<li>Let $x$ be an $\overline{\mathbb{R}}$-valued random variable on a probability space $(X,\Sigma, \mathbf{p})$. </li>
<li>Note that $x^+ := \max{x, 0}$ and $x^- := \max{-x,0}$ are $[0, \infty]$-valued random variables on $(X,\Sigma,\mathbf{p})$ with $x = x^++  x^-$ </li>
<li>Define the <strong>expectation</strong> of $x$ as the (extended real) number $\mathbb{E}(x) := \mathbb{E}(x^+) -\mathbb{E}(x^-)$, provided that $\mathbb{E}(x^+)$ and $\mathbb{E}(x^-)$ are not both infinite.<ul>
<li>If $\mathbb{E} (x^+) = \infty = \mathbb{E}(x^-)$, we say that the expectation of $x$ does not exist.</li>
</ul>
</li>
</ul>
<blockquote>
<p>This definition generalizes the one we gave for the expectation of $[0,\infty]$-valued random variables.</p>
</blockquote>
<blockquote>
<p>In real analysis, $\mathbb{E}(x)$ is called the Lebesgue integral of $x$ (with respect to $\mathbf{p}$), and is denoted by $\int_Xxd\mathbf{p}$.</p>
</blockquote>
<p><strong>Variance of Arbitrary Random Variables</strong>:</p>
<ul>
<li><p>In turn, the <strong>variance</strong> of an arbitrary random variable $x$ on $(X,\Sigma,\mathbf{p})$ is the number<br>$$<br>\mathbb{V}(x) := \mathbb{E}((x - \mathbb{E}(x))^2)<br>$$</p>
</li>
<li><p>where $(x-\mathbb{E}(x))^2$ is the arbitrary random variable $\omega\mapsto (x(\omega) -\mathbb{E}(x))^2$ on $(X,\Sigma, \mathbf{p})$.</p>
</li>
</ul>
<blockquote>
<p>However, it is often more convenient to use the alternate formula<br>$$<br>\mathbb{V}(x) := \mathbb{E}(x^2) - \mathbb{E}(x)^2<br>$$</p>
</blockquote>
<p><strong>Integrable</strong>:</p>
<ul>
<li>$x$ is <strong>integrable</strong> (with respect to $\mathbf{p}$) if $\mathbb{E}(|x|)=\mathbb{E}(x^+)+\mathbb{E}(x^-)&lt;\infty$ .</li>
</ul>
<blockquote>
<p>$\mathbb{E}(x)$ exists iff $\min{\mathbb{E}(x^+), \mathbb{E}(x^-)} &lt; \infty$, iff either $\mathbb{E}(x^+)$ or $\mathbb{E}(x^-)$ is finite</p>
<p>$x$ is integrable iff $\max{\mathbb{E}(x^+), \mathbb{E}(x^-)} &lt; \infty$, iff both $\mathbb{E}(x^+)$ and $\mathbb{E}(x^-)$ is finite</p>
<p>$x$ is integrable iff $\mathbb{E}(x)$ exists and it is finite.</p>
</blockquote>
<blockquote>
<p>Integrability of a random variable means simply that the expectation of this random variable is a real number.</p>
</blockquote>
<p><strong>Lebesgue Integration of Aribitrary Maps</strong>:</p>
<ul>
<li><p>Let $(X,\Sigma,\mu)$ be a measure space. </p>
</li>
<li><p>$f : X\to \overline{\mathbb{R}}$ a -measurable map. The <strong>Lebesgue integral of $f$ (with respect to $\mu$</strong>) is defined as the (extended real) number<br>$$<br>\int_Xfdu:=\int_Xf^+d\mu-\int_Xf^-d\mu<br>$$</p>
</li>
<li><p>provided that the right-hand side of this expression is not of the $\infty-\infty$ form. </p>
<ul>
<li>If the latter condition is not met, we say that the Lebesgue integral of $f$ (with respect to $\mu$) does not exist.</li>
</ul>
</li>
<li><p>For any $S\in\Sigma$, we also define<br>$$<br>\int_Sfd\mu:=\int_X\mathbf{1}_Sd\mu,<br>$$</p>
</li>
<li><p>provided that the right-hand side of this expression exists. </p>
</li>
</ul>
<p><strong>Integrable</strong>:</p>
<ul>
<li>$f$ is <strong>integrable</strong> (with respect to $\mu$) if $\int_X |f|d\mu &lt; \infty$.</li>
</ul>
<p><strong>Uniform Integrable</strong>:</p>
<ul>
<li><p>A collection $\mathcal{X}$ of random variables on a probability space $(X,\Sigma,\mathbf{p})$ is said to be <strong>uniformly integrable</strong> (with respect to $\mathbf{p}$) if<br>$$<br>\lim_{ a\to\infty}\sup\left{ \int_{ { \vert x\vert&gt;a} }\vert x\vert d\mathbf{p}:x\in\mathcal{X} \right }=0<br>$$</p>
</li>
<li><p>that is, for every $\varepsilon &gt; 0$, there is a real number $a &gt; 0$ such that<br>$$<br>\int_{ {|x|&gt;a } }|x|d\mathbf{p}&lt;\varepsilon \ \ \ \ \ \mbox{ for each }x\in\mathcal{X}<br>$$</p>
</li>
<li><p>In turn, a sequence $(x_m)$ of random variables on $(X,\Sigma,\mathbf{p})$ is called uniformly integrable if ${x_1, x_2,\dots}$ is <strong>uniformly integrable</strong></p>
</li>
</ul>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Proposition 2.1</strong>: </p>
<p>For any $\mathbb{R}$-valued random variable $x$ on a probability space $(X,\Sigma,\mathbf{p})$ such that $\mathbb{E}(x)$ exists, we have $|\mathbb{E}(x)| \leq \mathbb{E}(|x|)$</p>
<p><strong>Proposition 2.2</strong>:</p>
<ul>
<li>Let $x$ and $y$ be $\overline{\mathbb{R}}$-valued random variables on a probability space $(X,\Sigma,\mathbf{p})$.</li>
<li>For any real number $a$, we have $\mathbb{E}(ax) = a\mathbb{E}(x)$, provided that $\mathbb{E}(x)$ exists.</li>
<li>Furthermore, $\mathbb{E}(x + y) = \mathbb{E}(x) + \mathbb{E}(y)$, provided that $x + y\in \overline{\mathbb{R}}^X$, $\mathbb{E}(x)$ exists, and $y$ is integrable.</li>
</ul>
<blockquote>
<p>The set of all integrable random variables on a probability space $(X,\Sigma,\mathbf{p})$ is denoted by $\mathcal{L}^1(X,\Sigma,\mathbf{p})$, that is,<br>$$<br>\mathcal{L}^1(X,\Sigma,\mathbf{p}):=\left{x\in\mathcal{L}^0(X,\Sigma,\mathbf{p}):\int_X|x|d\mathbf{p}\right}<br>$$<br>$\mathcal{L}^1(X,\Sigma,\mathbf{p})$ is a linear subspace of $\mathcal{L}^0(X,\Sigma)$.</p>
<p>The map $\mathbb{E}$ acts as a linear functional on this linear space.</p>
</blockquote>
<p><strong>Proposition 2.3</strong>:</p>
<ul>
<li><p>Let $x$ and $y$ be $\overline{\mathbb{R}}$-valued random variables on a probability space $(X,\Sigma,\mathbf{p})$.</p>
</li>
<li><p>If both $\mathbb{E}(x)$ and $\mathbb{E}(y)$ exist, then<br>$$<br>x\geq_{a.s.}y\ \ \ \ \mbox{ implies }\ \ \ \ \mathbb{E}(x) \geq \mathbb{E}(y)<br>$$</p>
</li>
</ul>
<p><strong>Corollary 2.4</strong>:</p>
<ul>
<li><p>Let $x$ and $y$ be $\overline{\mathbb{R}}$-valued random variables on a probability space $(X,\Sigma,\mathbf{p})$.</p>
</li>
<li><p>If both $\mathbb{E}(x)$ and $\mathbb{E}(y)$ exist, then<br>$$<br>x=_{a.s.}y\ \ \ \ \mbox{ implies }\ \ \ \ \mathbb{E}(x) = \mathbb{E}(y)<br>$$</p>
</li>
</ul>
<p><strong>The Monotone Convergence Theorem 2</strong>:</p>
<ul>
<li>Let $x, x_1,x_2,\dots$ be $\overline{\mathbb{R}}$-valued random variables on a probability space $(X,\Sigma, \mathbf{p})$. Then,<br>$$<br>\mathbb{E}(x_1)&gt;-\infty,\ \ \ x_m \uparrow_{a.s.} x\ \ \ \ \ \mbox{ implies }\ \ \ \ \ \ \mathbb{E}(x_m)\uparrow \mathbb{E}(x)<br>$$</li>
</ul>
<p><strong>The Change of Variables Formula</strong>:</p>
<ul>
<li><p>Let $Y$ be a metric space, $x$ a $Y$-valued random variable on a probability space $(X,\Sigma,\mathbf{p})$, and $\varphi$ an $\overline{\mathbb{R}}$-valued random variable on $(Y,\mathcal{B}(Y ),\mathbf{p}_x)$. </p>
</li>
<li><p>If either $\mathbb{E}_{\mathbf{p}_x} (\varphi)$ or $\mathbb{E}_\mathbf{p}(\varphi\circ x)$ exists, then<br>$$<br>\int_Y\varphi d\mathbf{p}_x=\int_X(\varphi\circ x)d\mathbf{p}<br>$$</p>
</li>
</ul>
<blockquote>
<p>The Change of Variables Formula remains valid in the context of any measure space. </p>
</blockquote>
<blockquote>
<p>Note that when $Y = \mathbb{R} $, the distribution function induced by $\mathbf {p}_x $is the distribution function of $x$, and denoted by $F_x$.</p>
<p>And the distribution induced by $F_x$ is the Lebesgue-Stieltjes probability measure actually, that is $\mathbf{p}_x=\ell_x$</p>
</blockquote>
<h2 id="Examples-and-Exercises"><a href="#Examples-and-Exercises" class="headerlink" title="Examples and Exercises"></a>Examples and Exercises</h2><p><strong>Example 2.5</strong>:</p>
<ul>
<li><p>Let $x$ be a nonnegative random variable on a probability space $\mathbb(X,\Sigma,\mathbf{p})$ such that $x(X)$ is countable.</p>
</li>
<li><p>The Change of Variables Formula says that the expectation of $x$ equals the Lebesgue integral of the identity function on $x(X)$ with respect to the probability measure $\mathbf{p}_x$.</p>
</li>
<li><p>Therefore,<br>$$<br>\mathbb{E}(x)=\sum_{a\in x(X)}a\mathbf{p}{x=a}<br>$$</p>
</li>
</ul>
<p><strong>Example 2.6, Geometric distribution</strong>:</p>
<ul>
<li><p>Take any $p\in (0,1)$ and let $x$ be an $\mathbb{N}$-valued random variable on a probability space $(X,\Sigma, \mathbf{p})$ such that $\mathbf{p}{x = i} = p(1-p)^{i-1}$ for each $i\in\mathbb{N}$. </p>
</li>
<li><p>Such a random variable is said to have a <strong>geometric distribution</strong> with parameter $p$.<br>$$<br>\mathbb{E}(x)=p+2p(1-p)+3p(1-p)^2 +\cdots=\frac{p}{1-p}\sum^\infty_{i=1}i(1-p)^i=\frac{p}{1-p}\frac{1-p}{1-(1-p)^2}=\frac{1}p<br>$$</p>
</li>
</ul>
<p><strong>Example 2.7, Poisson distribution</strong>:</p>
<ul>
<li><p>Given a positive real number  $\lambda&gt; 0$, a $\mathbb{Z}_+$-valued random variable $x$ on a probability space $(X,\Sigma, \mathbf{p})$ such that<br>$$<br>\mathbf{p}{x=i}=\frac{e^{-\lambda}\lambda^i}{i!},\ \ \ i=0,1,\dots<br>$$</p>
</li>
<li><p>is said to have a Poisson distribution with parameter $\lambda$.</p>
</li>
<li><p>Since $e^\lambda=1+\lambda+\frac{\lambda^2}{2}+\frac{\lambda^3}{3!}+\cdots$</p>
</li>
<li><p>We have $\mathbb{E}(x)=\lambda$, $\mathbb{E}(x^2)=\lambda+\lambda^2$ and $\mathbb{V}(x)=\lambda$.</p>
</li>
</ul>
<p><strong>Example</strong>:</p>
<ul>
<li><p>Consider the experiment of throwing a single die, that is, the probability space $(X, 2^X,\mathbf{p})$ where $X := [6]$ and $\mathbf{p}(S) := \frac{|S|}{6} $ for all $S\in 2^X$.</p>
</li>
<li><p>Consider the random variable $x\in[2]^X$ which is defined as<br>$$<br>x(\omega):=\left{\begin{matrix}1,&amp;\mbox{ if }\omega\mbox{ is even}\2, &amp;\mbox{ if }\omega\mbox{ is odd}\end{matrix}\right.<br>$$</p>
</li>
<li><p>In addition, define $\varphi : [2] \to \mathbb{R}$ by $\varphi(t) := t^2$, and observe that $\varphi$ is a ${1,4}$-valued random variable on $([2], 2^{[2]},\mathbf{p}_x)$.</p>
</li>
<li><p>Clearly, we have $\mathbb{E}_{\mathbf{p}_x} (\varphi) = (1) \frac{1}{2} + (4) \frac{1}{2} = \frac{5}{2}$.</p>
</li>
<li><p>On the other hand, $\varphi\circ x$ is a ${1,4}$-valued random variable on $(X,2^X,\mathbf{p})$ that takes value $1$ if the outcome of the experiment is even and $4$ if the outcome is odd. </p>
</li>
<li><p>Thus, we have $\mathbb{E}_{\mathbf{p}} (\varphi\circ x) = (1) \frac{1}{2} + (4) \frac{1}{2} = \frac{5}{2}$.</p>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T13:52:59.000Z" title="12/15/2020, 9:52:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-F-Expectation-Lebesgue-Integral-and-Stieltjes-Integral/">1.1.F Expectation, Lebesgue Integral, and Stieltjes Integral</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/10%20Expectation%20via%20the%20Lebesgue%20Integral/The-Expectation-Functional-of-Simple-Random-Variables/">The Expectation Functional of Simple Random Variables</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Expectation of Simple Random Variables</strong>:</p>
<ul>
<li><p>Let $(X,\Sigma, \mathbf{p})$ be a probability space. </p>
</li>
<li><p>The set of all simple random variables on $(X,\Sigma, \mathbf{p})$ is a linear space relative to the pointwise defined addition and scalar multiplication operations.</p>
</li>
<li><p>By definition, for any simple random variable $x$ on $(X,\Sigma, \mathbf{p})$, we have $|x(X)| &lt; \infty$ and<br>$$<br>x=\sum_{a\in x(X)}a\mathbf{1}_{x=a}<br>$$</p>
</li>
<li><p>where $\mathbf{1}_{ {x=a} }$ stands for the indicator function of the event ${x = a}\in\Sigma$ on $X$.</p>
</li>
<li><p>We define the <strong>expectation</strong> of any such $x$ as the real number<br>$$<br>\mathbb{E}(x):=\sum_{a\in  x(X)}a\mathbf{p}{x=a}<br>$$</p>
</li>
<li><p>Thus, the expected value of $x$ is the weighted average of its values, where the weight of $a$ is $\mathbf{p}<em>x{a}$ for each $a\in x(X)$. That is, $\mathbf{E}(x) =\sum</em>{a\in x(X)}\mathbf{p}_x{a}$.</p>
</li>
</ul>
<blockquote>
<p>Linearity of $\mathbb{E}$:<br>$$<br>\mathbb{E}(x+y)=\mathbb{E}(x)+\mathbb{E}(y)<br>$$<br>Monotonicity of $\mathbb{E}$:<br>$$<br>\mathbb{E}(x) \geq \mathbb{E}(y)\mbox{ whenever }x\geq_{a.s.}y<br>$$</p>
<p>$$<br>\mathbb{E}(x)= \mathbb{E}(y)\mbox{ whenever }x=_{a.s.}y<br>$$</p>
</blockquote>
<p><strong>Variance of Simple Random Variables</strong>:</p>
<ul>
<li><p>The <strong>variance</strong> of a simple random variable $x$ on $(X,\Sigma,\mathbf{p})$ is the number<br>$$<br>\mathbb{V}(x) := \mathbb{E}((x - \mathbb{E}(x))^2)<br>$$</p>
</li>
<li><p>where $(x-\mathbb{E}(x))^2$ is the simple random variable $\omega\mapsto (x(\omega) -\mathbb{E}(x))^2$ on $(X,\Sigma, \mathbf{p})$.</p>
</li>
</ul>
<blockquote>
<p>However, it is often more convenient to use the alternate formula<br>$$<br>\mathbb{V}(x) := \mathbb{E}(x^2) - \mathbb{E}(x)^2<br>$$</p>
</blockquote>
<p><strong>Expectation of Nonnegative Random Variables</strong></p>
<ul>
<li><p>Let $x$ be a $[0, \infty]$-valued random variable on a probability space $(X,\Sigma,\mathbf{p})$. </p>
</li>
<li><p>We define the <strong>expectation</strong> of $x$ as the (extended real) number<br>$$<br>\mathbb{E}(x) := \sup{\mathbb{E}(z) : z \in \mathfrak{L}(x)}<br>$$</p>
</li>
<li><p>where $\mathfrak{L}(x)$ stands for the set of all simple random variables $z$ such that $z\leq x$.</p>
</li>
<li><p>In turn, the <strong>variance</strong> of $x$ is defined as the (extended real) number<br>$$<br>\mathbb{V}(x) := \mathbb{E}((x - \mathbb{E}(x))^2),<br>$$</p>
</li>
<li><p>provided that $\mathbb{E}(x) &lt; \infty$. </p>
</li>
<li><p>where $(x-\mathbb{E}(x))^2$ is the simple random variable $\omega\mapsto (x(\omega) -\mathbb{E}(x))^2$ on $(X,\Sigma, \mathbf{p})$.</p>
</li>
</ul>
<blockquote>
<p>These definitions agree with those in the case of simple random variables on $(X,\Sigma, \mathbf{p})$. Moreover, they extend those definitions to the case of $[0,\infty]$-valued simple random variables.</p>
</blockquote>
<blockquote>
<p>In words, the (extended real) number $\mathbb{E}(x)$ is defined as the supremum of the weighted averages of all those simple random variables that are ‚Äúsmaller than‚Äù $x$ everywhere. </p>
<p>So, in this sense, the idea behind the definition of $\mathbb{E}(x)$ is reminiscent of that of the computation of the area under a given curve in $\mathbb{R}\times \mathbb{R}_+$ by approximating this area with the sum of the areas of the rectangles that lie under the curve and above the horizontal axis.</p>
<p>Put this way, you should see that $\mathbb{E}(x)$ can be thought of as some sort of an integral of $x$ ‚Äì it is called the <strong>Lebesgue integral</strong> of $x$ with respect to $\mathbf{p}$ ‚Äìwhere the sets in the domain of $x$ (analogous to the bases of the rectangles under the curve) are ‚Äúmeasured‚Äù according to the underlying probability measure.</p>
</blockquote>
<blockquote>
<p>The commonly used notation for the Lebesgue integral of $x$ on $X$ with respect to $\mathbf{p}$ is $\int_Xxdp$, that is<br>$$<br>\int_X xd\mathbf{p}\ \mbox{ and }\ \mathbb{E}(x)<br>$$<br>denote the same (extended real) number. </p>
</blockquote>
<blockquote>
<p>Adopting the widely used conventions of integration theory, we also set<br>$$<br>\int_Sxd\mathbf{p}:=\mathbb{E}(x\mathbf{1}_S)\mbox{ for any } S\in \Sigma,<br>$$<br>where $\mathbf{1}_S$ is the indicator function of $S$ on $X$. Therefore, recalling the definition of the expectation of a simple random variable, we see that $\int_S d\mathbf{p}$, that is, the Lebesgue integral of the constant function $1$ with respect to $\mathbf{p}$ on $S$, and $\mathbb{E}(\mathbf{1}_S )$ denote the same number, namely, $\mathbf{p}(S)$, for any $S\in\Sigma$.</p>
</blockquote>
<blockquote>
<p>Many authors write<br>$$<br>\int_X x(\omega)\mathbf{p}(dw)<br>$$<br>instead of $\int_Xxd\mathbf{p}$. The Lebesgue integral of the map $\omega\mapsto\omega^2$ on the probability space $([0,1],\mathcal{B}[0,1],\ell)$ is, for instance, written as $\int_{[0,1]}\omega^2\ell(d\omega)$. </p>
</blockquote>
<p><strong>Lebesgue Integration of Simple Maps</strong>:</p>
<ul>
<li><p>Let $(X,\Sigma,\mu )$ be a measure space. </p>
</li>
<li><p>By <strong>a nonnegative simple $\Sigma$-measurable map</strong> on $X$, we mean a real function $f\in \mathcal{L}^0(X,\Sigma)$ such that $f\geq0$ and $f(X)$ is finite. </p>
</li>
<li><p>The <strong>Lebesgue integral</strong> of any such map with respect to $\mu$ is defined as the number<br>$$<br>\int_Xfd\mu:=\sum_{a\in f(X)}a\mu{f=a},<br>$$</p>
</li>
<li><p>where we adopt the convention that $0\cdot\infty$ equals $0$.</p>
</li>
</ul>
<p><strong>Lebesgue Integration of Nonnegative Maps</strong>:</p>
<ul>
<li><p>Let $(X,\Sigma,\mu)$ be a measure space. </p>
</li>
<li><p>The <strong>Lebesgue integral of any $\Sigma$-measurable</strong> $f : X \to [0, \infty]$ with respect to $\mu$ is defined as the (extended) real number<br>$$<br>\int_X fd\mu:=\sup{\int_Xhd\mu:h\in\mathfrak{M}(f)}<br>$$</p>
</li>
<li><p>where $\mathfrak{M}(f)$ stands for the set of all nonnegative simple $\Sigma$-measurable maps $h$ on $X$ with $h\leq f$. </p>
</li>
<li><p>In turn, we define<br>$$<br>\int_S fd\mu:=\int_X f\mathbf{1}_S d\mu\ \ \ \ \mbox{ for any }S\in\Sigma<br>$$</p>
</li>
<li><p>where $\mathbf{1}_S$ is the indicator function of $S$ on $X$.</p>
</li>
</ul>
<p><strong>$\sigma$-finite Measure</strong>:</p>
<ul>
<li>Let $(X,\Sigma,\mu)$ be a measure space. </li>
<li>We say that this space (or $\mu$ itself) is <strong>$\sigma$-finite</strong> if there is a countable partition $\mathcal{S}$ of $X$ such that $\mathcal{S}\subseteq \Sigma$ and $\mu(S) &lt; \infty$ for each $S \in\mathcal{S}$</li>
</ul>
<p><strong>Absolutely Continuous, Density Function, Density</strong>:</p>
<ul>
<li><p>Let $F$ be a distribution function. </p>
</li>
<li><p>We say that $F$ is <strong>absolutely continuous</strong> (with respect to the Lebesgue measure) if there is a Borel measurable map $f : \mathbb{R} \to \mathbb{R}<em>+$ such that<br>$$<br>F(t)=\int</em>{(-\infty,t]}fd\ell<br>$$</p>
</li>
<li><p>for every real number $t$.</p>
</li>
<li><p>When this is the case, we say that $F$ is induced by the <strong>density function</strong> $f$, and refer to $f$ as a <strong>density</strong> for $F$.</p>
</li>
</ul>
<blockquote>
<p>When $f$ is a density for $F$, $F(t)-F(s)=\int_{(s,t]}fd\ell$ for any real numbers $s$ and $t$ with $t &gt; s$.</p>
</blockquote>
<blockquote>
<p>Some distribution functions do not have closed form decriptions, but they are rather defined through integrating a density function.</p>
<p>The most important example of such a function is the so-called <strong>normal distribution</strong> function (with parameters $\mu $ and $\sigma$). For any given real numbers $\mu$ and $\sigma&gt;0$, this function $F$ is defined by<br>$$<br>f(t)=\frac{1}{\sqrt{2\pi}}e^{\frac{(t-\mu)^2}{2\sigma^2}}<br>$$<br>for any real number $t$, it is thus trivially absolutely continuous.</p>
<p>If  $\mu= 0$ and $\mu = 1$ here, this function is called the <strong>standard normal distribution</strong> <strong>function</strong>.</p>
</blockquote>
<blockquote>
<p>Not all distribution function arises from a density funtion.</p>
</blockquote>
<p><strong>Absolutely Continuous Measures</strong>:</p>
<ul>
<li>Let $(X,\Sigma)$ be a measurable space, and $\mu$ and $\nu$  two measures on $\Sigma$. </li>
<li>We say that $\mu$ is <strong>absolutely continuous with respect to $\nu$</strong>, this is denoted by writing    $\mu\ll\nu$ </li>
<li>if $\mu(S) = 0$ for every $S\in\Sigma$  with $\nu(S) = 0$.</li>
</ul>
<blockquote>
<p>The zero measure on $\Sigma$ is absolutely continuous with respect to any measure on $\Sigma$</p>
<p>While the counting measure on $\Sigma$ is not absolutely continuous with respect to any measure $\nu$ on $\Sigma$  such that $\nu(S) = 0$ for some nonempty $S\in\Sigma$ .</p>
</blockquote>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Proposition 1.1</strong>: </p>
<ul>
<li><p>For any $[0,\infty]$-valued random variables $x$ and $y$ (on a given probability space),<br>$$<br>x\geq_{a.s.}y\ \ \ \ \mbox{ implies }\ \ \ \ \mathbb{E}(x) \geq \mathbb{E}(y)<br>$$</p>
<p>$$<br>x=_{a.s.}y\ \ \ \ \mbox{ implies }\ \ \ \ \mathbb{E}(x) = \mathbb{E}(y)<br>$$</p>
</li>
</ul>
<p><strong>The Monotone Convergence Theorem 1</strong>:</p>
<ul>
<li>Let $x, x_1,x_2,\dots$ be $[0,\infty]$-valued random variables on a probability space $(X,\Sigma, \mathbf{p})$. Then,<br>$$<br>x_m \uparrow_{a.s.} x\ \ \ \ \ \mbox{ implies }\ \ \ \ \ \ \mathbb{E}(x_m)\uparrow \mathbb{E}(x)<br>$$</li>
</ul>
<p><strong>Proposition 1.2</strong>: </p>
<ul>
<li>Let $x$ and $y$ be two $[0,\infty]$-valued random variables on a probability space $(X,\Sigma, \mathbf{p})$. Then, for any $a\geq 0$,<br>$$<br>\mathbb{E}(ax+y)=a\mathbb{E}(x)+\mathbb{E}(y)<br>$$</li>
</ul>
<p><strong>Proposition 1.3</strong>: </p>
<ul>
<li><p>Let $(X,\Sigma,\mu )$ be a finite measure space. Then, there is a real number  $\lambda\geq 0$ and a probability measure $\mathbf{p}$ on $\Sigma$ such that<br>$$<br>\int_Xfd\mu=\lambda\int_Xfd\mathbf{p}<br>$$</p>
</li>
<li><p>for every $\Sigma$-measurable $f : X \to [0,\infty]$.</p>
</li>
</ul>
<p><strong>Proposition 1.5</strong>:</p>
<ul>
<li><p>Given any measure space $(X,\Sigma,\mu )$,<br>$$<br>\int_x(af+g)d\mu=a\int_Xfd\mu+\int_Xgd\mu<br>$$</p>
</li>
<li><p>for every $a\geq0$ and $\Sigma$-measurable $f : X \to [0,\infty]$.</p>
</li>
</ul>
<p><strong>Proposition 1.6</strong>: </p>
<ul>
<li>Every absolutely continuous distribution function is uniformly continuous.</li>
</ul>
<blockquote>
<p>If a distribution function is not continuous even at a single point, then it cannot possibly possess a density.</p>
<p>The converse of Proposition 1.6 is false. Indeed, even a continuous distribution function need not possess a density.</p>
</blockquote>
<p><strong>Proposition 1.7</strong>:</p>
<ul>
<li><p>Let $(X,\Sigma,\nu )$ be a measure space and take any $f\in \mathcal{L}^0_+(X,\Sigma )$. </p>
</li>
<li><p>Then, the map $\mu:\Sigma \to\mathbb{R}$ defined by<br>$$<br>\mu(S):=\int_S fd\nu,<br>$$</p>
</li>
<li><p>is a measure on $\Sigma$ with  $\mu\ll\nu$ . </p>
</li>
<li><p>If $\nu$ is $\sigma$-finite, so is $\mu$.</p>
</li>
</ul>
<p><strong>The Radon-Nikodym Theorem</strong>:</p>
<ul>
<li>Let $(X,\Sigma)$ be a measurable space, and $\mu$ and $\nu$ two $\sigma$-finite measures on $\Sigma$ with $\mu\ll\nu$. Then, there is an $f\in \mathcal{L}^0_+ ( X ,\Sigma)$ such that<br>$$<br>\mu(S)=\int_Sfd\nu\mbox{ for every }S\in\Sigma<br>$$</li>
</ul>
<blockquote>
<p>Any map $f\in\mathcal{L}^0_+(X,\Sigma)$ such that above equation holds is commonly referred to as either the <strong>density of $\mu$ with respect to $\nu$</strong> or as the <strong>Radon-Nikodym derivative of $\mu$ with respect to $\nu$</strong>. </p>
<p>It is quite standard to denote any such map as $\frac{d\mu}{d\nu}$.</p>
</blockquote>
<p><strong>Proposition 1.8</strong>:</p>
<ul>
<li>Let $F$ be a distribution function and $\mathbf{p}_F$ the Lebesgue-Stieltjes probability measure on $\mathbb{R}$ induced by $F$. </li>
<li>Then, $F$ is absolutely continuous iff, $\mathbf{p}_F$ is absolutely continuous with respect to $\ell$.</li>
</ul>
<h2 id="Examples-and-Exercises"><a href="#Examples-and-Exercises" class="headerlink" title="Examples and Exercises"></a>Examples and Exercises</h2><p><strong>Example 1.1, Binomial Distribution</strong>: </p>
<ul>
<li><p>Let $n$ be a positive integer and $p$ a number in $[0, 1]$.</p>
</li>
<li><p>A ${0,\dots, n}$-valued random variable $x$ on a probability space $(X,\Sigma,\mathbf{p})$ such that<br>$$<br>\mathbf{p}{x=i}=\left(\begin{matrix}n\ i\end{matrix}\right)p^i(1-p)^{n-i},\ \ \ \ i=0,\dots,n<br>$$</p>
</li>
<li><p>is said to have a binomial distribution with parameters $n$ and $p$</p>
</li>
<li><p>If $n = 1$ here, we say that $x$ has a Bernoulli distribution with parameter $p$</p>
</li>
<li><p>When $n = 1$, we have $\mathbb{E}(x) = p(1) + (1-p)(0) = p$, that is, the expected value of any random variable that has a Bernoulli distribution with parameter $p$ is $p$.</p>
</li>
<li><p>In this case, we also find that $\mathbb{E}(x^2) = p$, so $\mathbb{V}(x) = p -p^2$</p>
</li>
<li><p>More generally, for any random variable that has a binomial distribution with parameters $n$ and $p$, we have<br>$$<br>\mathbb{E}(x)=\sum^n_{i=0}\left(\begin{matrix}n\ i \end{matrix}\right)p^i(1-p)^{n-i}i=np\sum^{n-1}_{i=0}\left(\begin{matrix}n-1\ i \end{matrix}\right)p^i(1-p)^{(n-1)-i}<br>$$</p>
</li>
<li><p>so, by the Binomial Theorem, $\mathbb{E}(x) = np(p + (1 -p))^{n-1} = np$. By using a similar</p>
<p>method, we can also show that $\mathbb{E}(x^2) = n^2 p^2 -np^2 + np$, so $\mathbb{V}(x) = np(1-p)$.</p>
</li>
</ul>
<p><strong>Example 1.3</strong>:</p>
<ul>
<li><p>Let $(X,2^X,\mathbf{p})$ be a probability space with $X$ being a countable set. </p>
</li>
<li><p>We wish to find an expression for the expectation of an arbitrary nonnegative random variable $x$ on $(X,2^X,\mathbf{p})$.</p>
</li>
<li><p>Assume that $X$ is countably infinite, and enumerate it as $X := {\omega_1,\omega_2,\dots}$. </p>
</li>
<li><p>For every positive integer $m$, let us define the simple random variable<br>$$<br>x_m(\omega)=\left{\begin{matrix}x(\omega),&amp;\mbox{ if }\omega\in{\omega_1,\dots,\omega_m}\0,&amp;\mbox{otherwise}\end{matrix}\right.<br>$$</p>
</li>
<li><p>By definition of $\mathbb{E}$ for simple random variables, we have $\mathbb{E}(x_m) =\sum_{i\in[m]} x(\omega_i)\mathbf{p}{\omega_i}$ for each $m$.</p>
</li>
<li><p>But, $x_m \uparrow x$, so we have $\mathbb{E}(x_m)\uparrow \mathbb{E}(x)$ by the Monotone Convergence Theorem 1. Consequently,<br>$$<br>\mathbb{E}(x)=\lim\mathbb{E}(x_m)=\lim\sum_{i\in[m]}x(\omega_i)\mathbf{p}{\omega_i}=\sum^\infty_{i=1}x(\omega_i)\mathbf{p}{\omega_i}=\sum_{x\in X}x(\omega)\mathbf{p}{\omega}<br>$$</p>
</li>
<li><p>for any nonnegative random variable $x$ on $(X,2^X,\mathbf{p})$.</p>
</li>
</ul>
<p><strong>Example 1.5</strong>: </p>
<ul>
<li><p>For any real numbers $a$ and $b$ with $a &lt; b$, the uniform distribution $F$ on $[a,b]$ is absolutely continuous.</p>
</li>
<li><p>The map $f:\mathbb{R}\to\mathbb{R}+$ where<br>$$<br>f(t)=\left{\begin{matrix}\frac{1}{a-b},&amp;0\leq t\leq b\0,&amp;\mbox{otherwise}\end{matrix}\right.<br>$$</p>
</li>
<li><p>is a density for that distribution function. </p>
</li>
<li><p>Similarly, for any $\lambda &gt; 0$, the exponential distribution with parameter $\lambda$ ,is absolutely continuous.</p>
</li>
<li><p>The map $f:\mathbb{R}\to\mathbb{R}+$ where<br>$$<br>f(t)=\left{\begin{matrix}\lambda e^{-\lambda t},&amp; t\geq 0\0,&amp;\mbox{otherwise}\end{matrix}\right.<br>$$</p>
</li>
<li><p>is a density for that distribution function. </p>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T13:51:59.000Z" title="12/15/2020, 9:51:59 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-E-Probability-via-Measure-Theory/">1.1.E Probability via Measure Theory</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/9%20Random%20Variables/The-Distribution-of-a-Random-Variable/">The Distribution of a Random Variable</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Image Measure of $\mu$ by $f$</strong>: </p>
<ul>
<li>Let $(X_1,\Sigma_1)$ and $(X_2,\Sigma_2)$ be two measurable spaces, and $f : X_1\to X_2$ a $\Sigma_1\backslash\Sigma_2$-measurable function. </li>
<li>For any measure $\mu$ on $\Sigma_1$, the map $\mu_f : \Sigma_2 \to [0, \infty]$, defined by</li>
</ul>
<p>$$<br>\mu_f(S):=\mu(f^{-1}(S))<br>$$</p>
<ul>
<li>is called <strong>the image measure of $\mu$ by $f$.</strong></li>
</ul>
<p><strong>Distribution</strong>: </p>
<ul>
<li>Let $Y$ be a metric space. </li>
<li>For any $Y $-valued random variable $x$ on a probability space $(X,\Sigma,\mathbf{p})$, the image measure of $\mu$ by $x$ (where we think of $x$ as $\Sigma\backslash \mathcal{B}(Y )$-measurable) is called the <strong>distribution</strong> of $x$</li>
<li>that is, $\mathbf {p}_x$ is the Borel measure on $Y$ such that</li>
</ul>
<p>$$<br>\mathbf{p}_x(S):=\mathbf{p}(x^{-1}(S))\ \ \mbox{ for each }\ S\in\mathcal{B}(Y)<br>$$</p>
<blockquote>
<p>For the single measure on the probability space $(X,\Sigma,\mathbf{p})$, if we have different random variables, we will have different distributions.</p>
</blockquote>
<blockquote>
<p>For any metric space $Y$, the distribution $\mathbf{p}_x$ of a $Y$-valued random variable $x$ on a probability space $(X,\Sigma,\mathbf{p})$ describes the probabilities for every event that may involve $x$. </p>
</blockquote>
<p><strong>Distribution Function</strong>: </p>
<ul>
<li>When $x$ is a random variable that is, $Y = \mathbb{R} $, the distribution function induced by $\mathbf {p}_x $is called the <strong>distribution function</strong> of $x$. </li>
<li>We denote this distribution function by $F_x$, and say that $x$ is <strong>continuous</strong> if $F_x$ is a continuous function. </li>
<li>On the other hand, we say that $x$ is discrete if $F_x$ is a <strong>discrete</strong> distribution function.</li>
</ul>
<blockquote>
<p>We often describe the probabilistic behavior of a random variable by specifying its distribution function directly. So, the statement<br>$$<br>x \mbox{ is a random variable on }X \mbox{ with the distribution function }F<br>$$<br>means that $x$ is a random variable on some probability space $(X,\Sigma,\mathbf{p})$ such that the distribution of $x$ is the Lebesgue-Stieltjes probability measure induced by $F$, that is, $F = F_x$.</p>
</blockquote>
<blockquote>
<p>For the single measure on the probability space $(X,\Sigma,\mathbf{p})$, if we have different random variables, we will also have different distribution functions.</p>
</blockquote>
<p><strong>Equal $\mu$-almost everywhere, Equal almost surely</strong>: </p>
<ul>
<li>Let $Y$ be a separable metric space, and $x$ and $y$ two $Y $-valued random variables on a measure space $(X,\Sigma,\mu)$. </li>
<li>If $\mu{x\neq y}=0$, we say that $x$ and $y$ are <strong>equal $\mu$-almost everywhere</strong>, and write $x=_{\mu-a.e.} y$. </li>
<li>But if $\mu$ is a probability measure, and $x$ and $y$ are equal $\mu$-almost everywhere; that is, when $\mu{x = y} = 1$, we say that $x $ and $y$ are <strong>equal almost surely</strong> (assuming that $\mu$ is understood from the context), and write $x =_{a.s.} y$.</li>
</ul>
<p><strong>$x$ large than $y$ $\mu$-almost everywhere, larger than $y$ almost surely</strong>: </p>
<ul>
<li>Let $x$ and $y$ be two $\overline{\mathbb{R}}$-valued random variables on a measure space $(X,\Sigma,\mu)$. If ${x &lt; y} = 0$, we say that $x$ is <strong>larger than $y$ $\mu$-almost everywhere</strong>, and write $x\geq_{\mu-a.e.} y$. </li>
<li>But if $\mu$ is a probability measure, and $x$ is larger than $y$ $\mu$-almost everywhere, that is, when ${x \geq y} = 1$, we say that $x$ is <strong>larger than $y$ almost surely</strong> (assuming that $\mu$ is understood from the context), and write $x\geq_{a.s.} y$. </li>
<li>The expressions ‚Äú$x\leq_{\mu-a.e.}y$‚Äù and ‚Äú$x\leq_{a.s.} y$‚Äù are understood similarly.</li>
</ul>
<p><strong>Converge Almost Surely</strong>: </p>
<ul>
<li>Let $Y$ be a separable metric space, and let $x,x_1,x_2,\cdots$ be a $Y$-valued random variables on a probability space $(X,\Sigma, \mathbf{p})$. </li>
<li>We say that $(x_m)$ <strong>converges almost surely to $x$</strong> (or that $x$ is an <strong>almost sure limit</strong> of $(x_m)$) whenever $\mathbf{p}{x_m\to x}=1$, that is,</li>
</ul>
<p>$$<br>\mathbf{p}{\omega\in X : d_Y (x_m(\omega),x(\omega)) \to 0} = 1.<br>$$</p>
<ul>
<li>In this case, we write $x_m\to_{a.s.} x$, but if $x$ is a constant map, say, $x =\nu $ for some $\nu\in Y$, we abuse notation and write $x_m\to_{a.s.}\nu $.</li>
</ul>
<h2 id="Examples-and-Exercises"><a href="#Examples-and-Exercises" class="headerlink" title="Examples and Exercises"></a>Examples and Exercises</h2><p><strong>Uniform Distribution</strong>: </p>
<ul>
<li>Let $a $ and $b$ be two real numbers with $a &lt; b$. </li>
<li>Consider the distribution function $F$ where $F |<em>{(-\infty,a)} = 0,\ F|</em>{(b,\infty) }= 1$, and</li>
</ul>
<p>$$<br>F(t)=\frac{t-a}{b-a},\ \ \ a\leq t\leq b.<br>$$</p>
<ul>
<li>This distribution function, as well as the Lebesgue-Stieltjes probability measure induced by it, is called the uniform distribution on $[a, b]$.</li>
<li>In turn, a random variable with the uniform distribution on $[a,b]$ is often referred to as a ‚Äúrandom variable which is uniformly distributed on $[a, b]$‚Äù.</li>
</ul>
<p><strong>Exponential Distribution</strong>: </p>
<ul>
<li>Let $\lambda$ be a positive real number. </li>
<li>Consider the distribution function $F$ where $F|_{(-\infty;0)} = 0$ and</li>
</ul>
<p>$$<br>F(t)=1-e^{-\lambda t}, \ \ \ \ t\geq0.<br>$$</p>
<ul>
<li>This distribution function, as well as the Lebesgue-Stieltjes probability measure induced by it, is called the exponential distribution with parameter $\lambda$. </li>
<li>In turn, a random variable with the exponential distribution with parameter  is often referred to as a ‚Äúrandom variable which is exponentially distributed with parameter $\lambda$‚Äù.</li>
</ul>
<p><strong>Remark 2.1</strong>:</p>
<ul>
<li><p>There is a one-to-one correspondence between any two of the following three concepts:</p>
<ol>
<li><p>Borel probability measures on $\mathbb{R} $</p>
</li>
<li><p>Distribution functions</p>
</li>
<li><p>Random variables on $ ((0, 1), \mathcal{B}(0, 1),\ell)$, (with different distributions $\ell_x$, actually)</p>
<ul>
<li><p>Every random variable transfers a measure space to a Borel probability space. The measure space is the same, but different random variables transfer it into different Borel probability spaces.</p>
</li>
<li><p>The Lebesgue measure on the measure space equals the probability measure on the Borel measure space.</p>
<ul>
<li><p>If $\mathbf{p}$ is induced by a strictly increasing distribution function, say $F$. </p>
</li>
<li><p>Since $F$ is then a bijection from $\mathbb{R}$ onto $(0,1)$, it is invertible, and we may define in this case $x := F^{-1}$</p>
</li>
<li><p>Since $x$ is increasing, we have $x\in \mathcal{L}^0((0,1), \mathcal{B}(0,1))$. </p>
</li>
<li><p>Moreover,<br>$$<br>\ell_x(a, b] = \ell(x^{-1}(a), x^{-1}(b)] = F (b)-  F (a) = \mathbf{p}(a, b]<br>$$<br>for any $-\infty \leq a \leq b &lt; 1$<br>$$<br>\ell_x(a,\infty) = 1 - F (a) = \mathbf{p}(a,\infty)<br>$$<br>for any $-\infty\leq  a$.</p>
</li>
<li><p>Thus $\ell_x$ and $\mathbf{p}$ agree on the semialgebra of all right-semiclosed intervals. </p>
</li>
<li><p>If $F$ is not invertible, need to define</p>
</li>
<li><p><strong>Pseudo-Inverse</strong>: Define the pseudo-inverse of a distribution function $F$ as the map $F^{-1} :(0,1)\to \mathbb{R} $ with<br>$$<br>F^{-1}(\omega) := \inf {t\in \mathbb{R} : F(t) \geq\omega}.<br>$$</p>
</li>
</ul>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<p><strong>Example 2.3</strong>:</p>
<ul>
<li>Consider the probability space $(\mathbb{N},2^\mathbb{N},\mathbf{p})$ where $\mathbf{p}{i} = 2^{-i}$ for each $i\in \mathbb{N}$. </li>
<li>Any two ($Y$-valued) random variables $x$ and $y$ on this space is almost surely equal to each other is $x = y$.</li>
</ul>
<p><strong>Example 2.3</strong>:</p>
<ul>
<li>Consider the probability space $([0,1], \mathcal{B}[0, 1], \ell)$ and take any two random variables $x$ and $y$ on this space. If $x|<em>{[0,1]\setminus\mathbb{Q} }= y|</em>{[0,1]\setminus\mathbb{Q}}$, then $x =_{a.s.} y$. </li>
<li>Of course, we can replace $\mathbb{Q}$ with any countable subset of $[0, 1]$ in this observation.</li>
</ul>
<p><strong>Example 2.4</strong>: </p>
<ul>
<li>Consider the probability space $([0,1], \mathcal{B}[0, 1], \ell)$.</li>
<li>Consider the sequence $(x_m) $ in $\mathbb{R}^{[0,1]}$ where $x_m(\omega) := 1 + \omega^m$. Then, $x_m\to 1$ is false, because $x_m(1) = 2$ for each $m$, and yet ${x_m\to 1} = [0, 1)$, and hence $x_m \to_{a.s.} 1$.</li>
</ul>
<p><strong>Example 2.4</strong>: </p>
<ul>
<li>Consider the probability space $([0,1], \mathcal{B}[0, 1], \ell)$.</li>
<li>Consider the sequence $(y_m)$ in $\mathbb{R}^{[0,1]}$ where $y_m$ is the indicator function of $[0, \frac{m+1}{2m}]$ on $[0,1]$. Then, $y_m\to_{a.s}. \mathbf{1}_{[0,\frac{1}{2})}$, but $y_m(\frac{1}{2}) = 1$ for each $m$.</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T13:51:55.000Z" title="12/15/2020, 9:51:55 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-E-Probability-via-Measure-Theory/">1.1.E Probability via Measure Theory</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/9%20Random%20Variables/Random-Variables/">Random Variables</a></h1><div class="content"><p>One is often interested in a particular characteristic of the (uncertain) outcomes of an experiment. To deal with such situations we may want to transform the given probability space (that models the underlying experiment) into another probability space the sample space of which contains the set of all values of the characteristic that we are interested in. </p>
<p>This is achieved by means of a measurable function, which is more commonly referred to as a random variable in probability theory. In the most general sense of the term, such a function maps one measurable space into another. </p>
<p>However, most measurable functions that are encountered in practice map a measurable space into a metric space, leading to the notion of Borel measurability. </p>
<h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Measurable</strong>: </p>
<ul>
<li>Let $(X_1,\Sigma_1)$ and $(X_2,\Sigma_2)$ be two measurable spaces. </li>
<li>We say that a function $f : X_1\rightarrow X _2$ is **$\Sigma_1\backslash\Sigma_2$-measurable** if $f^{-1}(S) \in \Sigma_1$ for every $S \in \Sigma_2 $.</li>
</ul>
<p><strong>Random Variable, $\Sigma$-Measurable Real Function, Borel Measurable</strong>: </p>
<ul>
<li><p>Let $(X,\Sigma)$ be a measurable space and $Y$ a metric space. </p>
</li>
<li><p>A function $x : X\rightarrow Y$ is called a <strong>$Y$-valued random variable</strong> on $(X,\Sigma)$ if it is $\Sigma\backslash \mathcal{B}(Y)$-measurable, that is, if $x^{-1}(S)\in\Sigma$  for every $S\in \mathcal{B}(Y )$. </p>
</li>
<li><p>An $\mathbb{R} $-valued random variable is simply called a <strong>random variable</strong> on $(X,\Sigma)$.</p>
<ul>
<li>The set of all random variables on a measurable space $(X,\Sigma )$ is denoted by $\mathcal {L}^0(X,\Sigma)$. Moreover, we define<br>$$<br>L^0_+(X,\Sigma) := {x \in \mathcal{L}^0(X,\Sigma) : x\geq 0}.<br>$$</li>
</ul>
</li>
<li><p>In real analysis what we call here a random variable on $(X,\Sigma )$ is called a <strong>$\Sigma$-measurable real function</strong> on $X$. </p>
</li>
<li><p>Furthermore, a ($Y$-valued) random variable on a Borel probability space is said to be <strong>Borel measurable</strong>. </p>
</li>
</ul>
<blockquote>
<p>Let $(X,\Sigma)$ be a measurable space and $Y$ a metric space. In principle, to verify that a map $x:X\to Y$ is a $Y$-valued random variable, we need to show that $x^{-1}(B)\in\Sigma$ for every Borel subset $B$ of $Y$ .</p>
<p>Fortunately, there is a nice short-cut. If we can find a collection $\mathcal{A}$ of subsets of $Y$ that generates $\mathcal{B}(Y)$ and if we manage to verify that $x^{-1}(\mathcal{A})$  for every $A\in\mathcal{A}$ we may then conclude that $x$ is a $Y$-valued random variable.</p>
<p>For instance, if<br>$$<br>x^{-1}(O)\in\Sigma\mbox{ for every open subset }O \mbox{ of }Y,<br>$$<br>or<br>$$<br>x^{-1}(C)\in\Sigma\mbox{ for every closed subset }C \mbox{ of }Y,<br>$$<br>then $x$ is sure to be a $Y$-valued random variable.</p>
</blockquote>
<blockquote>
<p>The fact that the set of all intervals of the form $(-\infty,a]$, or of the form $(1,a)$, generates $\mathcal{B}(\mathbb{R})$ is used frequently, so it is probably a good idea to state it separately.</p>
<p>Given any measurable space $(X,\Sigma)$ and a map $x : X \rightarrow \mathbb{R} $, we have<br>$$<br>x\in\mathcal{L}^0(X,\Sigma)\mbox{ iff }{\omega\in X:x(\omega)\leq a}\in\Sigma\  \mbox{ for every } a\in\mathbb{R}<br>$$</p>
<p>and<br>$$<br>x\in\mathcal{L}^0(X,\Sigma)\mbox{ iff }{\omega\in X:x(\omega)&lt; a}\in\Sigma\  \mbox{ for every } a\in\mathbb{R}<br>$$</p>
<p>In measure theory and probability, we simply write ${x \leq a}$ for the set ${ \omega\in X : x(\omega) \leq a}$. While it may take a bit getting used to at first, this type of shorthand notation simplifies complex expressions considerably. For instance, with this notational convention, they we have<br>$$<br>x\in \mathcal{L}^0(X,\Sigma)\mbox{ iff }{x\leq a}\in\Sigma\ \mbox{ for every } a\in\mathbb{R}<br>$$<br>In what follows, we will work with these sorts of expressions routinely. All you need to do is to remember that, given a probability (or measure) space $(X,\Sigma, \mathbf{p})$, the set<br>$$<br>{\mbox{a statement about random variables defined on this space}}<br>$$<br>equals, by convention,<br>$$<br>{\omega\in X :\mbox{ this statement is true}}<br>$$<br>For any $x,y \in \mathcal{L}^0(X )$, the event that the absolute value of the difference between $x$ and $y$ is strictly larger than $3$ is written as ${|x-y|&gt; 3} $ instead of the mouthful ${\omega\in X : |x(\omega) -y(\omega)| &gt; 3}$. </p>
<p>In turn, the probability of this event is written simply as $\mathbf{p}{|x- y| &gt; 3}$:</p>
</blockquote>
<p><strong>Random $n$-vector, Random Real Sequence, Random Bounded Map, Random Element</strong>: </p>
<ul>
<li>An $\mathbb{R}^n$-valued random variable as a <strong>random $n$-vector</strong> if $n \geq 2$. </li>
<li>Analogously, an $\mathbb{R}^{\infty}$-valued random variable may be called a <strong>random real sequence</strong></li>
<li>A $\mathbf{B}[0,1]$-valued random variable is a <strong>random bounded map</strong> on $[0,1]$ and so on. </li>
<li>More generally, a $Y$-valued random variable (for any metric space $Y$) is sometimes referred to as a <strong>random element</strong> of $Y$.</li>
</ul>
<p><strong>Simple</strong>: </p>
<ul>
<li>Let $Y$ be a metric space. A $Y$-valued random variable $x$ is called <strong>simple</strong> if it takes finitely many values, that is, when the range of $x$ is a finite set.</li>
</ul>
<p><strong>Postive Parts, Negative Parts</strong>: </p>
<ul>
<li>Let $X$ be a nonempty set and $x$ an $\overline{\mathbb{R} }$-valued function on $X$: We define the positive and negative parts of $x$ as</li>
</ul>
<p>$$<br>x^+:= \max {x, 0}\mbox{ and }x^-:= \max {-x,0}<br>$$</p>
<ul>
<li><p>respectively. </p>
</li>
<li><p>Clearly, both $x^+$ and $x^-$ are $[0, \infty]$-valued functions on $X$, and we have<br>$$<br>x=x^+ -x^-<br>$$</p>
</li>
<li><p>The absolute value of $x$ is also decomposed into these two functions as follows:<br>$$<br>|x|=x^+ +x^-<br>$$</p>
</li>
</ul>
<blockquote>
<p>It is plain that the positive and negative parts of an $\overline{\mathbb{R}}$-valued function inherits the measurability of that function. </p>
<p>In other words, if $x$ is an $\overline{\mathbb{R}}$-valued random variable on a probability space $(X,\Sigma,\mathbf{p})$, then both $x^+$ and $x^-$ are $[0,\infty]$-valued random variables on $(X,\Sigma, \mathbf{p})$. </p>
<p>Conversely, if $x^+$ and $x^-$ are $[0,\infty]$-valued random variables on $(X,\Sigma,\mathbf{p})$, then $x$ must itself be an $\overline{\mathbb{R}}$-valued random variable on $(X,\Sigma,\mathbf{p})$.</p>
</blockquote>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Proposition 1.1</strong>: </p>
<ul>
<li>Let $X$ and $Y$ be two metric spaces, and $x: X \rightarrow Y$ a map that is continuous at all but countably many points. Then, $x$ is a $Y $-valued random variable on $(X,\mathcal{B}(X))$.</li>
</ul>
<blockquote>
<p>Continuity at everywhere but countably many points is suffcient for Borel measurability. The converse is false. Even a map that is discontinuous everywhere may be Borel measurable.</p>
</blockquote>
<p><strong>Proposition 1.2</strong>: </p>
<ul>
<li>Let $(X_i,\Sigma_ i)$ be a measurable space for each $i \in [3]$. </li>
<li>If $f : X_1 \rightarrow X_2$ is a $\Sigma_1\backslash\Sigma_2$-measurable map and $g : X_2 \rightarrow X_3$ is a $\Sigma_2\backslash\Sigma_3$-measurable map, then $g \circ f$ is a $\Sigma_1\backslash\Sigma_3$-measurable map from $X_1$ into $X_3$.</li>
</ul>
<p><strong>Proposition 1.5</strong>: </p>
<ul>
<li>Let $Y$ be a metric space and $(x_m)$ a sequence of $Y $-valued random variables on a measurable space $(X,\Sigma )$ such that $x_m\rightarrow x $ for some function $x: X \rightarrow Y$ . Then, $x$ is a $Y $-valued random variable on $(X,\Sigma )$.</li>
</ul>
<blockquote>
<p>If $(x_m)$ is a sequence of metric space-valued random variables on some measurable space, $\lim x_m$ is well-defined as a random variable on that space</p>
<p>This is unlike what is the case with continuous functions.</p>
</blockquote>
<p><strong>Corollary 1.6</strong>: </p>
<ul>
<li>Let $(x_m)$ be an increasing sequence of $\overline{\mathbb{R} }$-valued random variables on a measurable space $(X,\Sigma )$. Then, $\lim x_m$ is an $\overline{\mathbb{R}}$-valued random variable on $(X,\Sigma )$.</li>
</ul>
<p><strong>Theorem 1.7</strong>: </p>
<ul>
<li>Let $Y$ be a compact metric space and $x$ a $Y $-valued random variable on a measurable space $(X,\Sigma)$. </li>
<li>Then, there is a sequence $(x_m)$ of simple $Y$-valued random variables on $(X,\Sigma )$ such that $x_m\rightarrow x$ uniformly.</li>
</ul>
<blockquote>
<p>For a random variable with compact range, we can approximate a given random variable on a measurable space by means of simple random variables on that space. </p>
</blockquote>
<h2 id="Examples-and-Exercises"><a href="#Examples-and-Exercises" class="headerlink" title="Examples and Exercises"></a>Examples and Exercises</h2><p><strong>Example 1.1</strong>: </p>
<ul>
<li>If $X$ is a nonempty set and $Y$ a metric space, then any map from $X$ into $Y$ is a $Y$-valued random variable on $(X,2^X )$. </li>
<li>In particular, $\mathbb{R}^X = \mathcal{L}^0(X, 2^X )$.</li>
<li>If $X$ is finite, then any such function is a simple random variable on $(X,2^X )$. </li>
</ul>
<p><strong>Example 1.3</strong>:</p>
<ul>
<li>Let $X$ and $Y$ be two metric spaces. If $x : X\to Y$ is continuous, then $x$ is a $Y $-valued random variable on $(X,\mathcal{B}(X))$.</li>
<li>Indeed, continuity of $x$ implies that the inverse image of every open set in $Y$ under $x$ is open in $X$. </li>
<li>So this is enough to conclude that $x$ is a $Y$-valued random variable. </li>
<li>In particular, $\mathbf{C}(X) \subseteq \mathcal{L}^0(X,\mathcal{B}(X))$</li>
</ul>
<p><strong>Example</strong>:</p>
<ul>
<li>$x\in \mathcal{L}^0(X,\Sigma)$ implies $ax\in \mathcal{L}^0(X,\Sigma )$ for any real number $a$. </li>
<li>$x + y \in \mathcal{L}^0(X,\Sigma )$ for any $x,y\in \mathcal{L}^0(X,\Sigma)$. </li>
<li>Thus, $\mathcal{L}^0(X,\Sigma)$ is a linear space under the usual (pointwise) addition and scalar multiplication operations. <ul>
<li>The set of all simple random variables on $(X,\Sigma) $ constitutes a linear subspace of this linear space, which is itself a linear $X$ subspace of $\mathbb{R}^X $ .  </li>
<li>If $X$ is a metric space, then $\mathbf{C}(X)$ is also a linear subspace of $\mathcal{L}^0(X,\mathcal{B}(X))$.</li>
</ul>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T13:11:55.000Z" title="12/15/2020, 9:11:55 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-E-Probability-via-Measure-Theory/">1.1.E Probability via Measure Theory</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/8%20Probability%20via%20Measure%20Theory/Constructing-Probability-Spaces/">Constructing Probability Spaces</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Distribution Function</strong>: </p>
<ul>
<li>A map $F\in \mathbb{R} \rightarrow [0, 1]$ is said to be a <strong>distribution function</strong> if it is increasing, right-continuous, and $F(-\infty) = 0 = 1-F(\infty)$.</li>
</ul>
<blockquote>
<p>Every Borel probability measure on $\mathbb{R}$ induces a distribution function in a natural manner. Indeed, it is easy to see that the map $t \mapsto\mathbf{p}(-\infty, t]$ on $\mathbb{R}$ is a distribution function for any $\mathbf{p}\in \Delta(\mathbb{R})$</p>
</blockquote>
<p><strong>Distribution function induced by</strong> $\mathbf{p}$:</p>
<ul>
<li><p>For any $\mathbf{p}\in \Delta(\mathbb{R})$, the map $F_\mathbf{p} :\mathbb{R}\to [0, 1]$ defined by $F (t) := \mathbf{p}(-\infty, t]$, is a distribution function. </p>
</li>
<li><p>We refer to $F_\mathbf{p}$ <strong>the distribution function induced by $\mathbf{p}$.</strong></p>
</li>
</ul>
<p><strong>Lebesgue-Stieltjes Probability Measure induced by $F$ on $\mathbb{R} $</strong>: </p>
<ul>
<li>Let $\mathcal{S}$ be the semialgebra of all right-semiclosed intervals. </li>
<li>Taking any distribution function $F$, define the map $\mathbf{q}\in[0, 1]^{\mathcal {S}}$ as</li>
</ul>
<p>$$<br>\mathbf{q}(a,b]:=F(b)-F(a).\ \ \ -\infty\leq a\leq b&lt;\infty<br>$$</p>
<ul>
<li><p>and<br>$$<br>\mathbf{q}(a,\infty):=1-F(a),\ \ \ \ -\infty\leq a.<br>$$</p>
</li>
<li><p>The probability measure on $\sigma(\mathcal{S})=\mathcal{B}(\mathbb{R} )$ which accords with $\mathbf{q}$, and denoted by $\mathbf{p}_F$ is called the <strong>Lebesgue-Stieltjes probability measure induced by $F$ on $\mathbb{R} $.</strong></p>
<ul>
<li><p>Carath√©odory‚Äôs Extension Theorem would then say that there is a unique extension of $\mathbf{q}$ to a probability measure on $\mathcal{B}(\mathbb{R} )$.</p>
</li>
<li><p>To prove $\mathbf{q}$ is $\sigma$-additive on $\mathcal{S}$, let us take any countably infinite set $\mathcal{T}$ of pairwise disjoint right-semiclosed intervals, and assume that $\bigsqcup{T}$ is itself a right-semiclosed interval, say, $(a,b]$. </p>
</li>
<li><p>As things are trivial when $a = b$, we assume in what follows that $a &lt; b$ </p>
</li>
<li><p>We will assume here that $\bigsqcup \mathcal{T}$ is bounded from above, that is, it is an interval of the form $(a,b]$,  where $-\infty\leq a &lt; b &lt;\infty$</p>
</li>
<li><p>Let us then enumerate $T$ as ${f(a_1, b_1], (a_2, b_2],\cdots}$. </p>
</li>
<li><p>Then we can show that<br>$$<br>\mathbf{q}(a,b]=\sum^\infty_{i=1}\mathbf{q}(a_i,b_i].<br>$$</p>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>A Borel probability measure on $\mathbb{R} $ can actually be identified with a distribution function.</p>
</blockquote>
<p><strong>Lebesgue-Stieltjes probability measure induced by $F$ on $(a, b]$ / Lebesgue-Stieltjes measure induced by $F$ on $(a, b]$</strong>: </p>
<ul>
<li>If $X := (a, b]$ with $-\infty&lt; a &lt; b &lt; \infty$, and $F \in [0,1]^X$ is an increasing and right-continuous function with $F(a+) = 0$ and $F(b) = 1$, then we can define <strong>the Lebesgue-Stieltjes probability measure induced by $F$ on $(a, b] $</strong>, analogously.</li>
<li>Drop the conditions $F(a+) = 0$ and $F(b) = 1$, and allow $F \in \mathbb{R}^X$ then we can define <strong>the Lebesgue-Stieltjes measure induced by $F$ on $(a, b] $</strong>, analogously.</li>
</ul>
<p><strong>Lebesque Measure on $\mathbb{R} $</strong>: </p>
<ul>
<li><p>Take any integer $i$, let $X_i := (i,i+1]$, and define $F_i : X_i \rightarrow [0,1]$ by $F_i(t) := t-i$.</p>
</li>
<li><p>Let $\ell_i$ denote the Lebesgue-Stieltjes measure induced by $F_i$ on $X_i$ for each $i$</p>
</li>
<li><p>We define the <strong>Lebesgue measure on $\mathbb{R} $</strong> as the $[0,\infty]$-valued map $\ell$ on $\mathcal{B}(\mathbb{R} )$ with<br>$$<br>\ell(S):=\sum_{i\in\mathbb{Z}}\ell_i(S\cap X_i)<br>$$</p>
</li>
</ul>
<blockquote>
<p>As such, $\ell$ is both regular and tight.</p>
<p>Furthermore, it assigns to any interval its length as its measure. </p>
<p>In particular, it is readily verified that $\ell(a, b] = b$  a for any real numbers $a$ and $b$ with $a &lt; b$, while $\ell(I) = \infty$ for any unbounded interval $I$</p>
</blockquote>
<blockquote>
<p>Lebesque Measure on $\mathbb{R} $ is, geometrically speaking, the natural measure on the real line.</p>
<p>This is indeed a $\sigma$-finite measure on $\mathcal{B}(\mathbb{R} )$.</p>
<p>The restriction of $\ell$ to any Borel subset $X$ of $\mathbb{R}$ is a Borel measure on $X$; that is, $(X,\mathcal{B}(X),\ell|_{\mathcal{B}(X)})$ is a Borel measure space for any $X\in\mathcal{B}(\mathbb{R} )$. </p>
<p>For brevity, we denote this measure space simply as $(X,\mathcal{B}(X),\ell)$ in what follows. For instance, $([0,1],\mathcal{B}([0,1]),\ell)$ is a Borel probability space.</p>
</blockquote>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Carath√©odory‚Äôs Extension Theorem</strong>: </p>
<ul>
<li><p>Let $\mathcal{S}$ be a semialgebra on a nonempty set $X$ and take any $\mathbf{q}: \mathcal{S}\rightarrow [0,\infty]$. </p>
</li>
<li><p>If $\mathbf{q}$ is $\sigma$-additive, then there exists a measure $\mathbf{p}$ on $\sigma(\mathcal{S})$ such that $\mathbf{p}(S) = \mathbf{q}(S)$ for each $S \in \mathcal{S}$. </p>
</li>
<li><p>Moreover, if $\mathbf{q}(X) &lt; \infty$, then $\mathbf{p}$ is unique.</p>
</li>
</ul>
<blockquote>
<p>We can always extend a $\sigma$-additive $[0,\infty]$-valued map on an algebra $\mathcal{A}$ to a $\sigma$-additive $[0,\infty]$-valued map on $\sigma(\mathcal{A})$ </p>
<p>Moreover, this extension is unique, provided that our map is real-valued.</p>
</blockquote>
<blockquote>
<p>We can always obtain a probability measure, uniquely, on a $\sigma$-algebra by specifying the behavior of the measure only on a semialgebra that generates this $\sigma$-algebra. Since semialgebras and algebras are often easier than $\sigma$-algebras to work with, this fact is quite useful in constructing probability measures.</p>
</blockquote>
<p><strong>Proposition 3.1</strong>: </p>
<ul>
<li>For any real number a and Borel subset $S$ of $\mathbb{R} $, the set $S + a$ is Borel, and $\ell (S + a) =\ell (S)$.</li>
</ul>
<p><strong>Proposition 3.4</strong>: </p>
<ul>
<li><p>Let $f$ be an additive self-map on $\mathbb{R} $.</p>
</li>
<li><p>If $f$ is bounded on some Borel subset $S$ of $\mathbb{R} $ with $\ell(S) &gt; 0$, then it is linear.</p>
</li>
</ul>
<h2 id="Examples-and-Exercises"><a href="#Examples-and-Exercises" class="headerlink" title="Examples and Exercises"></a>Examples and Exercises</h2><p><strong>Example</strong>:</p>
<ul>
<li>Any singleton set in $\mathbb{R}$ has Lebesgue measure zero.</li>
<li>Since the Lebesgue measure of any singleton is zero, so must be the Lebesgue measure of any countable subset of $\mathbb{R}$, because the $\sigma$-additivity of $\ell$ implies that $\ell{a_1, a_2\dots, } = \sum^\infty \ell{a_i}=0$ for any real sequence $(a_m)$. </li>
<li>For instance: $\ell(\mathbb{Q}) = 0$</li>
</ul>
<p><strong>Example 3.5</strong>:</p>
<ul>
<li><p>There are in fact uncountable sets in $\mathbb{R}$ which have Lebesgue measure zero.</p>
</li>
<li><p>For example, the Contor Set.</p>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T12:51:55.000Z" title="12/15/2020, 8:51:55 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-E-Probability-via-Measure-Theory/">1.1.E Probability via Measure Theory</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/8%20Probability%20via%20Measure%20Theory/Elements-of-Probability-Theory/">Elements of Probability Theory</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Finitely Additive, $\sigma$-additive</strong>: </p>
<ul>
<li>Let $X$ be a nonempty set and $\mathcal{A}$ a collection of subsets of $X$ which constains $\empty$. </li>
<li>A map $\mathbf{p}:\mathcal{A}\mapsto [0,+\infty]$ is said to be <strong>finitely additive</strong> (**$\sigma$-additive**, responsive.) if $\mathbf{p}(\empty)=0$ and</li>
</ul>
<p>$$<br>\mathbf{p}(\bigsqcup\mathcal{S})=\sum_{S\in\mathcal{S}}\mathbf{p}(S)<br>$$</p>
<ul>
<li>for any nonempty finite (countable, resp.) set $\mathcal{S}$ of pariwise disjoint elements of $\mathcal{A}$ such that $\bigsqcup \mathcal{S}\in \mathcal{A}$.</li>
</ul>
<blockquote>
<p>$\sigma$-additivity implies the likelihood of the union of countably many pairwise disjoint events is simply the sum of the individual probabilities of each of these events.</p>
</blockquote>
<blockquote>
<p>The additivity property is the heart of the measure theory, entails several other useful properties for measures.</p>
</blockquote>
<p><strong>Measure, Measure Space</strong>: </p>
<ul>
<li>Let $(X,\Sigma)$ be a measurable space. </li>
<li>Any $\sigma$-additive function $\mu: \Sigma\mapsto[0,\infty]$ is called a <strong>measure</strong> on $\Sigma$, and in that case the ordered triplet $(X,\Sigma , \mu)$ is said to be a <strong>measure space</strong>. </li>
<li>If $\mu(X) &lt;\infty $; then $\mu$ is called a <strong>finite measure</strong>, and $(X,\Sigma ,\mu )$ is referred to as a <strong>finite measure space</strong>. </li>
<li>If there is a countable subset $\mathcal{T}$ of $\Sigma$ such that $X =\bigsqcup \mathcal{T}$ and $\mu(T) &lt; \infty$ for each $T\in \mathcal{T }$, we say that $\mu$ is a **$\sigma$-finite measure**, and refer to $(X,\Sigma,\mu)$ as a **$\sigma$-finite measure space**.</li>
</ul>
<blockquote>
<p>A useful interpretation is to think of a measure on $\Sigma$ as a function that tells us the ‚Äúsize‚Äù of each set in $\Sigma$ in some geometric sense.</p>
<p>Depending on the context, for instance, this may correspond to, say, area or volume or mass, etc., of the members of $\Sigma$.</p>
</blockquote>
<p><strong>Probability Measure, Probability Space</strong>: </p>
<ul>
<li>Let $(X,\Sigma,\mu)$ be a measure space. </li>
<li>If $\mu(X) = 1$, then $\mu$ is said to be a <strong>probability measure</strong>, and in this case, $(X,\Sigma,\mu)$ is called a <strong>probability space</strong>.</li>
</ul>
<blockquote>
<p>Roughly speaking, a probability measure tells us the likelihood of observing any conceivable event in an experiment the outcome of which is uncertain.</p>
</blockquote>
<p><strong>Borel Measure, Borel Space, Borel Probability Space</strong>: </p>
<ul>
<li>Given a metric space $X$, any measure $\mathbf{p}$ on $\mathcal{B}(X)$ is called a <strong>Borel measure</strong> on $X$, and in this case $(X,\mathcal{B}(X),\mathbf{p})$ is referred to as a <strong>Borel space</strong>. </li>
<li>If, in addition, $\mathbf{p}$ is a probability measure, then $(X,\mathcal{B}(X),\mathbf{p})$ is called a <strong>Borel probability space</strong>.<ul>
<li>We denote the set of all Borel probability measures on a metric space $X$ by $\Delta(X)$.</li>
</ul>
</li>
</ul>
<p><strong>Regular</strong>: </p>
<ul>
<li><p>Let $X$ be a metric space and $\mathbf{p}\in\Delta(X)$.</p>
</li>
<li><p>Let $\mathcal{O}_X$ and $\mathcal{C}_X$ denote the class of all open and closed subsets of $X$, respectively. </p>
</li>
<li><p>A Borel measure $\mathbf{p}$ on a metric space $X$ is said to be <strong>regular</strong> if<br>$$<br>\inf{\mathbf{p}(O): S\subseteq O\in \mathcal{O}_X}=\mathbf{p}(S) = \sup \mathbf{p}(C) : {S\supseteq  C\in \mathcal{C}_X}<br>$$</p>
</li>
<li><p>holds for any $S\in \mathcal{B}(X)$.</p>
</li>
</ul>
<blockquote>
<p>Much of the diffculty with working with probability measures stems from the fact that the contents of the $\sigma$-algebra of a probability space are often obscure. The situation reads markedly better in the case of Borel probability spaces, for the $\sigma$-algebra of such a space is generated by sets that are somewhat concrete (such as open (or closed) subsets of the sample space). </p>
<p>Moreover, in the context of any Borel probability space, it is possible to approximate the probability of any event by using only the open and closed sets. </p>
<p>Put more formally, if $X$ is a metric space and $\mathbf{p}\in\Delta(X)$, then, for any Borel subset $S$ of $X$ and $\varepsilon&gt; 0$, we can find an open subset $O$ and a closed subset $C$ of $X$ such that $C\subseteq S\subseteq O$ and $\mathbf{p}(O\setminus C) &lt;\varepsilon$.</p>
</blockquote>
<blockquote>
<p>Every Borel probability measure is regular.</p>
<p>Every finite Borel measure on a metric space is regular.</p>
</blockquote>
<p><strong>Tight</strong>: </p>
<ul>
<li>A finite Borel measure $\mathbf{p}$ on a metric space $X$ is said to be <strong>tight</strong> if for each $\varepsilon &gt; 0$, there is a compact subset $K$ of $X$ such that $p(X\backslash K) &lt;\varepsilon$.</li>
</ul>
<blockquote>
<p>Every Borel probability measure on a complete and separable metric space is tight.</p>
</blockquote>
<h2 id="Propositions-and-Theorems"><a href="#Propositions-and-Theorems" class="headerlink" title="Propositions and Theorems"></a>Propositions and Theorems</h2><p><strong>Lemma 2.1</strong>: </p>
<ul>
<li>Let $\mathcal{S}$ be a semialgebra on a nonempty set $X$, and $\mathbf{q} : \mathcal{S}\mapsto [0,+\infty]$ a finitely additive map. Then, there is a unique finitely additive map $\mathbf{p} : \alpha(\mathcal{S})\mapsto[0,+\infty]$ such that $\mathbf{p}(S) = \mathbf{q}(S)$ for each $S \in \mathcal{S}$.</li>
</ul>
<p><strong>Lemma 2.2</strong>: </p>
<ul>
<li>Let $\mathcal{S}$ be a semialgebra on a nonempty set $X$, and $\mathbf{q}: \mathcal{S} \mapsto [0,+\infty]$ a $\sigma$-additive map. Then, there is a unique $\sigma$-additive map $\mathcal{p}:\sigma(\mathcal{S})\mapsto [0,+\infty]$ such that $\mathbf{p}(S) = \mathbf{q}(S)$ for each $S\in \mathcal{S}$.</li>
</ul>
<blockquote>
<p>Every finitely additive (finitely additive and $\sigma$-subadditive) $[0,\infty]$-valued map on a semialgebra $\mathcal{S}$ can be extended, uniquely, to a finitely additive ($\sigma$-additive) $[0,\infty]$-valued map on the algebra generated by $\mathcal{S}$.</p>
</blockquote>
<p><strong>Lemma 2.3</strong>: </p>
<ul>
<li>Let $X$ be a nonempty set, $\mathcal{A}$ an algebra on $X$, and $\mu:\mathcal{A}\mapsto[0,\infty]$ a $\sigma$-additive map on $\mathcal{A}$. Then, $\mu$ is finitely additive. Consequently,</li>
</ul>
<p>$$<br>\mu(B\backslash A)=\mu(B)-\mu(A)\mbox{ for any} A,B\in \mathcal{A}\ \mbox{with}\ A\subseteq B,<br>$$</p>
<ul>
<li><p>which shows that $\mu$ is $\supseteq$-increasing (that is, $\mu(A)\leq\mu(B)$ for any $A,B\in \mathcal{A}$ with</p>
<p>$A\subseteq B$). Moreover,<br>$$<br>\mu(\bigcup\mathcal{S})\leq\sum_{S\in\mathcal{S}}\mu(S)<br>$$</p>
</li>
<li><p>for any countable $\mathcal{S}\subseteq \mathcal{A}$ with $\bigcup\mathcal{S}\in\mathcal{A}$.</p>
</li>
</ul>
<p><strong>Boole‚Äôs Inequality</strong>: </p>
<ul>
<li>Let $(X,\Sigma,\mathbf{p})$ be a probability space. Then,</li>
</ul>
<p>$$<br>\mathbf{p}(\bigcup\mathcal{S})\leq\sum_{S\in\mathcal{S}}\mathbf{p}(S)\ \mbox{for any nonempty countable}\ \mathcal{S}\subseteq\Sigma<br>$$</p>
<p><strong>Proposition 2.4</strong>: </p>
<ul>
<li>Let $(X,\Sigma, \mu)$ be a finite measure space, and let $(A_m)\in\Sigma^\infty$. If $A_1\subseteq A_2\subseteq\cdots$  (in which case we say that $(A_m)$ is an increasing sequence), then</li>
</ul>
<p>$$<br>\lim\mu(A_m)=\mu\left(\bigcup^\infty_{i=1}A_i\right).<br>$$</p>
<ul>
<li>On the other hand, if $A_1\supseteq A_2\supseteq \cdots$  (in which case we say that $(A_m)$ is a decreasing sequence), then<br>$$<br>\lim\mu(A_m)=\mu \left(\bigcap^\infty_{i=1}A_i\right) .<br>$$</li>
</ul>
<blockquote>
<p>These two properties of a finite measure measure are often referred to as the properties of continuity (from below and above, resp.) of a finite measure.</p>
</blockquote>
<p><strong>Proposition 2.5</strong>: </p>
<ul>
<li>Let $X$ be a nonempty set, $\mathcal{A}$ be an algebra on $X$, and  $\mu:A\rightarrow [0,\infty]$ a finitely additive function such that $\mu(C_m)\downarrow 0$ for any $(C_m)\in A^\infty$ with $C_m\downarrow\empty$. Then, $\mu$ is $\sigma$-additive.</li>
</ul>
<blockquote>
<p>Finite additivity and continuity of a set function jointly imply its $\sigma$-additivity. A finitely additive $[0,\infty]$-valued function on an algebra that is continuous from above at $\emptyset$ is $\sigma$-additive.</p>
</blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-15T12:41:55.000Z" title="12/15/2020, 8:41:55 PM">2020-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/1-Mathematics/">1 Mathematics</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a><span>¬†/¬†</span><a class="link-muted" href="/categories/1-Mathematics/1-1-Analysis/1-1-E-Probability-via-Measure-Theory/">1.1.E Probability via Measure Theory</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/15/Mathematics/Analysis/8%20Probability%20via%20Measure%20Theory/Measurable-Spaces/">Measurable Spaces</a></h1><div class="content"><h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p><strong>Algebra</strong></p>
<ul>
<li>Let $X$ be a nonempty set. </li>
<li>A nonempty collection $\mathcal{A} $ of subsets of $X$ is called an <strong>algebra</strong> on $X$ if<ol>
<li>$X\backslash A\in \mathcal{A}$ for all $A \in \mathcal{A}$; and</li>
<li>$A\cup B\in \mathcal{A}$ for all $A, B\in \mathcal{A}$.</li>
</ol>
</li>
<li>We say that $\mathcal{A}$ is a <strong>finite algebra</strong> on $X$ if it is an algebra on $X$ such that $| \mathcal{A}| &lt; \infty$.</li>
</ul>
<blockquote>
<p>In words, an algebra on a nonempty set $X$ is a nonempty collection of subsets of $X$ that is closed under complementation and taking pairwise (and thus finite) unions, and a finite algebra on $X$ is one that contains finitely many elements. (Obviously, any algebra on a finite set is a finite algebra on that set.)</p>
</blockquote>
<blockquote>
<p>Both $\emptyset$ and $X$ belong to any algebra $\mathcal{A}$ on $X$</p>
<p>By the de Morgan Law, an algebra $\mathcal{A}$ on $X$ is closed under taking finite intersections. That is, if $\mathcal{S}$ is a finite subset of $\mathcal{A}$, then $\bigcap\mathcal{S}\in\mathcal{A}$</p>
</blockquote>
<p><strong>$\sigma$-algebra, $\Sigma$-measureable set, Measureable Space</strong>: </p>
<ul>
<li>Let $X$ be a nonempty set. A nonempty collection of subsets of $X$ is called <strong>$\sigma$-algebra</strong> on $X$ if<ol>
<li> $X\backslash A\in\Sigma$ for all $A \in \Sigma$; and</li>
<li> $\bigcup^\infty A_i\in\Sigma$ whenever $A_i\in\Sigma$ for each $i=1,2‚Ä¶$</li>
</ol>
</li>
<li>Any element of $\Sigma$ is called a **$\Sigma$-measurable set** in $X$. </li>
<li>If $\Sigma$ is a $\sigma$-algebra on $X$, we refer to the pair $(X,\Sigma)$ as a <strong>measurable space</strong>.</li>
</ul>
<blockquote>
<p>A $\sigma$-algebra on $X$ is a nonempty collection of subsets of $X$ that is closed under complementation and taking countably infinite unions. </p>
<p>In particular, there is no difference between an algebra and a $\sigma$-algebra when the ground set $X$ under consideration is finite. </p>
<p>More generally, every finite algebra on $X$ is a $\sigma$-algebra on $X$</p>
</blockquote>
<blockquote>
<p>By the de Morgan Law, an $\sigma$-algebra on $X$ is closed under taking finite intersections. That is, if $\mathcal{C}$ is a countable subset of a $\sigma$-algebra $\Sigma$ on $X$, then $\bigcap\mathcal{C}\in\Sigma$</p>
</blockquote>
<p><strong>Sample Space</strong>:</p>
<ul>
<li>Given a nonempty set $X$ and a $\sigma$-algebra $\Sigma$ on $X$, we think of $X$ as the set of all possible outcomes that may result in an experiment, the so-called <strong>sample space</strong>, and view any one member of $\Sigma$ (and only such a subset of $X$) as an ‚Äúevent‚Äù that may take place in the experiment.</li>
</ul>
<p><strong>Event, Event Space</strong>:</p>
<ul>
<li>Given a $\sigma$-algebra $\Sigma$ on $X$, the intuitive concept of an ‚Äú<strong>event</strong>‚Äú is formalized as any $\Sigma$-measurable set in $X$. </li>
<li>That is, we say that $A$ is an event if and only if $A\in\Sigma$ , and for this reason a $\sigma$-algebra on $X$ is often referred to as an <strong>event space</strong> on $X$. </li>
</ul>
<blockquote>
<p>One may define many different event spaces on a given sample space, so what an ‚Äúevent‚Äù really is depends on the model one chooses to work with.</p>
</blockquote>
<p><strong>Semialgebra</strong>: </p>
<ul>
<li><p>Let $X$ be a nonempty set and $\mathcal{S}$ a collection of subsets of $X$. </p>
</li>
<li><p>We say that $\mathcal{S}$ is a <strong>semialgebra</strong> on $X$ if </p>
<ol>
<li>both $\empty$ and $X$ belong to $\mathcal{S}$; </li>
<li>$\mathcal{S}$ is closed under taking finite intersections, and </li>
<li>for any $S \in \mathcal{S}$, the set $X\backslash S$ can be written as the union of a collection of finitely many pairwise disjoint elements of $\mathcal{S}$.</li>
</ol>
</li>
</ul>
<p><strong>Generated Algebra</strong>: </p>
<ul>
<li><p>Let $X$ be a nonempty set and $\mathcal{S}$ a subset of $2^X$. </p>
</li>
<li><p>The smallest algebra on $X$ that contains $\mathcal{S}$ (in the sense that this algebra is included in any other algebra that contains $\mathcal{S}$) is called the <strong>algebra generated by $\mathcal{S}$</strong>; and is denoted as $\alpha(\mathcal{S})$.</p>
<ul>
<li>we have $\mathcal{A} =\alpha(\mathcal{A})$ for any algebra $\mathcal{A}$ on any nonempty set.</li>
</ul>
</li>
</ul>
<p><strong>Generated $\sigma$-algebra</strong>: </p>
<ul>
<li><p>Let $X$ be a nonempty set and $\mathcal{S}$ a nonempty subset of $2^X $. </p>
</li>
<li><p>The smallest $\sigma$-algebra on $X$ that contains $\mathcal{S}$ (in the sense that this $\sigma$-algebra is included in any other $\sigma$-algebra that contains $\mathcal{S}$) is called the $\sigma$-algebra generated by $\mathcal{S}$; and is denoted as $\sigma (\mathcal{S})$.<br>$$<br>\sigma(\mathcal{S})=\bigcap{\Sigma:\Sigma\mbox{ is a }\sigma\mbox{-algebra on }X\mbox{ such that }\mathcal{S}\subseteq\Sigma}<br>$$</p>
</li>
</ul>
<p><strong>Borel $\sigma$-algerbra</strong>: </p>
<ul>
<li>Let $X$ be a metric space, and, let $\mathcal{O}_X$ stand for the collection of all open, and $\mathcal{C}_X$ for that of all closed, subsets of $X$. <ul>
<li>The members of $\mathcal{O}_X$, or of $\mathcal{C}_X$, are of obvious importance, but unfortunately neither of these collections is an algebra in general. </li>
</ul>
</li>
<li>In metric spaces, then, it is natural to consider the $\sigma$-algebra generated by $\mathcal{O}_X$, called the <strong>Borel $\sigma$-algebra</strong> on $X$; and its members are referred to as <strong>Borel sets</strong> (or in probabilistic jargon, <strong>Borel events</strong>). </li>
<li>We denote the Borel $\sigma$-algebra on a metric space $X$ by $\mathcal{B}_X$. </li>
<li>By denifition, therefore, we have $\mathcal{B}(X):=\sigma(\mathcal{O}_X)$.<ul>
<li>We usually write $\mathcal{B}[a, b]$ for $\mathcal{B}([a, b])$, and $\mathcal{B}(a, b]$ for $\mathcal{B}((a, b])$, where $-\infty &lt; a &lt; b &lt; \infty$.</li>
</ul>
</li>
</ul>
<h2 id="Examples-and-Exercises"><a href="#Examples-and-Exercises" class="headerlink" title="Examples and Exercises"></a>Examples and Exercises</h2><p><strong>Example 1.3</strong></p>
<ol>
<li>The collection of all intervals is a semialgebra on $\mathbb{R}$, but it is not an algebra.</li>
<li>The collection of all open intervals is not a semialgebra on $\mathbb{R}$.</li>
<li>The collection of all right-semiclosed intervals is a semialgebra on $\mathbb{R}$; but it is not an algebra. </li>
<li>The smallest algebra on $\mathbb{R}$ that contains all right-semiclosed intervals is the collection of all finite disjoint unions of right-semiclosed intervals. This algebra is not a $\sigma$-algebra. </li>
</ol>
<p><strong>Example</strong>:</p>
<ul>
<li>if $X := {a,b,c}$,then <ul>
<li>$\alpha(\emptyset) = \alpha({\emptyset}) = \alpha({X}) = {\emptyset,X}$</li>
<li>$\alpha({\emptyset, X, {a}}) = {\emptyset,X,{a},{b,c}}$</li>
<li>$\alpha({\emptyset,X,{a},{b}}) = 2^X$</li>
</ul>
</li>
</ul>
<p><strong>Example 1.5</strong>:</p>
<ul>
<li>By definition, $\mathcal{B}(\mathbb{R}) = (\mathcal{O}_\mathbb{R})$; but one does not actually need all open sets in $\mathbb{R}$ for generating $\mathcal{B}(\mathbb{R})$<ul>
<li>For instance, what if we used instead the class of all open and bounded intervals, call it $\mathcal{A}_1$, then $\sigma(\mathcal{A}_1)=\mathcal{B}(\mathbb{R})$.</li>
<li>$\mathcal{A}_2:=$ the set of all closed and bounded intervals</li>
<li>$\mathcal{A}_3:=$ the set of all closed sets in $\mathbb{R}$</li>
<li>$\mathcal{A}_4:=$ the set of all bounded intervals of the form $(a, b]$</li>
<li>$\mathcal{A}_5:=$ the set of all intervals of the form $(-\infty,a]$</li>
<li>$\mathcal{A}_5:=$ the set of all intervals of the form $(-\infty,a)$</li>
<li>All of these collections generate the same $\sigma$-algebra, namely, $\mathcal{B}(\mathbb{R})$<ul>
<li>For any metric space $X$, $\mathcal{B}(X):=\sigma(\mathcal{O}_X)=\sigma(\mathcal{C}_X)$.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Efe A. Ok, ‚ÄúMeasure and Probability Theory with Economic Applications‚Äù;</li>
<li>Lecture notes, ECON 30400 2, Autumn 2020, Introduction: Mathematical Methods In Economics;</li>
<li>Walter Rudin, 1987, ‚ÄúReal and Complex Analysis‚Äù; </li>
<li>Walter Rudin, 1976, ‚ÄúPrinciple of Mathematical Analysis‚Äù; </li>
</ol>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="hqin"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">hqin</p><p class="is-size-6 is-block">A Student in Economics</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Zhengzhou, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">47</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">15</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">5</p></a></div></div></nav></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-01-02T14:17:12.000Z">2021-01-02</time></p><p class="title"><a href="/2021/01/02/Mathematics/Dynamic%20Optimization/1%20Preliminaries%20of%20Dynamic%20Optimization/The-Nature-of-Dynamic-Optimization/">The Nature of Dynamic Optimization</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-4-Dynamic-Optimization/">1.4 Dynamic Optimization</a> / <a href="/categories/1-Mathematics/1-4-Dynamic-Optimization/1-4-A-Preliminaries-of-Dynamic-Optimization/">1.4.A Preliminaries of Dynamic Optimization</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-24T14:52:59.000Z">2020-12-24</time></p><p class="title"><a href="/2020/12/24/Mathematics/Algebra/2%20Linear%20Algebra/Geometric-Linear-Algebra/">Geometric Linear Algebra</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-2-Algebra/">1.2 Algebra</a> / <a href="/categories/1-Mathematics/1-2-Algebra/1-2-B-Linear-Algebra/">1.2.B Linear Algebra</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-24T14:52:00.000Z">2020-12-24</time></p><p class="title"><a href="/2020/12/24/Mathematics/Algebra/1%20Abstract%20Algebra/Elements-of-Abstract-Algebra/">Elements of Abstract Algebra</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-2-Algebra/">1.2 Algebra</a> / <a href="/categories/1-Mathematics/1-2-Algebra/1-2-A-Abstract-Algebra/">1.2.A Abstract Algebra</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-15T14:50:59.000Z">2020-12-15</time></p><p class="title"><a href="/2020/12/15/Mathematics/Analysis/15%20Stochastic%20Dependence/Propertities-of-Conditional-Expectation/">Propertities of Conditional Expectation</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a> / <a href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/">1.1.H Stochastic Independence and Dependence</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-15T14:49:59.000Z">2020-12-15</time></p><p class="title"><a href="/2020/12/15/Mathematics/Analysis/15%20Stochastic%20Dependence/Conditional-Expectation/">Conditional Expectation</a></p><p class="categories"><a href="/categories/1-Mathematics/">1 Mathematics</a> / <a href="/categories/1-Mathematics/1-1-Analysis/">1.1 Analysis</a> / <a href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/">1.1.H Stochastic Independence and Dependence</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">January 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/12/"><span class="level-start"><span class="level-item">December 2020</span></span><span class="level-end"><span class="level-item tag">24</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/11/"><span class="level-start"><span class="level-item">November 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/10/"><span class="level-start"><span class="level-item">October 2020</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/09/"><span class="level-start"><span class="level-item">September 2020</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li></ul></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://ygnmax.github.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Guangnan Yang</span></span><span class="level-right"><span class="level-item tag">ygnmax.github.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Abstract-Algebra/"><span class="tag">Abstract Algebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Control-Theory/"><span class="tag">Control Theory</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Algebra/"><span class="tag">Linear Algebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Measure-Theoretic-Probability/"><span class="tag">Measure Theoretic Probability</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Real-Analysis/"><span class="tag">Real Analysis</span><span class="tag">24</span></a></div></div></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/1-Mathematics/"><span class="level-start"><span class="level-item">1 Mathematics</span></span><span class="level-end"><span class="level-item tag">47</span></span></a><ul><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/"><span class="level-start"><span class="level-item">1.1 Analysis</span></span><span class="level-end"><span class="level-item tag">44</span></span></a><ul><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-A-Preliminaries-of-Real-Analysis/"><span class="level-start"><span class="level-item">1.1.A Preliminaries of Real Analysis</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-B-Metric-Spaces-and-Continuity/"><span class="level-start"><span class="level-item">1.1.B Metric Spaces and Continuity</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-C-Linear-Spaces-and-Convexity/"><span class="level-start"><span class="level-item">1.1.C Linear Spaces and Convexity</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-D-Metric-Linear-Spaces-and-Normed-Linear-Spaces/"><span class="level-start"><span class="level-item">1.1.D Metric Linear Spaces and Normed Linear Spaces</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-E-Probability-via-Measure-Theory/"><span class="level-start"><span class="level-item">1.1.E Probability via Measure Theory</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-F-Expectation-Lebesgue-Integral-and-Stieltjes-Integral/"><span class="level-start"><span class="level-item">1.1.F Expectation, Lebesgue Integral, and Stieltjes Integral</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-G-Weak-Convergence-and-Probability-Limit/"><span class="level-start"><span class="level-item">1.1.G Weak Convergence and Probability Limit</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-1-Analysis/1-1-H-Stochastic-Independence-and-Dependence/"><span class="level-start"><span class="level-item">1.1.H Stochastic Independence and Dependence</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-2-Algebra/"><span class="level-start"><span class="level-item">1.2 Algebra</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/1-Mathematics/1-2-Algebra/1-2-A-Abstract-Algebra/"><span class="level-start"><span class="level-item">1.2.A Abstract Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-2-Algebra/1-2-B-Linear-Algebra/"><span class="level-start"><span class="level-item">1.2.B Linear Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/1-Mathematics/1-4-Dynamic-Optimization/"><span class="level-start"><span class="level-item">1.4 Dynamic Optimization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/1-Mathematics/1-4-Dynamic-Optimization/1-4-A-Preliminaries-of-Dynamic-Optimization/"><span class="level-start"><span class="level-item">1.4.A Preliminaries of Dynamic Optimization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">hqin</a><p class="is-size-7"><span>&copy; 2020 - 2021 hqin</span>¬†¬†</p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'folded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">√ó</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>